{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "brilliant-equality",
   "metadata": {},
   "source": [
    "# g4_v001\n",
    "exp045ベース"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "velvet-kazakhstan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import library\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import pathlib\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import itertools\n",
    "import lightgbm as lgb\n",
    "from optuna.integration import lightgbm as optuna_lgb\n",
    "import simdkalman\n",
    "import optuna\n",
    "import pyproj\n",
    "from pyproj import Proj, transform\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, confusion_matrix, accuracy_score\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "careful-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = ['2020-05-14-US-MTV-1', '2020-05-14-US-MTV-2', '2020-05-21-US-MTV-1', '2020-05-21-US-MTV-2',\n",
    "      '2020-05-29-US-MTV-1', '2020-05-29-US-MTV-2', '2020-06-04-US-MTV-1', '2020-06-05-US-MTV-1',\n",
    "      '2020-06-05-US-MTV-2', '2020-06-11-US-MTV-1', '2020-07-08-US-MTV-1', '2020-07-17-US-MTV-1',\n",
    "      '2020-07-17-US-MTV-2', '2020-08-03-US-MTV-1', '2020-08-06-US-MTV-2', '2020-09-04-US-SF-1',\n",
    "      '2020-09-04-US-SF-2',  '2021-01-04-US-RWC-1', '2021-01-04-US-RWC-2',\n",
    "      '2020-05-15-US-MTV-1', '2020-05-28-US-MTV-1', '2020-05-28-US-MTV-2', '2020-06-04-US-MTV-2',\n",
    "      '2020-06-10-US-MTV-1', '2020-06-10-US-MTV-2', '2020-08-03-US-MTV-2', '2020-08-13-US-MTV-1',\n",
    "      '2021-03-16-US-MTV-2']\n",
    "\n",
    "g2 = ['2021-01-05-US-SVL-1', '2021-01-05-US-SVL-2', '2021-04-15-US-MTV-1', \n",
    "      '2021-03-25-US-PAO-1', '2021-04-02-US-SJC-1', '2021-04-08-US-MTV-1']\n",
    "\n",
    "g3 = ['2021-03-10-US-SVL-1', '2021-04-26-US-SVL-1', '2021-04-26-US-SVL-2']\n",
    "\n",
    "g4 = ['2021-04-28-US-MTV-1', '2021-04-29-US-MTV-1', \n",
    "      '2021-03-16-US-RWC-2', '2021-04-21-US-MTV-1', '2021-04-28-US-MTV-2', '2021-04-29-US-MTV-2']\n",
    "\n",
    "g5 = ['2021-04-22-US-SJC-1', '2021-04-28-US-SJC-1', '2021-04-29-US-SJC-2', \n",
    "      '2021-04-22-US-SJC-2', '2021-04-29-US-SJC-3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bottom-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = g4\n",
    "ro_th = 50 # 相対移動距離をもとにした異常値除去の閾値\n",
    "rog_th = 10 # ground_truthをもとにした異常値除去の閾値\n",
    "rp_rate = 0.5 # 相対座標を混ぜる割合\n",
    "\n",
    "# ground_truthをもとにした異常値除去を行うcollection\n",
    "rog_target = ['2021-04-22-US-SJC-1', '2021-04-29-US-SJC-2', '2021-04-28-US-SJC-1', '2021-04-22-US-SJC-2', '2021-04-29-US-SJC-3',\n",
    "              '2021-04-28-US-MTV-1', '2021-04-29-US-MTV-1', '2021-03-16-US-RWC-2', '2021-04-28-US-MTV-2', '2021-04-29-US-MTV-2',\n",
    "              '2021-04-26-US-SVL-2', '2021-03-10-US-SVL-1', '2021-04-26-US-SVL-1',\n",
    "              '2021-04-21-US-MTV-1', '2021-04-28-US-MTV-1', '2021-04-29-US-MTV-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dedicated-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rb_dir = '../output/prep/baseline_g5_v001'\n",
    "sp0_dir = '../output/prep/speed0_pred_v001'\n",
    "degree_dir = '../output/prep/degree_pred_v002'\n",
    "dist_dir = '../output/prep/distance_pred_v002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "substantial-injury",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb_path\n",
    "\n",
    "def get_nb_name():\n",
    "    nb_path = ipynb_path.get()\n",
    "    nb_name = nb_path.rsplit('/',1)[1].replace('.ipynb','')\n",
    "    return nb_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fluid-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory setting\n",
    "nb_name = get_nb_name()\n",
    "INPUT = '../input/google-smartphone-decimeter-challenge'\n",
    "OUTPUT = '../output/' + nb_name\n",
    "os.makedirs(OUTPUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-genius",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "wireless-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_score(df, gt):\n",
    "    gt = gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n",
    "    df = df.merge(gt, on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n",
    "    # calc_distance_error\n",
    "    df['err'] = calc_haversine(df['latDeg_gt'], df['lngDeg_gt'], df['latDeg'], df['lngDeg'])\n",
    "    # calc_evaluate_score\n",
    "    df['phone'] = df['collectionName'] + '_' + df['phoneName']\n",
    "    res = df.groupby('phone')['err'].agg([percentile50, percentile95])\n",
    "    res['p50_p90_mean'] = (res['percentile50'] + res['percentile95']) / 2 \n",
    "    score = res['p50_p90_mean'].mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "headed-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculates the great circle distance between two points\n",
    "    on the earth. Inputs are array-like and specified in decimal degrees.\n",
    "    \"\"\"\n",
    "    RADIUS = 6_367_000\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + \\\n",
    "        np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    dist = 2 * RADIUS * np.arcsin(a**0.5)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "interior-gather",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_trafic(df, center, zoom=9):\n",
    "    fig = px.scatter_mapbox(df,\n",
    "                            \n",
    "                            # Here, plotly gets, (x,y) coordinates\n",
    "                            lat=\"latDeg\",\n",
    "                            lon=\"lngDeg\",\n",
    "                            \n",
    "                            #Here, plotly detects color of series\n",
    "                            color=\"phoneName\",\n",
    "                            labels=\"phoneName\",\n",
    "                            \n",
    "                            zoom=zoom,\n",
    "                            center=center,\n",
    "                            height=600,\n",
    "                            width=800)\n",
    "    fig.update_layout(mapbox_style='stamen-terrain')\n",
    "    fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
    "    fig.update_layout(title_text=\"GPS trafic\")\n",
    "    fig.show()\n",
    "    \n",
    "def visualize_collection(df, collection):\n",
    "    target_df = df[df['collectionName']==collection].copy()\n",
    "    lat_center = target_df['latDeg'].mean()\n",
    "    lng_center = target_df['lngDeg'].mean()\n",
    "    center = {\"lat\":lat_center, \"lon\":lng_center}\n",
    "    \n",
    "    visualize_trafic(target_df, center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "swiss-handling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_truth\n",
    "def get_ground_truth():\n",
    "    p = pathlib.Path(INPUT)\n",
    "    gt_files = list(p.glob('train/*/*/ground_truth.csv'))\n",
    "\n",
    "    gts = []\n",
    "    for gt_file in gt_files:\n",
    "        gts.append(pd.read_csv(gt_file))\n",
    "    ground_truth = pd.concat(gts)\n",
    "\n",
    "    return ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sorted-meeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile50(x):\n",
    "    return np.percentile(x, 50)\n",
    "def percentile95(x):\n",
    "    return np.percentile(x, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "alert-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_result:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.gt = get_ground_truth()\n",
    "        self.bl = pd.read_csv(INPUT + '/' + 'baseline_locations_train.csv')\n",
    "        \n",
    "        self.gt = self.gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n",
    "        self.df = self.df.merge(self.gt, on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n",
    "        self.df['phone'] = self.df['collectionName'] + '_' + self.df['phoneName']\n",
    "        self.df['err'] =  calc_haversine(self.df['latDeg_gt'], self.df['lngDeg_gt'], self.df['latDeg'], self.df['lngDeg'])\n",
    "        \n",
    "        self.phone_res = self.calc_err('phone')\n",
    "        self.clc_res = self.calc_err('collectionName')\n",
    "        self.phonename_res = self.calc_err('phoneName')\n",
    "        \n",
    "    def calc_err(self, by):\n",
    "        res = self.df.groupby(by)['err'].agg([percentile50, percentile95])\n",
    "        res['p50_p90_mean'] = (res['percentile50'] + res['percentile95']) / 2\n",
    "        return res\n",
    "    \n",
    "    @property\n",
    "    def score(self):\n",
    "        return self.phone_res['p50_p90_mean'].mean()\n",
    "    @property\n",
    "    def raw_data(self):\n",
    "        return self.df\n",
    "    @property\n",
    "    def err(self):\n",
    "        return self.phone_res\n",
    "    @property\n",
    "    def collection_err(self):\n",
    "        return self.clc_res\n",
    "    @property\n",
    "    def phonename_err(self):\n",
    "        return self.phonename_res\n",
    "    \n",
    "    def viz_map(self, collection, show_gt=True, show_bl=True):\n",
    "        tmp = self.df[self.df['collectionName']==collection][['collectionName', 'phoneName', 'latDeg', 'lngDeg']]\n",
    "        tmp2 = self.df[self.df['collectionName']==collection][['collectionName', 'phoneName', 'latDeg_gt', 'lngDeg_gt']]\n",
    "        tmp2 = tmp2.rename(columns={'latDeg_gt':'latDeg', 'lngDeg_gt':'lngDeg'})\n",
    "        tmp2['phoneName'] = tmp2['phoneName'] + '_GT'\n",
    "        tmp3 = self.bl[self.bl['collectionName']==collection][['collectionName', 'phoneName', 'latDeg', 'lngDeg']]\n",
    "        tmp3['phoneName'] = tmp3['phoneName'] + '_BL'\n",
    "        \n",
    "        if show_gt:\n",
    "            tmp = tmp.append(tmp2)\n",
    "        if show_bl:\n",
    "            tmp = tmp.append(tmp3)\n",
    "        visualize_collection(tmp, collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "royal-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    base_train = pd.read_csv(INPUT + '/' + 'baseline_locations_train.csv')\n",
    "    base_test = pd.read_csv(INPUT + '/' + 'baseline_locations_test.csv')\n",
    "    sample_sub = pd.read_csv(INPUT + '/' + 'sample_submission.csv')\n",
    "    ground_truth = get_ground_truth()\n",
    "    return base_train, base_test, sample_sub, ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-princeton",
   "metadata": {},
   "source": [
    "# 相対移動距離をもとにした外れ値除去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "awful-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, sub, gt = get_data()\n",
    "train = train[train['collectionName'].isin(target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "governmental-increase",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distance_diff(df):\n",
    "    df['latDeg_prev'] = df['latDeg'].shift(1)\n",
    "    df['latDeg_next'] = df['latDeg'].shift(-1)\n",
    "    df['lngDeg_prev'] = df['lngDeg'].shift(1)\n",
    "    df['lngDeg_next'] = df['lngDeg'].shift(-1)\n",
    "    df['phone_prev'] = df['phone'].shift(1)\n",
    "    df['phone_next'] = df['phone'].shift(-1)\n",
    "    \n",
    "    df['dist_prev'] = calc_haversine(df['latDeg'], df['lngDeg'], df['latDeg_prev'], df['lngDeg_prev'])\n",
    "    df['dist_next'] = calc_haversine(df['latDeg'], df['lngDeg'], df['latDeg_next'], df['lngDeg_next'])\n",
    "    \n",
    "    df.loc[df['phone']!=df['phone_prev'], ['latDeg_prev', 'lngDeg_prev', 'dist_prev']] = np.nan\n",
    "    df.loc[df['phone']!=df['phone_next'], ['latDeg_next', 'lngDeg_next', 'dist_next']] = np.nan\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "indian-tonight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reject outlier\n",
    "train = add_distance_diff(train)\n",
    "train.loc[((train['dist_prev'] > ro_th) & (train['dist_next'] > ro_th)), ['latDeg', 'lngDeg']] = np.nan\n",
    "train.to_csv(OUTPUT + '/train_ro.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-parameter",
   "metadata": {},
   "source": [
    "# ground_truthを基準にした外れ値除去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "allied-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_osmnx_data():\n",
    "    p = pathlib.Path(INPUT)\n",
    "    files = list(p.glob('prep/osmnx/*.csv'))\n",
    "\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        dfs.append(pd.read_csv(file))\n",
    "    osmnx = pd.concat(dfs)\n",
    "\n",
    "    return osmnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "desperate-architect",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_based_on_gt(target_df, target_gt, th):\n",
    "    osmnx_data = get_osmnx_data()\n",
    "    target_gt = target_gt.append(osmnx_data)\n",
    "    \n",
    "    for idx in target_df.index:\n",
    "        lat = target_df.at[idx, 'latDeg']\n",
    "        lng = target_df.at[idx, 'lngDeg']\n",
    "        collection = target_df.at[idx, 'collectionName']\n",
    "        \n",
    "        if np.isnan(lat):\n",
    "            continue\n",
    "        else:\n",
    "            target_gt['latDeg_pred'] = lat\n",
    "            target_gt['lngDeg_pred'] = lng\n",
    "            target_gt['dist'] = calc_haversine(target_gt['latDeg'], target_gt['lngDeg'], target_gt['latDeg_pred'], target_gt['lngDeg_pred'])\n",
    "            closest_dist = target_gt['dist'].min()\n",
    "            if closest_dist > th:\n",
    "                target_df.at[idx, 'latDeg'] = np.nan\n",
    "                target_df.at[idx, 'lngDeg'] = np.nan\n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "killing-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_remove_point(df):\n",
    "    out_df = pd.DataFrame()\n",
    "    collections = df['collectionName'].unique()\n",
    "    \n",
    "    for collection in collections:\n",
    "        tmp = df[df['collectionName']==collection].copy()\n",
    "        tmp = tmp.sort_values('millisSinceGpsEpoch')\n",
    "        tmp = tmp.reset_index().set_index('millisSinceGpsEpoch')\n",
    "        tmp[['latDeg', 'lngDeg']] = tmp[['latDeg', 'lngDeg']].interpolate(method='index', limit_area='inside')\n",
    "        tmp = tmp.sort_values('index')\n",
    "        tmp = tmp.reset_index().set_index('index')\n",
    "        out_df = out_df.append(tmp)\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "chicken-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "rog_df = train[train['collectionName'].isin(rog_target)].copy()\n",
    "rog_gt = gt[gt['collectionName'].isin(rog_target)].copy()\n",
    "rog_df = remove_based_on_gt(rog_df, rog_gt, rog_th)\n",
    "rog_df = interpolate_remove_point(rog_df)\n",
    "train.loc[rog_df.index, ['latDeg', 'lngDeg']] = rog_df[['latDeg', 'lngDeg']]\n",
    "train.to_csv(OUTPUT + '/train_ro_rog.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-consumer",
   "metadata": {},
   "source": [
    "# kalmanフィルタ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "surprising-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1.0\n",
    "state_transition = np.array([[1, 0, T, 0, 0.5 * T ** 2, 0], [0, 1, 0, T, 0, 0.5 * T ** 2], [0, 0, 1, 0, T, 0],\n",
    "                             [0, 0, 0, 1, 0, T], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1]])\n",
    "process_noise = np.diag([1e-5, 1e-5, 5e-6, 5e-6, 1e-6, 1e-6]) + np.ones((6, 6)) * 1e-9\n",
    "observation_model = np.array([[1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0]])\n",
    "observation_noise = np.diag([5e-5, 5e-5]) + np.ones((2, 2)) * 1e-9\n",
    "\n",
    "kf = simdkalman.KalmanFilter(\n",
    "        state_transition = state_transition,\n",
    "        process_noise = process_noise,\n",
    "        observation_model = observation_model,\n",
    "        observation_noise = observation_noise)\n",
    "\n",
    "def apply_kf_smoothing(df, kf_=kf):\n",
    "    unique_paths = df[['collectionName', 'phoneName']].drop_duplicates().to_numpy()\n",
    "    for collection, phone in unique_paths:\n",
    "        cond = np.logical_and(df['collectionName'] == collection, df['phoneName'] == phone)\n",
    "        data = df[cond][['latDeg', 'lngDeg']].to_numpy()\n",
    "        data = data.reshape(1, len(data), 2)\n",
    "        smoothed = kf_.smooth(data)\n",
    "        df.loc[cond, 'latDeg'] = smoothed.states.mean[0, :, 0]\n",
    "        df.loc[cond, 'lngDeg'] = smoothed.states.mean[0, :, 1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "female-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = apply_kf_smoothing(train)\n",
    "train.to_csv(OUTPUT + '/train_ro_rog_kf.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-paragraph",
   "metadata": {},
   "source": [
    "# speed0の処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "victorian-induction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp0_process(df, sp0_result):\n",
    "    df = df.merge(sp0_result, on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n",
    "    df['phone'] = df['collectionName'] + '_' + df['phoneName']\n",
    "    df['group'] = df.groupby('phone').cumcount()\n",
    "    df.loc[(df['group']>0)&(df['isSpeed0']==1),'group'] = np.nan\n",
    "    df['group'] = df['group'].fillna(method='ffill')\n",
    "    df[['latDeg', 'lngDeg']] = df.groupby(['phone', 'group'])[['latDeg','lngDeg']].transform('mean')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "friendly-holder",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sp0_pred = pd.read_csv(sp0_dir + '/train_sp0_pred.csv')\n",
    "train = sp0_process(train, train_sp0_pred)\n",
    "train.to_csv(OUTPUT + '/train_ro_rog_kf_sp0.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-eagle",
   "metadata": {},
   "source": [
    "# phones_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "interim-moisture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lerp_data(df):\n",
    "    '''\n",
    "    Generate interpolated lat,lng values for different phone times in the same collection.\n",
    "    '''\n",
    "    org_columns = df.columns\n",
    "    \n",
    "    # Generate a combination of time x collection x phone and combine it with the original data (generate records to be interpolated)\n",
    "    time_list = df[['collectionName', 'millisSinceGpsEpoch']].drop_duplicates()\n",
    "    phone_list =df[['collectionName', 'phoneName']].drop_duplicates()\n",
    "    tmp = time_list.merge(phone_list, on='collectionName', how='outer')\n",
    "    \n",
    "    lerp_df = tmp.merge(df, on=['collectionName', 'millisSinceGpsEpoch', 'phoneName'], how='left')\n",
    "    lerp_df['phone'] = lerp_df['collectionName'] + '_' + lerp_df['phoneName']\n",
    "    lerp_df = lerp_df.sort_values(['phone', 'millisSinceGpsEpoch'])\n",
    "    \n",
    "    # linear interpolation\n",
    "    lerp_df['latDeg_prev'] = lerp_df['latDeg'].shift(1)\n",
    "    lerp_df['latDeg_next'] = lerp_df['latDeg'].shift(-1)\n",
    "    lerp_df['lngDeg_prev'] = lerp_df['lngDeg'].shift(1)\n",
    "    lerp_df['lngDeg_next'] = lerp_df['lngDeg'].shift(-1)\n",
    "    lerp_df['phone_prev'] = lerp_df['phone'].shift(1)\n",
    "    lerp_df['phone_next'] = lerp_df['phone'].shift(-1)\n",
    "    lerp_df['time_prev'] = lerp_df['millisSinceGpsEpoch'].shift(1)\n",
    "    lerp_df['time_next'] = lerp_df['millisSinceGpsEpoch'].shift(-1)\n",
    "    # Leave only records to be interpolated\n",
    "    lerp_df = lerp_df[(lerp_df['latDeg'].isnull())&(lerp_df['phone']==lerp_df['phone_prev'])&(lerp_df['phone']==lerp_df['phone_next'])].copy()\n",
    "    # calc lerp\n",
    "    lerp_df['latDeg'] = lerp_df['latDeg_prev'] + ((lerp_df['latDeg_next'] - lerp_df['latDeg_prev']) * ((lerp_df['millisSinceGpsEpoch'] - lerp_df['time_prev']) / (lerp_df['time_next'] - lerp_df['time_prev']))) \n",
    "    lerp_df['lngDeg'] = lerp_df['lngDeg_prev'] + ((lerp_df['lngDeg_next'] - lerp_df['lngDeg_prev']) * ((lerp_df['millisSinceGpsEpoch'] - lerp_df['time_prev']) / (lerp_df['time_next'] - lerp_df['time_prev']))) \n",
    "    \n",
    "    # Leave only the data that has a complete set of previous and next data.\n",
    "    lerp_df = lerp_df[~lerp_df['latDeg'].isnull()]\n",
    "    \n",
    "    return lerp_df[org_columns]\n",
    "\n",
    "def calc_mean_pred(df, lerp_df):\n",
    "    '''\n",
    "    Make a prediction based on the average of the predictions of phones in the same collection.\n",
    "    '''\n",
    "    add_lerp = pd.concat([df, lerp_df])\n",
    "    mean_pred_result = add_lerp.groupby(['collectionName', 'millisSinceGpsEpoch'])[['latDeg', 'lngDeg']].mean().reset_index()\n",
    "    mean_pred_df = df[['collectionName', 'phoneName', 'millisSinceGpsEpoch']].copy()\n",
    "    mean_pred_df = mean_pred_df.merge(mean_pred_result[['collectionName', 'millisSinceGpsEpoch', 'latDeg', 'lngDeg']], on=['collectionName', 'millisSinceGpsEpoch'], how='left')\n",
    "    return mean_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "integral-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lerp = make_lerp_data(train)\n",
    "train = calc_mean_pred(train, train_lerp)\n",
    "train.to_csv(OUTPUT + '/train_ro_rog_kf_sp0_pm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-representative",
   "metadata": {},
   "source": [
    "# position_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "deadly-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['phone'] = train['collectionName'] + '_' + train['phoneName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "herbal-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WGS84_to_ECEF(lat, lon, alt):\n",
    "    # convert to radians\n",
    "    rad_lat = lat * (np.pi / 180.0)\n",
    "    rad_lon = lon * (np.pi / 180.0)\n",
    "    a    = 6378137.0\n",
    "    # f is the flattening factor\n",
    "    finv = 298.257223563\n",
    "    f = 1 / finv   \n",
    "    # e is the eccentricity\n",
    "    e2 = 1 - (1 - f) * (1 - f)    \n",
    "    # N is the radius of curvature in the prime vertical\n",
    "    N = a / np.sqrt(1 - e2 * np.sin(rad_lat) * np.sin(rad_lat))\n",
    "    x = (N + alt) * np.cos(rad_lat) * np.cos(rad_lon)\n",
    "    y = (N + alt) * np.cos(rad_lat) * np.sin(rad_lon)\n",
    "    z = (N * (1 - e2) + alt)        * np.sin(rad_lat)\n",
    "    return x, y, z\n",
    "\n",
    "transformer = pyproj.Transformer.from_crs(\n",
    "    {\"proj\":'geocent', \"ellps\":'WGS84', \"datum\":'WGS84'},\n",
    "    {\"proj\":'latlong', \"ellps\":'WGS84', \"datum\":'WGS84'},)\n",
    "\n",
    "def ECEF_to_WGS84(x,y,z):\n",
    "    lon, lat, alt = transformer.transform(x,y,z,radians=False)\n",
    "    return lon, lat, alt\n",
    "msge = 'millisSinceGpsEpoch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "coated-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_shift(df,a):\n",
    "\n",
    "    d = df.copy()\n",
    "    d['heightAboveWgs84EllipsoidM'] = 63.5\n",
    "    d['x'], d['y'], d['z'] = zip(*d.apply(lambda x: WGS84_to_ECEF(x.latDeg, x.lngDeg, x.heightAboveWgs84EllipsoidM), axis=1))\n",
    "\n",
    "    #a = -0.2\n",
    "    d.sort_values(['phone', msge], inplace=True)\n",
    "    for fi in ['x','y','z']:\n",
    "        d[[fi+'p']] = d[fi].shift().where(d['phone'].eq(d['phone'].shift()))\n",
    "        d[[fi+'diff']] = d[fi]-d[fi+'p']\n",
    "    #d[['yp']] = d['y'].shift().where(d['phone'].eq(d['phone'].shift()))\n",
    "    d[['dist']] = np.sqrt(d['xdiff']**2 + d['ydiff']**2+ d['zdiff']**2)\n",
    "    for fi in ['x','y','z']:\n",
    "        d[[fi+'new']] = d[fi+'p'] + d[fi+'diff']*(1-a/d['dist'])\n",
    "    lng, lat, alt = ECEF_to_WGS84(d['xnew'].values,d['ynew'].values,d['znew'].values)\n",
    "    \n",
    "    lng[np.isnan(lng)] = d.loc[np.isnan(lng),'lngDeg']\n",
    "    lat[np.isnan(lat)] = d.loc[np.isnan(lat),'latDeg']\n",
    "    d['latDeg'] = lat\n",
    "    d['lngDeg'] = lng\n",
    "    \n",
    "    return d \n",
    "\n",
    "def objective(trial):\n",
    "    a = trial.suggest_uniform('a', -1, 1)\n",
    "    score = get_train_score(position_shift(train, a),gt)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "meaning-latino",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-10 11:49:29,085]\u001b[0m A new study created in memory with name: no-name-a4413e57-d9b3-4e91-8fa6-d0eef7206916\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:29,445]\u001b[0m Trial 0 finished with value: 5.163754685389727 and parameters: {'a': 0.8933836967438302}. Best is trial 0 with value: 5.163754685389727.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:29,803]\u001b[0m Trial 1 finished with value: 5.683353597836895 and parameters: {'a': -0.85992642840241}. Best is trial 0 with value: 5.163754685389727.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:30,159]\u001b[0m Trial 2 finished with value: 5.283329666822132 and parameters: {'a': 0.32578491660493913}. Best is trial 0 with value: 5.163754685389727.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:30,621]\u001b[0m Trial 3 finished with value: 5.715824329312665 and parameters: {'a': -0.9483747150206154}. Best is trial 0 with value: 5.163754685389727.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:30,968]\u001b[0m Trial 4 finished with value: 5.405631783462361 and parameters: {'a': -0.11766569262781945}. Best is trial 0 with value: 5.163754685389727.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:31,313]\u001b[0m Trial 5 finished with value: 5.233776885319705 and parameters: {'a': 0.5647965859229731}. Best is trial 0 with value: 5.163754685389727.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:31,659]\u001b[0m Trial 6 finished with value: 5.4780028623500305 and parameters: {'a': -0.3243360128361721}. Best is trial 0 with value: 5.163754685389727.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:32,006]\u001b[0m Trial 7 finished with value: 5.602313615481678 and parameters: {'a': -0.6500508809817527}. Best is trial 0 with value: 5.163754685389727.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:32,352]\u001b[0m Trial 8 finished with value: 5.319578906924975 and parameters: {'a': 0.15336503646093025}. Best is trial 0 with value: 5.163754685389727.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:32,697]\u001b[0m Trial 9 finished with value: 5.1978364312017264 and parameters: {'a': 0.741312101687033}. Best is trial 0 with value: 5.163754685389727.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:33,187]\u001b[0m Trial 10 finished with value: 5.1523617568349005 and parameters: {'a': 0.9781004409640822}. Best is trial 10 with value: 5.1523617568349005.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:33,535]\u001b[0m Trial 11 finished with value: 5.151496590802377 and parameters: {'a': 0.9826008322384144}. Best is trial 11 with value: 5.151496590802377.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:33,880]\u001b[0m Trial 12 finished with value: 5.154162120810221 and parameters: {'a': 0.9668158967465317}. Best is trial 11 with value: 5.151496590802377.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:34,223]\u001b[0m Trial 13 finished with value: 5.234520183479788 and parameters: {'a': 0.560338597390709}. Best is trial 11 with value: 5.151496590802377.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:34,569]\u001b[0m Trial 14 finished with value: 5.203561850324301 and parameters: {'a': 0.7008519115280876}. Best is trial 11 with value: 5.151496590802377.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:34,915]\u001b[0m Trial 15 finished with value: 5.1523683186568805 and parameters: {'a': 0.9780678664832212}. Best is trial 11 with value: 5.151496590802377.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:35,266]\u001b[0m Trial 16 finished with value: 5.271601106106644 and parameters: {'a': 0.38294886684014195}. Best is trial 11 with value: 5.151496590802377.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:35,714]\u001b[0m Trial 17 finished with value: 5.161316534098351 and parameters: {'a': 0.9241917244431825}. Best is trial 11 with value: 5.151496590802377.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:36,094]\u001b[0m Trial 18 finished with value: 5.418591406038651 and parameters: {'a': -0.15302707369435437}. Best is trial 11 with value: 5.151496590802377.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:36,455]\u001b[0m Trial 19 finished with value: 5.317957434727376 and parameters: {'a': 0.16058074247389498}. Best is trial 11 with value: 5.151496590802377.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:36,849]\u001b[0m Trial 20 finished with value: 5.206085421963669 and parameters: {'a': 0.6853384035399523}. Best is trial 11 with value: 5.151496590802377.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:37,225]\u001b[0m Trial 21 finished with value: 5.153656205766175 and parameters: {'a': 0.9716885536708002}. Best is trial 11 with value: 5.151496590802377.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:37,572]\u001b[0m Trial 22 finished with value: 5.148574101916911 and parameters: {'a': 0.9957420771655919}. Best is trial 22 with value: 5.148574101916911.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:38,040]\u001b[0m Trial 23 finished with value: 5.180754706862589 and parameters: {'a': 0.8066750605447603}. Best is trial 22 with value: 5.148574101916911.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:38,393]\u001b[0m Trial 24 finished with value: 5.238841135426579 and parameters: {'a': 0.5370025897152626}. Best is trial 22 with value: 5.148574101916911.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:38,762]\u001b[0m Trial 25 finished with value: 5.149642051438922 and parameters: {'a': 0.9913210710562681}. Best is trial 22 with value: 5.148574101916911.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:39,105]\u001b[0m Trial 26 finished with value: 5.181370224472478 and parameters: {'a': 0.8046057909649974}. Best is trial 22 with value: 5.148574101916911.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:39,452]\u001b[0m Trial 27 finished with value: 5.527049050616398 and parameters: {'a': -0.4556832605822852}. Best is trial 22 with value: 5.148574101916911.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:39,796]\u001b[0m Trial 28 finished with value: 5.260433007202381 and parameters: {'a': 0.4424578846474166}. Best is trial 22 with value: 5.148574101916911.\u001b[0m\n",
      "\u001b[32m[I 2021-07-10 11:49:40,142]\u001b[0m Trial 29 finished with value: 5.172377854487876 and parameters: {'a': 0.8439755019246851}. Best is trial 22 with value: 5.148574101916911.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9957420771655919\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=30)\n",
    "opt_a = study.best_params['a']\n",
    "print(opt_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "excellent-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = position_shift(train, opt_a)\n",
    "train.to_csv(OUTPUT + f'/{nb_name}_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-compilation",
   "metadata": {},
   "source": [
    "# trainの結果確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "specific-cyprus",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = train_result(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "charged-germany",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.148574101916911"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "contemporary-share",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percentile50</th>\n",
       "      <th>percentile95</th>\n",
       "      <th>p50_p90_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phone</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-04-28-US-MTV-1_Pixel4</th>\n",
       "      <td>1.785767</td>\n",
       "      <td>5.298627</td>\n",
       "      <td>3.542197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-28-US-MTV-1_Pixel5</th>\n",
       "      <td>1.557713</td>\n",
       "      <td>3.163401</td>\n",
       "      <td>2.360557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-28-US-MTV-1_SamsungS20Ultra</th>\n",
       "      <td>3.218219</td>\n",
       "      <td>5.812820</td>\n",
       "      <td>4.515520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-29-US-MTV-1_Pixel4</th>\n",
       "      <td>4.436486</td>\n",
       "      <td>8.291618</td>\n",
       "      <td>6.364052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-29-US-MTV-1_Pixel5</th>\n",
       "      <td>3.778874</td>\n",
       "      <td>7.520886</td>\n",
       "      <td>5.649880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-29-US-MTV-1_SamsungS20Ultra</th>\n",
       "      <td>6.098795</td>\n",
       "      <td>10.819682</td>\n",
       "      <td>8.459239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     percentile50  percentile95  p50_p90_mean\n",
       "phone                                                                        \n",
       "2021-04-28-US-MTV-1_Pixel4               1.785767      5.298627      3.542197\n",
       "2021-04-28-US-MTV-1_Pixel5               1.557713      3.163401      2.360557\n",
       "2021-04-28-US-MTV-1_SamsungS20Ultra      3.218219      5.812820      4.515520\n",
       "2021-04-29-US-MTV-1_Pixel4               4.436486      8.291618      6.364052\n",
       "2021-04-29-US-MTV-1_Pixel5               3.778874      7.520886      5.649880\n",
       "2021-04-29-US-MTV-1_SamsungS20Ultra      6.098795     10.819682      8.459239"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-thanks",
   "metadata": {},
   "source": [
    "# make_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "helpful-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(INPUT + '/' + 'baseline_locations_test.csv')\n",
    "test = test[test['collectionName'].isin(target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "electrical-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = add_distance_diff(test)\n",
    "test.loc[((test['dist_prev'] > ro_th) & (test['dist_next'] > ro_th)), ['latDeg', 'lngDeg']] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "graphic-patio",
   "metadata": {},
   "outputs": [],
   "source": [
    "rog_df = test[test['collectionName'].isin(rog_target)].copy()\n",
    "rog_gt = gt[gt['collectionName'].isin(rog_target)].copy()\n",
    "rog_df = remove_based_on_gt(rog_df, rog_gt, rog_th)\n",
    "rog_df.to_csv(OUTPUT + '/test_rog.csv', index=False)\n",
    "rog_df = interpolate_remove_point(rog_df)\n",
    "test.loc[rog_df.index, ['latDeg', 'lngDeg']] = rog_df[['latDeg', 'lngDeg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "another-venezuela",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = apply_kf_smoothing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "noticed-atlas",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sp0_pred = pd.read_csv(sp0_dir + '/test_sp0_pred.csv')\n",
    "test = sp0_process(test, test_sp0_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "modular-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lerp = make_lerp_data(test)\n",
    "test = calc_mean_pred(test, test_lerp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "twenty-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['phone'] = test['collectionName'] + '_' + test['phoneName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "palestinian-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = position_shift(test, opt_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "therapeutic-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[['phone', 'millisSinceGpsEpoch', 'latDeg', 'lngDeg']].copy()\n",
    "test.to_csv(OUTPUT + f'/{nb_name}_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "consecutive-dutch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone</th>\n",
       "      <th>millisSinceGpsEpoch</th>\n",
       "      <th>latDeg</th>\n",
       "      <th>lngDeg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-16-US-RWC-2_Pixel4XL</td>\n",
       "      <td>1299971492657</td>\n",
       "      <td>37.395001</td>\n",
       "      <td>-122.101713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-16-US-RWC-2_Pixel4XL</td>\n",
       "      <td>1299971493646</td>\n",
       "      <td>37.395001</td>\n",
       "      <td>-122.101713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-16-US-RWC-2_Pixel4XL</td>\n",
       "      <td>1299971494662</td>\n",
       "      <td>37.395001</td>\n",
       "      <td>-122.101713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-16-US-RWC-2_Pixel4XL</td>\n",
       "      <td>1299971495652</td>\n",
       "      <td>37.395001</td>\n",
       "      <td>-122.101713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-16-US-RWC-2_Pixel4XL</td>\n",
       "      <td>1299971496643</td>\n",
       "      <td>37.395001</td>\n",
       "      <td>-122.101713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17541</th>\n",
       "      <td>2021-04-29-US-MTV-2_SamsungS20Ultra</td>\n",
       "      <td>1303772667000</td>\n",
       "      <td>37.395825</td>\n",
       "      <td>-122.102996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17542</th>\n",
       "      <td>2021-04-29-US-MTV-2_SamsungS20Ultra</td>\n",
       "      <td>1303772668000</td>\n",
       "      <td>37.395825</td>\n",
       "      <td>-122.102996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17543</th>\n",
       "      <td>2021-04-29-US-MTV-2_SamsungS20Ultra</td>\n",
       "      <td>1303772669000</td>\n",
       "      <td>37.395825</td>\n",
       "      <td>-122.102996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17544</th>\n",
       "      <td>2021-04-29-US-MTV-2_SamsungS20Ultra</td>\n",
       "      <td>1303772670000</td>\n",
       "      <td>37.395825</td>\n",
       "      <td>-122.102996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17545</th>\n",
       "      <td>2021-04-29-US-MTV-2_SamsungS20Ultra</td>\n",
       "      <td>1303772671000</td>\n",
       "      <td>37.395825</td>\n",
       "      <td>-122.102996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17546 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     phone  millisSinceGpsEpoch     latDeg  \\\n",
       "0             2021-03-16-US-RWC-2_Pixel4XL        1299971492657  37.395001   \n",
       "1             2021-03-16-US-RWC-2_Pixel4XL        1299971493646  37.395001   \n",
       "2             2021-03-16-US-RWC-2_Pixel4XL        1299971494662  37.395001   \n",
       "3             2021-03-16-US-RWC-2_Pixel4XL        1299971495652  37.395001   \n",
       "4             2021-03-16-US-RWC-2_Pixel4XL        1299971496643  37.395001   \n",
       "...                                    ...                  ...        ...   \n",
       "17541  2021-04-29-US-MTV-2_SamsungS20Ultra        1303772667000  37.395825   \n",
       "17542  2021-04-29-US-MTV-2_SamsungS20Ultra        1303772668000  37.395825   \n",
       "17543  2021-04-29-US-MTV-2_SamsungS20Ultra        1303772669000  37.395825   \n",
       "17544  2021-04-29-US-MTV-2_SamsungS20Ultra        1303772670000  37.395825   \n",
       "17545  2021-04-29-US-MTV-2_SamsungS20Ultra        1303772671000  37.395825   \n",
       "\n",
       "           lngDeg  \n",
       "0     -122.101713  \n",
       "1     -122.101713  \n",
       "2     -122.101713  \n",
       "3     -122.101713  \n",
       "4     -122.101713  \n",
       "...           ...  \n",
       "17541 -122.102996  \n",
       "17542 -122.102996  \n",
       "17543 -122.102996  \n",
       "17544 -122.102996  \n",
       "17545 -122.102996  \n",
       "\n",
       "[17546 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
