{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "activated-backing",
   "metadata": {},
   "source": [
    "# exp119_rb_tune_g3\n",
    "baseline再構成チューニングの検討 group5  \n",
    "rawPrUncMでのフィルタリング  \n",
    "キャリアスムージング  \n",
    "衛星閾値も対象に"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "automotive-berlin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import library\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import pathlib\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import itertools\n",
    "import lightgbm as lgb\n",
    "from optuna.integration import lightgbm as optuna_lgb\n",
    "import simdkalman\n",
    "import optuna\n",
    "import pyproj\n",
    "from pyproj import Proj, transform\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, confusion_matrix, accuracy_score\n",
    "pd.set_option('display.max_rows', 100)\n",
    "from math import * \n",
    "import scipy.optimize as opt\n",
    "import multiprocessing\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "graphic-breakdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = ['2020-05-14-US-MTV-1', '2020-05-14-US-MTV-2', '2020-05-21-US-MTV-1', '2020-05-21-US-MTV-2',\n",
    "      '2020-05-29-US-MTV-1', '2020-05-29-US-MTV-2', '2020-06-04-US-MTV-1', '2020-06-05-US-MTV-1',\n",
    "      '2020-06-05-US-MTV-2', '2020-06-11-US-MTV-1', '2020-07-08-US-MTV-1', '2020-07-17-US-MTV-1',\n",
    "      '2020-07-17-US-MTV-2', '2020-08-03-US-MTV-1', '2020-08-06-US-MTV-2', '2020-09-04-US-SF-1',\n",
    "      '2020-09-04-US-SF-2',  '2021-01-04-US-RWC-1', '2021-01-04-US-RWC-2',\n",
    "      '2020-05-15-US-MTV-1', '2020-05-28-US-MTV-1', '2020-05-28-US-MTV-2', '2020-06-04-US-MTV-2',\n",
    "      '2020-06-10-US-MTV-1', '2020-06-10-US-MTV-2', '2020-08-03-US-MTV-2', '2020-08-13-US-MTV-1',\n",
    "      '2021-03-16-US-MTV-2']\n",
    "\n",
    "g2 = ['2021-01-05-US-SVL-1', '2021-01-05-US-SVL-2', '2021-04-15-US-MTV-1', \n",
    "      '2021-03-25-US-PAO-1', '2021-04-02-US-SJC-1', '2021-04-08-US-MTV-1']\n",
    "\n",
    "g3 = ['2021-03-10-US-SVL-1', '2021-04-26-US-SVL-1', '2021-04-26-US-SVL-2']\n",
    "\n",
    "g4 = ['2021-04-28-US-MTV-1', '2021-04-29-US-MTV-1', \n",
    "      '2021-03-16-US-RWC-2', '2021-04-21-US-MTV-1', '2021-04-28-US-MTV-2', '2021-04-29-US-MTV-2']\n",
    "\n",
    "g5 = ['2021-04-22-US-SJC-1', '2021-04-28-US-SJC-1', '2021-04-29-US-SJC-2', \n",
    "      '2021-04-22-US-SJC-2', '2021-04-29-US-SJC-3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "interesting-dinner",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = g3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "objective-invite",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb_path\n",
    "\n",
    "def get_nb_name():\n",
    "    nb_path = ipynb_path.get()\n",
    "    nb_name = nb_path.rsplit('/',1)[1].replace('.ipynb','')\n",
    "    return nb_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "distributed-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory setting\n",
    "nb_name = get_nb_name()\n",
    "INPUT = '../input/google-smartphone-decimeter-challenge'\n",
    "OUTPUT = '../output/' + nb_name\n",
    "os.makedirs(OUTPUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-hollywood",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "operational-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_score(df, gt):\n",
    "    gt = gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n",
    "    df = df.merge(gt, on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n",
    "    # calc_distance_error\n",
    "    df['err'] = calc_haversine(df['latDeg_gt'], df['lngDeg_gt'], df['latDeg'], df['lngDeg'])\n",
    "    # calc_evaluate_score\n",
    "    df['phone'] = df['collectionName'] + '_' + df['phoneName']\n",
    "    res = df.groupby('phone')['err'].agg([percentile50, percentile95])\n",
    "    res['p50_p90_mean'] = (res['percentile50'] + res['percentile95']) / 2 \n",
    "    score = res['p50_p90_mean'].mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "harmful-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculates the great circle distance between two points\n",
    "    on the earth. Inputs are array-like and specified in decimal degrees.\n",
    "    \"\"\"\n",
    "    RADIUS = 6_367_000\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + \\\n",
    "        np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    dist = 2 * RADIUS * np.arcsin(a**0.5)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "reserved-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_trafic(df, center, zoom=9):\n",
    "    fig = px.scatter_mapbox(df,\n",
    "                            \n",
    "                            # Here, plotly gets, (x,y) coordinates\n",
    "                            lat=\"latDeg\",\n",
    "                            lon=\"lngDeg\",\n",
    "                            \n",
    "                            #Here, plotly detects color of series\n",
    "                            color=\"phoneName\",\n",
    "                            labels=\"phoneName\",\n",
    "                            \n",
    "                            zoom=zoom,\n",
    "                            center=center,\n",
    "                            height=600,\n",
    "                            width=800)\n",
    "    fig.update_layout(mapbox_style='stamen-terrain')\n",
    "    fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
    "    fig.update_layout(title_text=\"GPS trafic\")\n",
    "    fig.show()\n",
    "    \n",
    "def visualize_collection(df, collection):\n",
    "    target_df = df[df['collectionName']==collection].copy()\n",
    "    lat_center = target_df['latDeg'].mean()\n",
    "    lng_center = target_df['lngDeg'].mean()\n",
    "    center = {\"lat\":lat_center, \"lon\":lng_center}\n",
    "    \n",
    "    visualize_trafic(target_df, center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "interstate-mentor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_truth\n",
    "def get_ground_truth():\n",
    "    p = pathlib.Path(INPUT)\n",
    "    gt_files = list(p.glob('train/*/*/ground_truth.csv'))\n",
    "\n",
    "    gts = []\n",
    "    for gt_file in gt_files:\n",
    "        gts.append(pd.read_csv(gt_file))\n",
    "    ground_truth = pd.concat(gts)\n",
    "\n",
    "    return ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "excited-republican",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile50(x):\n",
    "    return np.percentile(x, 50)\n",
    "def percentile95(x):\n",
    "    return np.percentile(x, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "surprised-woman",
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_result:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.gt = get_ground_truth()\n",
    "        self.bl = pd.read_csv(INPUT + '/' + 'baseline_locations_train.csv')\n",
    "        \n",
    "        self.gt = self.gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n",
    "        self.df = self.df.merge(self.gt, on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n",
    "        self.df['phone'] = self.df['collectionName'] + '_' + self.df['phoneName']\n",
    "        self.df['err'] =  calc_haversine(self.df['latDeg_gt'], self.df['lngDeg_gt'], self.df['latDeg'], self.df['lngDeg'])\n",
    "        \n",
    "        self.phone_res = self.calc_err('phone')\n",
    "        self.clc_res = self.calc_err('collectionName')\n",
    "        self.phonename_res = self.calc_err('phoneName')\n",
    "        \n",
    "    def calc_err(self, by):\n",
    "        res = self.df.groupby(by)['err'].agg([percentile50, percentile95])\n",
    "        res['p50_p90_mean'] = (res['percentile50'] + res['percentile95']) / 2\n",
    "        return res\n",
    "    \n",
    "    @property\n",
    "    def score(self):\n",
    "        return self.phone_res['p50_p90_mean'].mean()\n",
    "    @property\n",
    "    def raw_data(self):\n",
    "        return self.df\n",
    "    @property\n",
    "    def err(self):\n",
    "        return self.phone_res\n",
    "    @property\n",
    "    def collection_err(self):\n",
    "        return self.clc_res\n",
    "    @property\n",
    "    def phonename_err(self):\n",
    "        return self.phonename_res\n",
    "    \n",
    "    def viz_map(self, collection, show_gt=True, show_bl=True):\n",
    "        tmp = self.df[self.df['collectionName']==collection][['collectionName', 'phoneName', 'latDeg', 'lngDeg']]\n",
    "        tmp2 = self.df[self.df['collectionName']==collection][['collectionName', 'phoneName', 'latDeg_gt', 'lngDeg_gt']]\n",
    "        tmp2 = tmp2.rename(columns={'latDeg_gt':'latDeg', 'lngDeg_gt':'lngDeg'})\n",
    "        tmp2['phoneName'] = tmp2['phoneName'] + '_GT'\n",
    "        tmp3 = self.bl[self.bl['collectionName']==collection][['collectionName', 'phoneName', 'latDeg', 'lngDeg']]\n",
    "        tmp3['phoneName'] = tmp3['phoneName'] + '_BL'\n",
    "        \n",
    "        if show_gt:\n",
    "            tmp = tmp.append(tmp2)\n",
    "        if show_bl:\n",
    "            tmp = tmp.append(tmp3)\n",
    "        visualize_collection(tmp, collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "severe-malaysia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    base_train = pd.read_csv(INPUT + '/' + 'baseline_locations_train.csv')\n",
    "    base_test = pd.read_csv(INPUT + '/' + 'baseline_locations_test.csv')\n",
    "    sample_sub = pd.read_csv(INPUT + '/' + 'sample_submission.csv')\n",
    "    ground_truth = pd.read_csv(INPUT + '/prep/ground_truth_train.csv')\n",
    "    return base_train, base_test, sample_sub, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "second-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecef2lla(x, y, z):\n",
    "    # x, y and z are scalars or vectors in meters\n",
    "    x = np.array([x]).reshape(np.array([x]).shape[-1], 1)\n",
    "    y = np.array([y]).reshape(np.array([y]).shape[-1], 1)\n",
    "    z = np.array([z]).reshape(np.array([z]).shape[-1], 1)\n",
    "\n",
    "    a=6378137\n",
    "    a_sq=a**2\n",
    "    e = 8.181919084261345e-2\n",
    "    e_sq = 6.69437999014e-3\n",
    "\n",
    "    f = 1/298.257223563\n",
    "    b = a*(1-f)\n",
    "\n",
    "    # calculations:\n",
    "    r = np.sqrt(x**2 + y**2)\n",
    "    ep_sq  = (a**2-b**2)/b**2\n",
    "    ee = (a**2-b**2)\n",
    "    f = (54*b**2)*(z**2)\n",
    "    g = r**2 + (1 - e_sq)*(z**2) - e_sq*ee*2\n",
    "    c = (e_sq**2)*f*r**2/(g**3)\n",
    "    s = (1 + c + np.sqrt(c**2 + 2*c))**(1/3.)\n",
    "    p = f/(3.*(g**2)*(s + (1./s) + 1)**2)\n",
    "    q = np.sqrt(1 + 2*p*e_sq**2)\n",
    "    r_0 = -(p*e_sq*r)/(1+q) + np.sqrt(0.5*(a**2)*(1+(1./q)) - p*(z**2)*(1-e_sq)/(q*(1+q)) - 0.5*p*(r**2))\n",
    "    u = np.sqrt((r - e_sq*r_0)**2 + z**2)\n",
    "    v = np.sqrt((r - e_sq*r_0)**2 + (1 - e_sq)*z**2)\n",
    "    z_0 = (b**2)*z/(a*v)\n",
    "    h = u*(1 - b**2/(a*v))\n",
    "    phi = np.arctan((z + ep_sq*z_0)/r)\n",
    "    lambd = np.arctan2(y, x)\n",
    "\n",
    "    return phi*180/np.pi, lambd*180/np.pi, h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-serial",
   "metadata": {},
   "source": [
    "# baselineの再作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "chief-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_calc_baseline(df, csr):\n",
    "    light_speed = 299_792_458\n",
    "    omega_e = 7.2921151467e-5\n",
    "    \n",
    "    df['sat'] = df['svid'].astype('str') + '_' + df['signalType']\n",
    "    df['isrbM'] = df.groupby('sat')['isrbM'].transform('median')\n",
    "    \n",
    "    # Corrected pseudorange according to data instructions\n",
    "    df['correctedPrM'] = df['rawPrM'] + \\\n",
    "                         df['satClkBiasM'] - \\\n",
    "                         df['isrbM'] - \\\n",
    "                         df['ionoDelayM'] - \\\n",
    "                         df['tropoDelayM']\n",
    "    \n",
    "    # Time it took for signal to travel\n",
    "    df['transmissionTimeSeconds'] = df['correctedPrM'] / light_speed\n",
    "    \n",
    "    # Compute true sat positions at arrival time\n",
    "    df['xSatPosMRotated'] = \\\n",
    "        np.cos(omega_e * df['transmissionTimeSeconds']) * df['xSatPosM'] \\\n",
    "        + np.sin(omega_e * df['transmissionTimeSeconds']) * df['ySatPosM']\n",
    "\n",
    "    df['ySatPosMRotated'] = \\\n",
    "        - np.sin(omega_e * df['transmissionTimeSeconds']) * df['xSatPosM'] \\\n",
    "        + np.cos(omega_e * df['transmissionTimeSeconds']) * df['ySatPosM']\n",
    "\n",
    "    df['zSatPosMRotated'] = df['zSatPosM']\n",
    "    \n",
    "    # Uncertainty weight for the WLS method\n",
    "    df['uncertaintyWeight'] = 1 / df['rawPrUncM']\n",
    "    \n",
    "    df = carrier_smoothing(df, csr)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "consecutive-diamond",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_baseline_point(df):\n",
    "\n",
    "    def distance(sat_pos, x):\n",
    "        sat_pos_diff = sat_pos.copy(deep=True)\n",
    "\n",
    "        sat_pos_diff['xSatPosMRotated'] = sat_pos_diff['xSatPosMRotated'] - x[0]\n",
    "        sat_pos_diff['ySatPosMRotated'] = sat_pos_diff['ySatPosMRotated'] - x[1]\n",
    "        sat_pos_diff['zSatPosMRotated'] = sat_pos_diff['zSatPosMRotated'] - x[2]\n",
    "\n",
    "        sat_pos_diff['d'] = sat_pos_diff['uncertaintyWeight'] * \\\n",
    "                            (np.sqrt((sat_pos_diff['xSatPosMRotated']**2 + sat_pos_diff['ySatPosMRotated']**2 + sat_pos_diff['zSatPosMRotated']**2)) + \\\n",
    "                             x[3] - sat_pos_diff['correctedPrM'])\n",
    "\n",
    "        return sat_pos_diff['d']\n",
    "\n",
    "    def distance_fixed_satpos(x):\n",
    "        return distance(df[['xSatPosMRotated', 'ySatPosMRotated', 'zSatPosMRotated', 'correctedPrM', 'uncertaintyWeight']], x)\n",
    "    \n",
    "    x0 = [0,0,0,0]\n",
    "    opt_res = opt.least_squares(distance_fixed_satpos, x0)\n",
    "    # Optimiser yields a position in the ECEF coordinates\n",
    "    opt_res_pos = opt_res.x\n",
    "    \n",
    "    # ECEF position to lat/long\n",
    "    wls_estimated_pos = ecef2lla(*opt_res_pos[:3])\n",
    "    wls_estimated_pos = np.squeeze(wls_estimated_pos)\n",
    "    \n",
    "    return wls_estimated_pos[0], wls_estimated_pos[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dirty-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_derived_data(train_test, collection, phonename):\n",
    "    derived = pd.read_csv(INPUT + f'/{train_test}/{collection}/{phonename}/{phonename}_derived.csv')\n",
    "    raw = pd.read_csv(INPUT + f'/prep/gnss/{train_test}/{collection}/{phonename}/Raw.csv')\n",
    "    status = pd.read_csv(INPUT + f'/prep/gnss/{train_test}/{collection}/{phonename}/Status.csv')\n",
    "    \n",
    "    # Assume we've loaded a dataframe from _GnssLog.txt for only lines beginning with \"Raw\", we denote this df_raw. Next, assume we've loaded a dataframe from _derived.csv. We denote this df_derived.\n",
    "\n",
    "    # Create a new column in df_raw that corresponds to df_derived['MillisSinceGpsEpoch']\n",
    "    raw['millisSinceGpsEpoch'] = np.floor( (raw['TimeNanos'] - raw['FullBiasNanos']) / 1000000.0).astype(int)\n",
    "    \n",
    "    # Change each value in df_derived['MillisSinceGpsEpoch'] to be the prior epoch.\n",
    "    raw_timestamps = raw['millisSinceGpsEpoch'].unique()\n",
    "    derived_timestamps = derived['millisSinceGpsEpoch'].unique()\n",
    "\n",
    "    # The timestamps in derived are one epoch ahead. We need to map each epoch\n",
    "    # in derived to the prior one (in Raw).\n",
    "    indexes = np.searchsorted(raw_timestamps, derived_timestamps)\n",
    "    from_t_to_fix_derived = dict(zip(derived_timestamps, raw_timestamps[indexes-1]))\n",
    "    derived['millisSinceGpsEpoch'] = np.array(list(map(lambda v: from_t_to_fix_derived[v], derived['millisSinceGpsEpoch'])))\n",
    "    \n",
    "    delta_millis = derived['millisSinceGpsEpoch'] - derived['receivedSvTimeInGpsNanos'] / 1e6\n",
    "    where_good_signals = (delta_millis > 0) & (delta_millis < 300)\n",
    "    derived = derived[where_good_signals].copy()\n",
    "\n",
    "    # Compute signal_type in df_raw.\n",
    "    # Map from constellation id to frequencies and signals.\n",
    "    CONSTEL_FREQ_TABLE = {\n",
    "        0: {'UNKNOWN': (0, 999999999999)},\n",
    "        1: {\n",
    "            'GPS_L1': (1563000000, 1587000000),\n",
    "            'GPS_L2': (1215000000, 1240000000),\n",
    "            'GPS_L5': (1164000000, 1189000000)\n",
    "        },\n",
    "        3: {\n",
    "            'GLO_G1': (1593000000, 1610000000),\n",
    "            'GLO_G2': (1237000000, 1254000000)\n",
    "        },\n",
    "        4: {\n",
    "            'QZS_J1': (1563000000, 1587000000),\n",
    "            'QZS_J2': (1215000000, 1240000000),\n",
    "            'QZS_J5': (1164000000, 1189000000)\n",
    "        },\n",
    "        5: {\n",
    "            'BDS_B1C': (1569000000, 1583000000),\n",
    "            'BDS_B1I': (1553000000, 1568990000),\n",
    "            'BDS_B2A': (1164000000, 1189000000),\n",
    "            'BDS_B2B': (1189000000, 1225000000)\n",
    "        },\n",
    "        6: {\n",
    "            'GAL_E1': (1559000000, 1591000000),\n",
    "            'GAL_E5A': (1164000000, 1189000000),\n",
    "            'GAL_E5B': (1189000000, 1218000000),\n",
    "            'GAL_E6': (1258000000, 1300000000)\n",
    "        },\n",
    "        7: {\n",
    "            'IRN_S': (2472000000, 2512000000),\n",
    "            'IRN_L5': (1164000000, 1189000000)\n",
    "        },\n",
    "    }\n",
    "\n",
    "    def SignalTypeFromConstellationAndFequency(constel, freq_hz):\n",
    "        'Returns the signal type as a string for the given constellation and frequency.'\n",
    "        freqs = CONSTEL_FREQ_TABLE.get(constel, {})\n",
    "        for id_freq_range in freqs.items():\n",
    "            rng = id_freq_range[1]\n",
    "            if rng[0] <= freq_hz <= rng[1]:\n",
    "                return id_freq_range[0]\n",
    "        return 'UNKNOWN'\n",
    "\n",
    "    signal_types = itertools.chain(*[c.keys() for c in CONSTEL_FREQ_TABLE.values()])\n",
    "    sig_type_cat = pd.api.types.CategoricalDtype(categories=signal_types)\n",
    "    raw['signalType'] = raw.apply(lambda r: SignalTypeFromConstellationAndFequency(r.ConstellationType, r.CarrierFrequencyHz), axis=1).astype(sig_type_cat)\n",
    "\n",
    "    # Fix QZS Svids issue. \n",
    "\n",
    "    # The SVID of any QZS sat in derived may be changed. Since it may be a many to one relationship, we'll need to adjust the values in Raw.\n",
    "    new_to_old = {1:(183, 193), 2:(184, 194, 196), 3:(187, 189, 197, 199), 4:(185, 195, 200)}\n",
    "    # Maps original svid to new svid for only ConstellationType=4.\n",
    "    old_to_new={}\n",
    "    for new_svid, old_svids in new_to_old.items():\n",
    "        for s in old_svids:\n",
    "            old_to_new[s] = new_svid\n",
    "    raw['svid'] = raw.apply(lambda r: old_to_new.get(r.Svid, r.Svid) if r.ConstellationType == 4 else r.Svid, axis=1)\n",
    "    del raw['collectionName']\n",
    "    del raw['phoneName']\n",
    "    \n",
    "    derived = derived.merge(raw, on=['millisSinceGpsEpoch', 'svid', 'signalType'], how='left')\n",
    "    \n",
    "    # status\n",
    "    status['millisSinceGpsEpoch'] = status['UnixTimeMillis'] - 315964800000 + 18000\n",
    "    status['svid'] = status.apply(lambda r: old_to_new.get(r.Svid, r.Svid) if r.ConstellationType == 4 else r.Svid, axis=1)\n",
    "    status['signalType'] = status.apply(lambda r: SignalTypeFromConstellationAndFequency(r.ConstellationType, r.CarrierFrequencyHz), axis=1).astype(sig_type_cat)\n",
    "    del status['collectionName']\n",
    "    del status['phoneName']\n",
    "    del status['Cn0DbHz']\n",
    "    status = status.drop_duplicates(subset=['svid', 'signalType', 'millisSinceGpsEpoch'])\n",
    "    \n",
    "    sv_sig = derived[['svid', 'signalType']].drop_duplicates()\n",
    "    output_df = pd.DataFrame()\n",
    "    for svid, signal in zip(sv_sig['svid'], sv_sig['signalType']):\n",
    "        derived_tmp = derived[(derived['svid']==svid)&(derived['signalType']==signal)].copy()\n",
    "        status_tmp = status[(status['svid']==svid)&(status['signalType']==signal)].copy()\n",
    "        del status_tmp['svid']\n",
    "        del status_tmp['signalType']\n",
    "        output_tmp = pd.merge_asof(derived_tmp, status_tmp, on='millisSinceGpsEpoch', direction='nearest')\n",
    "        output_df = output_df.append(output_tmp)\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "focal-gather",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_baseline(args):\n",
    "    s_th = 10\n",
    "    \n",
    "    phone, df, elev_deg, used_in_fix, rawpruncm, csr, nth = args\n",
    "    collection = phone.split('_')[0]\n",
    "    phonename = phone.split('_')[1]\n",
    "    derived = get_derived_data('train', collection, phonename)\n",
    "    derived = prepare_calc_baseline(derived, csr)\n",
    "    \n",
    "    derived = derived[derived['ElevationDegrees']>=elev_deg].copy()\n",
    "    derived = derived[derived['UsedInFix']>=used_in_fix].copy()\n",
    "    derived = derived[derived['rawPrUncM']<=rawpruncm].copy()\n",
    "\n",
    "    \n",
    "    idx = list(df.index)\n",
    "    s_list = []\n",
    "    n_list = []\n",
    "    lat_list = []\n",
    "    lng_list = []\n",
    "    unc_mean_list = []\n",
    "    unc_max_list = []\n",
    "    \n",
    "    for j,i in enumerate(idx):\n",
    "        s = df.at[i, 'millisSinceGpsEpoch']\n",
    "        tmp = derived[(derived['millisSinceGpsEpoch']>=s-s_th)&(derived['millisSinceGpsEpoch']<=s+s_th)].copy()\n",
    "        n = tmp['svid'].nunique()\n",
    "        s_list.append(s)\n",
    "        n_list.append(n)\n",
    "        \n",
    "        if n < 4:    \n",
    "            lat_list.append(np.nan)\n",
    "            lng_list.append(np.nan)\n",
    "            unc_mean_list.append(np.nan)\n",
    "            unc_max_list.append(np.nan)        \n",
    "        \n",
    "        else:\n",
    "            res = calc_baseline_point(tmp)\n",
    "            lat_list.append(res[0])\n",
    "            lng_list.append(res[1])\n",
    "            unc_mean_list.append(tmp['uncertaintyWeight'].mean())\n",
    "            unc_max_list.append(tmp['uncertaintyWeight'].max())\n",
    "    \n",
    "    output_df = pd.DataFrame()\n",
    "    output_df['millisSinceGpsEpoch'] = s_list\n",
    "    output_df['latDeg'] = lat_list\n",
    "    output_df['lngDeg'] = lng_list\n",
    "    output_df['n'] = n_list\n",
    "    output_df['unc_mean'] = unc_mean_list\n",
    "    output_df['unc_max'] = unc_max_list\n",
    "    output_df['collectionName'] = collection\n",
    "    output_df['phoneName'] = phonename\n",
    "    output_df['phone'] = phone\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "incorporated-handling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carrier_smoothing(df, rel_rate):\n",
    "    abs_rate = 1 - rel_rate\n",
    "    df = df.sort_values(['sat', 'millisSinceGpsEpoch'])\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    df.loc[df['AccumulatedDeltaRangeState']!=25, 'AccumulatedDeltaRangeMeters'] = np.nan\n",
    "    df['ADR_d'] = df['AccumulatedDeltaRangeMeters'] - df.groupby('sat')['AccumulatedDeltaRangeMeters'].shift(1)\n",
    "    df['ADR_d_prev'] = df['ADR_d'].shift(-1)\n",
    "    \n",
    "    df_index = list(df.index)\n",
    "    for idx in df_index:\n",
    "        if idx == df.index[-1]-1:\n",
    "            break\n",
    "        if df.at[idx, 'sat'] != df.at[idx+1, 'sat']:\n",
    "            continue\n",
    "            \n",
    "        p_abs = df.at[idx, 'correctedPrM']\n",
    "        p_adrd = df.at[idx, 'ADR_d']\n",
    "        \n",
    "        if not np.isnan(p_adrd):\n",
    "            p_abs_prev = df.at[idx-1, 'correctedPrM']\n",
    "            p_rel = p_abs_prev + p_adrd\n",
    "            p_new = p_abs * abs_rate + p_rel * rel_rate\n",
    "            df.at[idx, 'correctedPrM'] = p_new            \n",
    "\n",
    "    df_index.reverse()\n",
    "    for idx in df_index:\n",
    "        if idx == df.index[0]:\n",
    "            break\n",
    "        if df.at[idx, 'sat'] != df.at[idx-1, 'sat']:\n",
    "            continue\n",
    "\n",
    "        p_abs = df.at[idx, 'correctedPrM']\n",
    "        p_adrd = df.at[idx, 'ADR_d_prev']\n",
    "\n",
    "        if not np.isnan(p_adrd):\n",
    "            p_abs_prev = df.at[idx+1, 'correctedPrM']\n",
    "            p_rel = p_abs_prev - p_adrd\n",
    "            p_new = p_abs * abs_rate + p_rel * rel_rate\n",
    "            df.at[idx, 'correctedPrM'] = p_new                \n",
    "            \n",
    "    return df        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-modem",
   "metadata": {},
   "source": [
    "# データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "talented-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, sub, gt = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cheap-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['collectionName'].isin(target)].copy()\n",
    "train = train[train['phone']!='Mi8'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-shooting",
   "metadata": {},
   "source": [
    "# 元のベースラインの精度確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "assured-airport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percentile50</th>\n",
       "      <th>percentile95</th>\n",
       "      <th>p50_p90_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phone</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-03-10-US-SVL-1_Pixel4XL</th>\n",
       "      <td>3.788289</td>\n",
       "      <td>10.398351</td>\n",
       "      <td>7.093320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-10-US-SVL-1_SamsungS20Ultra</th>\n",
       "      <td>3.337535</td>\n",
       "      <td>9.181723</td>\n",
       "      <td>6.259629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-26-US-SVL-1_Mi8</th>\n",
       "      <td>1.696266</td>\n",
       "      <td>4.704213</td>\n",
       "      <td>3.200240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-26-US-SVL-1_Pixel5</th>\n",
       "      <td>1.683179</td>\n",
       "      <td>5.318300</td>\n",
       "      <td>3.500739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     percentile50  percentile95  p50_p90_mean\n",
       "phone                                                                        \n",
       "2021-03-10-US-SVL-1_Pixel4XL             3.788289     10.398351      7.093320\n",
       "2021-03-10-US-SVL-1_SamsungS20Ultra      3.337535      9.181723      6.259629\n",
       "2021-04-26-US-SVL-1_Mi8                  1.696266      4.704213      3.200240\n",
       "2021-04-26-US-SVL-1_Pixel5               1.683179      5.318300      3.500739"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result(train).err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "green-blank",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.01348208125419"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result(train).score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-lottery",
   "metadata": {},
   "source": [
    "# パラメータチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "congressional-couple",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    elev_deg = trial.suggest_int('elev_deg', 5, 15)\n",
    "    used_in_fix = trial.suggest_categorical('used_in_fix', [0,1])\n",
    "    rawpruncm = trial.suggest_int('rawpruncm', 25, 100)\n",
    "    csr = trial.suggest_float('csr', 0, 1, step=0.1)\n",
    "    nth = trial.suggest_int('nth', 4, 8)\n",
    "    \n",
    "    args = []\n",
    "    for phone in train['phone'].unique():\n",
    "        tmp = train[train['phone']==phone].copy()\n",
    "        args.append([phone, tmp, elev_deg, used_in_fix, rawpruncm, csr, nth])\n",
    "    \n",
    "    processes = multiprocessing.cpu_count()\n",
    "    with multiprocessing.Pool(processes=processes) as pool:\n",
    "        dfs = pool.imap_unordered(calc_baseline, args)\n",
    "        dfs = list(dfs)\n",
    "        \n",
    "    result = pd.concat(dfs)\n",
    "    \n",
    "    result = result.rename(columns={'latDeg':'latDeg_rb', 'lngDeg':'lngDeg_rb'})\n",
    "    result = train.merge(result[['millisSinceGpsEpoch', 'phone', 'latDeg_rb', 'lngDeg_rb']], on=['millisSinceGpsEpoch', 'phone'], how='left')\n",
    "    idx = result[~result['latDeg_rb'].isnull()].index\n",
    "    result.loc[idx, 'latDeg'] = result.loc[idx, 'latDeg_rb']\n",
    "    result.loc[idx, 'lngDeg'] = result.loc[idx, 'lngDeg_rb'] \n",
    "    return train_result(result).score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-publication",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-22 01:22:01,505]\u001b[0m A new study created in memory with name: no-name-22e681a3-572f-49e0-bcda-2f6fef5e4f81\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 01:32:49,699]\u001b[0m Trial 0 finished with value: 4.889829538933357 and parameters: {'elev_deg': 9, 'used_in_fix': 1, 'rawpruncm': 60, 'csr': 0.30000000000000004, 'nth': 7}. Best is trial 0 with value: 4.889829538933357.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 01:44:04,857]\u001b[0m Trial 1 finished with value: 4.911441409167004 and parameters: {'elev_deg': 15, 'used_in_fix': 0, 'rawpruncm': 37, 'csr': 0.9, 'nth': 8}. Best is trial 0 with value: 4.889829538933357.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 01:54:49,275]\u001b[0m Trial 2 finished with value: 4.913588211732126 and parameters: {'elev_deg': 11, 'used_in_fix': 1, 'rawpruncm': 95, 'csr': 0.0, 'nth': 8}. Best is trial 0 with value: 4.889829538933357.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 02:05:34,404]\u001b[0m Trial 3 finished with value: 5.054308079804972 and parameters: {'elev_deg': 6, 'used_in_fix': 1, 'rawpruncm': 64, 'csr': 0.4, 'nth': 7}. Best is trial 0 with value: 4.889829538933357.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 02:16:38,982]\u001b[0m Trial 4 finished with value: 4.717275969929696 and parameters: {'elev_deg': 12, 'used_in_fix': 0, 'rawpruncm': 33, 'csr': 0.7000000000000001, 'nth': 6}. Best is trial 4 with value: 4.717275969929696.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 02:26:43,219]\u001b[0m Trial 5 finished with value: 4.798994689059956 and parameters: {'elev_deg': 9, 'used_in_fix': 1, 'rawpruncm': 94, 'csr': 1.0, 'nth': 4}. Best is trial 4 with value: 4.717275969929696.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 02:35:57,238]\u001b[0m Trial 6 finished with value: 5.086798969782572 and parameters: {'elev_deg': 5, 'used_in_fix': 1, 'rawpruncm': 46, 'csr': 0.30000000000000004, 'nth': 4}. Best is trial 4 with value: 4.717275969929696.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 02:46:46,086]\u001b[0m Trial 7 finished with value: 4.686984888412799 and parameters: {'elev_deg': 10, 'used_in_fix': 1, 'rawpruncm': 97, 'csr': 0.9, 'nth': 5}. Best is trial 7 with value: 4.686984888412799.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 02:58:34,079]\u001b[0m Trial 8 finished with value: 5.185175986351519 and parameters: {'elev_deg': 5, 'used_in_fix': 0, 'rawpruncm': 100, 'csr': 0.5, 'nth': 5}. Best is trial 7 with value: 4.686984888412799.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 03:09:21,447]\u001b[0m Trial 9 finished with value: 4.858511533210321 and parameters: {'elev_deg': 13, 'used_in_fix': 1, 'rawpruncm': 98, 'csr': 0.30000000000000004, 'nth': 8}. Best is trial 7 with value: 4.686984888412799.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 03:20:44,834]\u001b[0m Trial 10 finished with value: 5.046821833837662 and parameters: {'elev_deg': 7, 'used_in_fix': 1, 'rawpruncm': 79, 'csr': 0.8, 'nth': 5}. Best is trial 7 with value: 4.686984888412799.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 03:32:30,215]\u001b[0m Trial 11 finished with value: 4.753678057439642 and parameters: {'elev_deg': 12, 'used_in_fix': 0, 'rawpruncm': 25, 'csr': 0.7000000000000001, 'nth': 6}. Best is trial 7 with value: 4.686984888412799.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 03:42:13,209]\u001b[0m Trial 12 finished with value: 4.933269073221508 and parameters: {'elev_deg': 14, 'used_in_fix': 0, 'rawpruncm': 25, 'csr': 0.6000000000000001, 'nth': 6}. Best is trial 7 with value: 4.686984888412799.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 03:53:11,420]\u001b[0m Trial 13 finished with value: 4.728554717144885 and parameters: {'elev_deg': 10, 'used_in_fix': 0, 'rawpruncm': 80, 'csr': 1.0, 'nth': 5}. Best is trial 7 with value: 4.686984888412799.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 04:03:54,751]\u001b[0m Trial 14 finished with value: 4.665665981377163 and parameters: {'elev_deg': 11, 'used_in_fix': 0, 'rawpruncm': 42, 'csr': 0.8, 'nth': 5}. Best is trial 14 with value: 4.665665981377163.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 04:14:54,973]\u001b[0m Trial 15 finished with value: 4.903509198024713 and parameters: {'elev_deg': 8, 'used_in_fix': 0, 'rawpruncm': 54, 'csr': 0.9, 'nth': 5}. Best is trial 14 with value: 4.665665981377163.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 04:25:52,687]\u001b[0m Trial 16 finished with value: 4.688947208725088 and parameters: {'elev_deg': 10, 'used_in_fix': 0, 'rawpruncm': 74, 'csr': 0.8, 'nth': 4}. Best is trial 14 with value: 4.665665981377163.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 04:35:30,555]\u001b[0m Trial 17 finished with value: 4.752900276596971 and parameters: {'elev_deg': 11, 'used_in_fix': 1, 'rawpruncm': 47, 'csr': 1.0, 'nth': 5}. Best is trial 14 with value: 4.665665981377163.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 04:46:36,733]\u001b[0m Trial 18 finished with value: 4.691208333678086 and parameters: {'elev_deg': 13, 'used_in_fix': 0, 'rawpruncm': 38, 'csr': 0.8, 'nth': 4}. Best is trial 14 with value: 4.665665981377163.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 04:57:45,552]\u001b[0m Trial 19 finished with value: 4.956828265883454 and parameters: {'elev_deg': 8, 'used_in_fix': 1, 'rawpruncm': 66, 'csr': 0.6000000000000001, 'nth': 7}. Best is trial 14 with value: 4.665665981377163.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 05:08:59,724]\u001b[0m Trial 20 finished with value: 4.8729885912462825 and parameters: {'elev_deg': 11, 'used_in_fix': 0, 'rawpruncm': 48, 'csr': 0.0, 'nth': 5}. Best is trial 14 with value: 4.665665981377163.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 05:18:30,315]\u001b[0m Trial 21 finished with value: 4.688947208725088 and parameters: {'elev_deg': 10, 'used_in_fix': 0, 'rawpruncm': 80, 'csr': 0.8, 'nth': 4}. Best is trial 14 with value: 4.665665981377163.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 05:28:01,202]\u001b[0m Trial 22 finished with value: 4.691509942170391 and parameters: {'elev_deg': 9, 'used_in_fix': 0, 'rawpruncm': 88, 'csr': 0.9, 'nth': 4}. Best is trial 14 with value: 4.665665981377163.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 05:37:38,886]\u001b[0m Trial 23 finished with value: 4.712028410727184 and parameters: {'elev_deg': 12, 'used_in_fix': 0, 'rawpruncm': 72, 'csr': 0.7000000000000001, 'nth': 5}. Best is trial 14 with value: 4.665665981377163.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 05:47:42,066]\u001b[0m Trial 24 finished with value: 4.662324925973255 and parameters: {'elev_deg': 10, 'used_in_fix': 0, 'rawpruncm': 83, 'csr': 0.9, 'nth': 4}. Best is trial 24 with value: 4.662324925973255.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 05:58:41,230]\u001b[0m Trial 25 finished with value: 4.906191944341851 and parameters: {'elev_deg': 8, 'used_in_fix': 0, 'rawpruncm': 88, 'csr': 1.0, 'nth': 6}. Best is trial 24 with value: 4.662324925973255.\u001b[0m\n",
      "\u001b[32m[I 2021-07-22 06:10:15,112]\u001b[0m Trial 26 finished with value: 4.639278658369498 and parameters: {'elev_deg': 11, 'used_in_fix': 0, 'rawpruncm': 87, 'csr': 0.9, 'nth': 5}. Best is trial 26 with value: 4.639278658369498.\u001b[0m\n",
      "Process ForkPoolWorker-878:\n",
      "Process ForkPoolWorker-871:\n",
      "Process ForkPoolWorker-865:\n",
      "Process ForkPoolWorker-887:\n",
      "Process ForkPoolWorker-885:\n",
      "Process ForkPoolWorker-870:\n",
      "Process ForkPoolWorker-877:\n",
      "Process ForkPoolWorker-883:\n",
      "Process ForkPoolWorker-867:\n",
      "Process ForkPoolWorker-896:\n",
      "Process ForkPoolWorker-874:\n",
      "Process ForkPoolWorker-890:\n",
      "Process ForkPoolWorker-872:\n",
      "Process ForkPoolWorker-893:\n",
      "Process ForkPoolWorker-886:\n",
      "Process ForkPoolWorker-895:\n",
      "Process ForkPoolWorker-875:\n",
      "Process ForkPoolWorker-894:\n",
      "Process ForkPoolWorker-891:\n",
      "Process ForkPoolWorker-889:\n",
      "Process ForkPoolWorker-879:\n",
      "Process ForkPoolWorker-869:\n",
      "Process ForkPoolWorker-881:\n",
      "Process ForkPoolWorker-892:\n",
      "Process ForkPoolWorker-880:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-866:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-888:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-884:\n",
      "Process ForkPoolWorker-876:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-873:\n",
      "Process ForkPoolWorker-882:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-868:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-17-740974be389d>\", line 37, in calc_baseline\n",
      "    res = calc_baseline_point(tmp)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"<ipython-input-15-985565db2cc3>\", line 20, in calc_baseline_point\n",
      "    opt_res = opt.least_squares(distance_fixed_satpos, x0)\n",
      "  File \"<ipython-input-17-740974be389d>\", line 37, in calc_baseline\n",
      "    res = calc_baseline_point(tmp)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"<ipython-input-15-985565db2cc3>\", line 20, in calc_baseline_point\n",
      "    opt_res = opt.least_squares(distance_fixed_satpos, x0)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/scipy/optimize/_lsq/least_squares.py\", line 927, in least_squares\n",
      "    tr_options.copy(), verbose)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/scipy/optimize/_lsq/trf.py\", line 121, in trf\n",
      "    loss_function, tr_solver, tr_options, verbose)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/scipy/optimize/_lsq/least_squares.py\", line 927, in least_squares\n",
      "    tr_options.copy(), verbose)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/scipy/optimize/_lsq/trf.py\", line 121, in trf\n",
      "    loss_function, tr_solver, tr_options, verbose)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/scipy/optimize/_lsq/trf.py\", line 536, in trf_no_bounds\n",
      "    J = jac(x, f)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/scipy/optimize/_lsq/trf.py\", line 499, in trf_no_bounds\n",
      "    f_new = fun(x_new)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/scipy/optimize/_lsq/least_squares.py\", line 885, in jac_wrapped\n",
      "    kwargs=kwargs, sparsity=jac_sparsity)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/scipy/optimize/_lsq/least_squares.py\", line 812, in fun_wrapped\n",
      "    return np.atleast_1d(fun(x, *args, **kwargs))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/scipy/optimize/_numdiff.py\", line 487, in approx_derivative\n",
      "    use_one_sided, method)\n",
      "  File \"<ipython-input-15-985565db2cc3>\", line 17, in distance_fixed_satpos\n",
      "    return distance(df[['xSatPosMRotated', 'ySatPosMRotated', 'zSatPosMRotated', 'correctedPrM', 'uncertaintyWeight']], x)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/scipy/optimize/_numdiff.py\", line 557, in _dense_difference\n",
      "    df = fun(x) - f0\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/scipy/optimize/_numdiff.py\", line 437, in fun_wrapped\n",
      "    f = np.atleast_1d(fun(x, *args, **kwargs))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\", line 2912, in __getitem__\n",
      "    indexer = self.loc._get_listlike_indexer(key, axis=1, raise_missing=True)[1]\n",
      "  File \"<ipython-input-15-985565db2cc3>\", line 17, in distance_fixed_satpos\n",
      "    return distance(df[['xSatPosMRotated', 'ySatPosMRotated', 'zSatPosMRotated', 'correctedPrM', 'uncertaintyWeight']], x)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\", line 1250, in _get_listlike_indexer\n",
      "    keyarr = ax.reindex(keyarr)[0]\n",
      "  File \"<ipython-input-15-985565db2cc3>\", line 12, in distance\n",
      "    x[3] - sat_pos_diff['correctedPrM'])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 3323, in reindex\n",
      "    target = ensure_index(target)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/ops/common.py\", line 65, in new_method\n",
      "    return method(self, other)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 5623, in ensure_index\n",
      "    return Index(index_like)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/ops/__init__.py\", line 345, in wrapper\n",
      "    return left._construct_result(result, name=res_name)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 401, in __new__\n",
      "    new_data, new_dtype = _maybe_cast_data_without_dtype(subarr)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\", line 2770, in _construct_result\n",
      "    out = self._constructor(result, index=self.index)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 5751, in _maybe_cast_data_without_dtype\n",
      "    inferred = lib.infer_dtype(subarr, skipna=False)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\", line 327, in __init__\n",
      "    data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True)\n",
      "  File \"pandas/_libs/lib.pyx\", line 1343, in pandas._libs.lib.infer_dtype\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/construction.py\", line 428, in sanitize_array\n",
      "    subarr = _try_cast(data, dtype, copy, raise_cast_failure)\n",
      "  File \"pandas/_libs/lib.pyx\", line 1201, in pandas._libs.lib._try_infer_map\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/construction.py\", line 539, in _try_cast\n",
      "    if maybe_castable(arr) and not copy and dtype is None:\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/_dtype.py\", line 321, in _name_get\n",
      "    def _name_get(dtype):\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/dtypes/cast.py\", line 1198, in maybe_castable\n",
      "    return arr.dtype.name not in _POSSIBLY_CAST_DTYPES\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/_dtype.py\", line 336, in _name_get\n",
      "    name += \"{}\".format(dtype.itemsize * 8)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials = 100, timeout=60*60*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
