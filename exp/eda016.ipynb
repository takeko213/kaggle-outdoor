{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "political-grade",
   "metadata": {},
   "source": [
    "# eda016\n",
    "gnss_logのセンサ周りの可視化 \n",
    "https://www.kaggle.com/museas/estimating-the-direction-with-a-magnetic-sensor  \n",
    "との平滑化周りの比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "advanced-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipynb_path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "received-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nb_name():\n",
    "    nb_path = ipynb_path.get()\n",
    "    nb_name = nb_path.rsplit('/',1)[1].replace('.ipynb','')\n",
    "    return nb_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "continental-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_trafic(df, center, zoom=9):\n",
    "    fig = px.scatter_mapbox(df,\n",
    "                            \n",
    "                            # Here, plotly gets, (x,y) coordinates\n",
    "                            lat=\"latDeg\",\n",
    "                            lon=\"lngDeg\",\n",
    "                            \n",
    "                            #Here, plotly detects color of series\n",
    "                            color=\"phoneName\",\n",
    "                            labels=\"phoneName\",\n",
    "                            \n",
    "                            zoom=zoom,\n",
    "                            center=center,\n",
    "                            height=1000,\n",
    "                            width=2000)\n",
    "    fig.update_layout(mapbox_style='stamen-terrain')\n",
    "    fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
    "    fig.update_layout(title_text=\"GPS trafic\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "swedish-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_collection(df, collection):\n",
    "    target_df = df[df['collectionName']==collection].copy()\n",
    "    lat_center = target_df['latDeg'].mean()\n",
    "    lng_center = target_df['lngDeg'].mean()\n",
    "    center = {\"lat\":lat_center, \"lon\":lng_center}\n",
    "    \n",
    "    visualize_trafic(target_df, center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "amazing-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculates the great circle distance between two points\n",
    "    on the earth. Inputs are array-like and specified in decimal degrees.\n",
    "    \"\"\"\n",
    "    RADIUS = 6_367_000\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + \\\n",
    "        np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    dist = 2 * RADIUS * np.arcsin(a**0.5)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "broken-finding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowpass filter\n",
    "\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "order = 3\n",
    "fs = 50.0\n",
    "cutoff = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "featured-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Offset correction\n",
    "# refarence https://github.com/J-ROCKET-BOY/SS-Fitting\n",
    "\n",
    "def SS_fit(data) : \n",
    "\n",
    "    x = data[:,[0]]\n",
    "    y = data[:,[1]]\n",
    "    z = data[:,[2]]\n",
    "\n",
    "    data_len = len(x)\n",
    "    \n",
    "    x2 = np.power(x,2)\n",
    "    y2 = np.power(y,2)\n",
    "    z2 = np.power(z,2)\n",
    "\n",
    "    r1 = -x*(x2+y2+z2)\n",
    "    r2= -y*(x2+y2+z2)\n",
    "    r3 = -z*(x2+y2+z2)\n",
    "    r4 = -(x2+y2+z2)\n",
    "\n",
    "    left = np.array([[np.sum(x2),np.sum(x*y),np.sum(x*z),np.sum(x)],\n",
    "                     [np.sum(x*y),np.sum(y2),np.sum(y*z),np.sum(y)],\n",
    "                     [np.sum(x*z),np.sum(y*z),np.sum(z2),np.sum(z)],\n",
    "                     [np.sum(x), np.sum(y), np.sum(z), data_len]])\n",
    "    \n",
    "    right = np.array([np.sum(r1),\n",
    "                      np.sum(r2),\n",
    "                      np.sum(r3),\n",
    "                      np.sum(r4)])\n",
    "    \n",
    "    si = np.dot(np.linalg.inv(left),right)\n",
    "\n",
    "    x0 = (-1/2)* si[0]\n",
    "    y0 = (-1/2)* si[1]\n",
    "    z0 = (-1/2)* si[2]\n",
    "    \n",
    "    return np.array([x0,y0,z0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "sensitive-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vincenty's formulae\n",
    "# refarence https://qiita.com/r-fuji/items/99ca549b963cedc106ab\n",
    "\n",
    "def vincenty_inverse(lat1, lon1, lat2, lon2):\n",
    "\n",
    "    # Not advanced\n",
    "    if isclose(lat1, lat2) and isclose(lon1, lon2):\n",
    "        return False\n",
    "    \n",
    "    # WGS84\n",
    "    a = 6378137.0\n",
    "    ƒ = 1 / 298.257223563\n",
    "    b = (1 - ƒ) * a\n",
    "\n",
    "    lat_1 = atan((1 - ƒ) * tan(radians(lat1)))\n",
    "    lat_2 = atan((1 - ƒ) * tan(radians(lat2)))\n",
    "    \n",
    "    lon_diff = radians(lon2) - radians(lon1)\n",
    "    λ = lon_diff\n",
    "\n",
    "    for i in range(1000):\n",
    "        sinλ = sin(λ)\n",
    "        cosλ = cos(λ)\n",
    "        sinσ = sqrt((cos(lat_2) * sinλ) ** 2 + (cos(lat_1) * sin(lat_2) - sin(lat_1) * cos(lat_2) * cosλ) ** 2)\n",
    "        cosσ = sin(lat_1) * sin(lat_2) + cos(lat_1) * cos(lat_2) * cosλ\n",
    "        σ = atan2(sinσ, cosσ)\n",
    "        sinα = cos(lat_1) * cos(lat_2) * sinλ / sinσ\n",
    "        cos2α = 1 - sinα ** 2\n",
    "        cos2σm = cosσ - 2 * sin(lat_1) * sin(lat_2) / cos2α\n",
    "        C = ƒ / 16 * cos2α * (4 + ƒ * (4 - 3 * cos2α))\n",
    "        λʹ = λ\n",
    "        λ = lon_diff + (1 - C) * ƒ * sinα * (σ + C * sinσ * (cos2σm + C * cosσ * (-1 + 2 * cos2σm ** 2)))\n",
    "        \n",
    "        if abs(λ - λʹ) <= 1e-12:\n",
    "            break\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    α = atan2(cos(lat_2) * sinλ, cos(lat_1) * sin(lat_2) - sin(lat_1) * cos(lat_2) * cosλ)\n",
    "\n",
    "    if α < 0:\n",
    "        α = α + pi * 2\n",
    "\n",
    "    return degrees(α)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "pharmaceutical-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc3(row):\n",
    "    deg = - degrees(atan2(-1*row['calc2'],row['calc1']))\n",
    "    if deg < 0:\n",
    "        deg += 360\n",
    "    return deg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "selective-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory setting\n",
    "nb_name = get_nb_name()\n",
    "INPUT = '../input/google-smartphone-decimeter-challenge'\n",
    "OUTPUT = '../output/' + nb_name\n",
    "os.makedirs(OUTPUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-charger",
   "metadata": {},
   "source": [
    "# 特徴量生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "strange-therapy",
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_train = pd.read_csv(INPUT + '/prep/gnss/train/UncalAccel.csv')\n",
    "gyro_train = pd.read_csv(INPUT + '/prep/gnss/train/UncalGyro.csv')\n",
    "mag_train = pd.read_csv(INPUT + '/prep/gnss/train/UncalMag.csv')\n",
    "train = pd.read_csv(INPUT + '/' + 'baseline_locations_train.csv')\n",
    "ground_truth = pd.read_csv(INPUT + '/prep/ground_truth_train.csv')\n",
    "\n",
    "train['speedMps'] = ground_truth['speedMps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "interracial-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sensor_features(df, accel, gyro, mag):\n",
    "    # phoneを追加\n",
    "    df['phone'] = df['collectionName'] + '_' + df['phoneName']\n",
    "    accel['phone'] = accel['collectionName'] + '_' + accel['phoneName']\n",
    "    gyro['phone'] = gyro['collectionName'] + '_' + gyro['phoneName']\n",
    "    mag['phone'] = mag['collectionName'] + '_' + mag['phoneName']\n",
    "    \n",
    "    # utc -> gps\n",
    "    accel['millisSinceGpsEpoch'] = accel['utcTimeMillis'] - 315964800000 + 18000\n",
    "    gyro['millisSinceGpsEpoch'] = gyro['utcTimeMillis'] - 315964800000 + 18000\n",
    "    mag['millisSinceGpsEpoch'] = mag['utcTimeMillis'] - 315964800000 + 18000\n",
    "        \n",
    "    # resampling追加\n",
    "    df['secondSinceGpsEpoch'] = df['millisSinceGpsEpoch'] // 1000\n",
    "    accel['secondSinceGpsEpoch'] = accel['millisSinceGpsEpoch'] // 1000\n",
    "    gyro['secondSinceGpsEpoch'] = gyro['millisSinceGpsEpoch'] // 1000\n",
    "    mag['secondSinceGpsEpoch'] = mag['millisSinceGpsEpoch'] // 1000\n",
    "\n",
    "    for phone in accel['phone'].unique():\n",
    "        accel_idx = accel[accel['phone']==phone].index\n",
    "        for c in ['UncalAccelXMps2', 'UncalAccelYMps2', 'UncalAccelZMps2']:\n",
    "            accel.loc[accel_idx, c+'_fil'] =  butter_lowpass_filter(accel.loc[accel_idx, c], cutoff, fs, order)\n",
    "            accel.at[accel_idx[0], c+'_fil'] = np.nan\n",
    "            accel.loc[accel_idx, c+'ro'] = accel.loc[accel_idx, c+'_fil'].rolling(1000, center=True, min_periods=1).mean()\n",
    "    \n",
    "    for phone in gyro['phone'].unique():        \n",
    "        gyro_idx = gyro[gyro['phone']==phone].index\n",
    "        for c in ['UncalGyroXRadPerSec', 'UncalGyroYRadPerSec', 'UncalGyroZRadPerSec']:\n",
    "            gyro.loc[gyro_idx, c+'_fil'] =  butter_lowpass_filter(gyro.loc[gyro_idx, c], cutoff, fs, order)\n",
    "            gyro.at[gyro_idx[0], c+'_fil'] = np.nan\n",
    "    \n",
    "    for phone in mag['phone'].unique():\n",
    "        mag_idx = mag[mag['phone']==phone].index\n",
    "        for c in ['UncalMagXMicroT', 'UncalMagYMicroT', 'UncalMagZMicroT']:\n",
    "            mag.loc[mag_idx, c+'_fil'] =  butter_lowpass_filter(mag.loc[mag_idx, c], cutoff, fs, order)\n",
    "            mag.at[mag_idx[0], c+'_fil'] = np.nan\n",
    "            mag.loc[accel_idx, c+'ro'] = mag.loc[accel_idx, c+'_fil'].rolling(1000, min_periods=1).mean()\n",
    "    \n",
    "    # clipping\n",
    "    accel[['UncalAccelXMps2', 'UncalAccelYMps2', 'UncalAccelZMps2']] = accel.groupby('phone')['UncalAccelXMps2', 'UncalAccelYMps2', 'UncalAccelZMps2'].transform(lambda x: x.clip(x.quantile(0.001), x.quantile(0.999)))\n",
    "    gyro[['UncalGyroXRadPerSec', 'UncalGyroYRadPerSec', 'UncalGyroZRadPerSec']] = gyro.groupby('phone')['UncalGyroXRadPerSec', 'UncalGyroYRadPerSec', 'UncalGyroZRadPerSec'].transform(lambda x: x.clip(x.quantile(0.001), x.quantile(0.999)))\n",
    "    mag[['UncalMagXMicroT', 'UncalMagYMicroT', 'UncalMagZMicroT']] = mag.groupby('phone')['UncalMagXMicroT', 'UncalMagYMicroT', 'UncalMagZMicroT'].transform(lambda x: x.clip(x.quantile(0.001), x.quantile(0.999)))\n",
    "    \n",
    "    accel2 = accel.groupby(['phone', 'secondSinceGpsEpoch'])['UncalAccelXMps2', 'UncalAccelYMps2', 'UncalAccelZMps2'].agg(['mean', 'std']).reset_index()\n",
    "    accel2.columns = ['phone', 'secondSinceGpsEpoch', 'UncalAccelXMps2_mean', 'UncalAccelXMps2_std', 'UncalAccelYMps2_mean', 'UncalAccelYMps2_std', 'UncalAccelZMps2_mean', 'UncalAccelZMps2_std']\n",
    "    gyro2 = gyro.groupby(['phone', 'secondSinceGpsEpoch'])['UncalGyroXRadPerSec', 'UncalGyroYRadPerSec', 'UncalGyroZRadPerSec'].agg(['mean', 'std']).reset_index()\n",
    "    gyro2.columns = ['phone', 'secondSinceGpsEpoch', 'UncalGyroXRadPerSec_mean', 'UncalGyroXRadPerSec_std', 'UncalGyroYRadPerSec_mean', 'UncalGyroYRadPerSec_std', 'UncalGyroZRadPerSec_mean', 'UncalGyroZRadPerSec_std' ]\n",
    "    mag2 = mag.groupby(['phone', 'secondSinceGpsEpoch'])['UncalMagXMicroT', 'UncalMagYMicroT', 'UncalMagZMicroT'].agg(['mean', 'std']).reset_index()\n",
    "    mag2.columns = ['phone', 'secondSinceGpsEpoch', 'UncalMagXMicroT_mean', 'UncalMagXMicroT_std', 'UncalMagYMicroT_mean', 'UncalMagYMicroT_std', 'UncalMagZMicroT_mean', 'UncalMagZMicroT_std']\n",
    "    \n",
    "    df = df.merge(accel2, on=['phone', 'secondSinceGpsEpoch'], how='left')\n",
    "    df = df.merge(gyro2, on=['phone', 'secondSinceGpsEpoch'], how='left')\n",
    "    df = df.merge(mag2, on=['phone', 'secondSinceGpsEpoch'], how='left')\n",
    "    \n",
    "    df.drop(['secondSinceGpsEpoch'], axis=1, inplace=True)\n",
    "    \n",
    "    return df,accel, gyro, mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-edward",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-acrobat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, accel, gyro, mag = add_sensor_features(train, accel_train, gyro_train, mag_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-poison",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-looking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-classroom",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-charger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-fetish",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-clarity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-sight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "contemporary-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz2(df, cols, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    cols_n = len(cols)\n",
    "    phones = df['phone'].unique()\n",
    "    \n",
    "    for phone in phones:\n",
    "        df_tmp = df[df['phone']==phone].copy()\n",
    "        \n",
    "        fig, axes = plt.subplots(figsize=(5*cols_n, 20), nrows=cols_n,sharex=True)\n",
    "        for i,c in enumerate(cols):\n",
    "            axes[i].plot(df_tmp['millisSinceGpsEpoch'], df_tmp[c], label=c)\n",
    "            axes[i].legend(loc='upper right')\n",
    "            axes[i].grid(color='g', linestyle=':', linewidth=0.3)\n",
    "        fig.suptitle(phone, fontsize=16)\n",
    "        fig.savefig(output_dir + '/' + phone + '.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bizarre-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz2(train, \n",
    "    cols=['speedMps', 'UncalAccelXMps2_mean', 'UncalAccelXMps2_std', 'UncalAccelYMps2_mean', 'UncalAccelYMps2_std', 'UncalAccelZMps2_mean', 'UncalAccelZMps2_std'],\n",
    "    output_dir = OUTPUT + '/gnss_ts/train/accel_f')\n",
    "\n",
    "viz2(train, \n",
    "    cols=['speedMps', 'UncalGyroXRadPerSec_mean', 'UncalGyroXRadPerSec_std', 'UncalGyroYRadPerSec_mean', 'UncalGyroYRadPerSec_std', 'UncalGyroZRadPerSec_mean', 'UncalGyroZRadPerSec_std'],\n",
    "    output_dir = OUTPUT + '/gnss_ts/train/gyro_f')\n",
    "\n",
    "viz2(train, \n",
    "    cols=['speedMps', 'UncalMagXMicroT_mean', 'UncalMagXMicroT_std', 'UncalMagYMicroT_mean', 'UncalMagYMicroT_std', 'UncalMagZMicroT_mean', 'UncalMagZMicroT_std'],\n",
    "    output_dir = OUTPUT + '/gnss_ts/train/mag_f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-notebook",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-softball",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
