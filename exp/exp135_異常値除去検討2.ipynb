{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "racial-dayton",
   "metadata": {},
   "source": [
    "# exp135_異常値除去検討"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "retired-tattoo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import library\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import pathlib\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import itertools\n",
    "import lightgbm as lgb\n",
    "from optuna.integration import lightgbm as optuna_lgb\n",
    "import simdkalman\n",
    "import optuna\n",
    "import pyproj\n",
    "from pyproj import Proj, transform\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, confusion_matrix, accuracy_score\n",
    "pd.set_option('display.max_rows', 100)\n",
    "import scipy.interpolate\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "inappropriate-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_labeling = pd.read_csv('../output/prep/area_labeling/result.csv')\n",
    "\n",
    "g1 = list(area_labeling[area_labeling['g']==1]['collectionName'])\n",
    "g2 = list(area_labeling[area_labeling['g']==2]['collectionName'])\n",
    "g3 = list(area_labeling[area_labeling['g']==3]['collectionName'])\n",
    "g4 = list(area_labeling[area_labeling['g']==4]['collectionName'])\n",
    "g5 = list(area_labeling[area_labeling['g']==5]['collectionName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eligible-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = g1 + g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "requested-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_th = 50 # 相対移動距離をもとにした異常値除去の閾値\n",
    "rog_th = 10 # ground_truthをもとにした異常値除去の閾値\n",
    "\n",
    "# ground_truthをもとにした異常値除去を行うcollection\n",
    "rog_target = ['2021-04-22-US-SJC-1', '2021-04-29-US-SJC-2', '2021-04-28-US-SJC-1', '2021-04-22-US-SJC-2', '2021-04-29-US-SJC-3',\n",
    "              '2021-04-28-US-MTV-1', '2021-04-29-US-MTV-1', '2021-03-16-US-RWC-2', '2021-04-28-US-MTV-2', '2021-04-29-US-MTV-2',\n",
    "              '2021-04-26-US-SVL-2', '2021-03-10-US-SVL-1', '2021-04-26-US-SVL-1',\n",
    "              '2021-04-21-US-MTV-1', '2021-04-28-US-MTV-1', '2021-04-29-US-MTV-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "verified-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb_path\n",
    "\n",
    "def get_nb_name():\n",
    "    nb_path = ipynb_path.get()\n",
    "    nb_name = nb_path.rsplit('/',1)[1].replace('.ipynb','')\n",
    "    return nb_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "indie-persian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory setting\n",
    "nb_name = get_nb_name()\n",
    "INPUT = '../input/google-smartphone-decimeter-challenge'\n",
    "OUTPUT = '../output/' + nb_name\n",
    "os.makedirs(OUTPUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-princess",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "laughing-latest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_score(df, gt):\n",
    "    gt = gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n",
    "    df = df.merge(gt, on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n",
    "    # calc_distance_error\n",
    "    df['err'] = calc_haversine(df['latDeg_gt'], df['lngDeg_gt'], df['latDeg'], df['lngDeg'])\n",
    "    # calc_evaluate_score\n",
    "    df['phone'] = df['collectionName'] + '_' + df['phoneName']\n",
    "    res = df.groupby('phone')['err'].agg([percentile50, percentile95])\n",
    "    res['p50_p90_mean'] = (res['percentile50'] + res['percentile95']) / 2 \n",
    "    score = res['p50_p90_mean'].mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "induced-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculates the great circle distance between two points\n",
    "    on the earth. Inputs are array-like and specified in decimal degrees.\n",
    "    \"\"\"\n",
    "    RADIUS = 6_367_000\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + \\\n",
    "        np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    dist = 2 * RADIUS * np.arcsin(a**0.5)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dangerous-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_trafic(df, center, zoom=9):\n",
    "    fig = px.scatter_mapbox(df,\n",
    "                            \n",
    "                            # Here, plotly gets, (x,y) coordinates\n",
    "                            lat=\"latDeg\",\n",
    "                            lon=\"lngDeg\",\n",
    "                            \n",
    "                            #Here, plotly detects color of series\n",
    "                            color=\"phoneName\",\n",
    "                            labels=\"phoneName\",\n",
    "                            \n",
    "                            zoom=zoom,\n",
    "                            center=center,\n",
    "                            height=600,\n",
    "                            width=800)\n",
    "    fig.update_layout(mapbox_style='stamen-terrain')\n",
    "    fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
    "    fig.update_layout(title_text=\"GPS trafic\")\n",
    "    fig.show()\n",
    "    \n",
    "def visualize_collection(df, collection):\n",
    "    target_df = df[df['collectionName']==collection].copy()\n",
    "    lat_center = target_df['latDeg'].mean()\n",
    "    lng_center = target_df['lngDeg'].mean()\n",
    "    center = {\"lat\":lat_center, \"lon\":lng_center}\n",
    "    \n",
    "    visualize_trafic(target_df, center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "precise-wings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_truth\n",
    "def get_ground_truth():\n",
    "    p = pathlib.Path(INPUT)\n",
    "    gt_files = list(p.glob('train/*/*/ground_truth.csv'))\n",
    "\n",
    "    gts = []\n",
    "    for gt_file in gt_files:\n",
    "        gts.append(pd.read_csv(gt_file))\n",
    "    ground_truth = pd.concat(gts)\n",
    "\n",
    "    return ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "shaped-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile50(x):\n",
    "    return np.percentile(x, 50)\n",
    "def percentile95(x):\n",
    "    return np.percentile(x, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "suspended-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_result:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.gt = get_ground_truth()\n",
    "        self.bl = pd.read_csv(INPUT + '/' + 'baseline_locations_train.csv')\n",
    "        \n",
    "        self.gt = self.gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n",
    "        self.df = self.df.merge(self.gt, on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n",
    "        self.df['phone'] = self.df['collectionName'] + '_' + self.df['phoneName']\n",
    "        self.df['err'] =  calc_haversine(self.df['latDeg_gt'], self.df['lngDeg_gt'], self.df['latDeg'], self.df['lngDeg'])\n",
    "        \n",
    "        self.phone_res = self.calc_err('phone')\n",
    "        self.clc_res = self.calc_err('collectionName')\n",
    "        self.phonename_res = self.calc_err('phoneName')\n",
    "        \n",
    "    def calc_err(self, by):\n",
    "        res = self.df.groupby(by)['err'].agg([percentile50, percentile95])\n",
    "        res['p50_p90_mean'] = (res['percentile50'] + res['percentile95']) / 2\n",
    "        return res\n",
    "    \n",
    "    @property\n",
    "    def score(self):\n",
    "        return self.phone_res['p50_p90_mean'].mean()\n",
    "    @property\n",
    "    def raw_data(self):\n",
    "        return self.df\n",
    "    @property\n",
    "    def err(self):\n",
    "        return self.phone_res\n",
    "    @property\n",
    "    def collection_err(self):\n",
    "        return self.clc_res\n",
    "    @property\n",
    "    def phonename_err(self):\n",
    "        return self.phonename_res\n",
    "    \n",
    "    def viz_map(self, collection, show_gt=True, show_bl=True):\n",
    "        tmp = self.df[self.df['collectionName']==collection][['collectionName', 'phoneName', 'latDeg', 'lngDeg']]\n",
    "        tmp2 = self.df[self.df['collectionName']==collection][['collectionName', 'phoneName', 'latDeg_gt', 'lngDeg_gt']]\n",
    "        tmp2 = tmp2.rename(columns={'latDeg_gt':'latDeg', 'lngDeg_gt':'lngDeg'})\n",
    "        tmp2['phoneName'] = tmp2['phoneName'] + '_GT'\n",
    "        tmp3 = self.bl[self.bl['collectionName']==collection][['collectionName', 'phoneName', 'latDeg', 'lngDeg']]\n",
    "        tmp3['phoneName'] = tmp3['phoneName'] + '_BL'\n",
    "        \n",
    "        if show_gt:\n",
    "            tmp = tmp.append(tmp2)\n",
    "        if show_bl:\n",
    "            tmp = tmp.append(tmp3)\n",
    "        visualize_collection(tmp, collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "blind-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    base_train = pd.read_csv(INPUT + '/' + 'baseline_locations_train.csv')\n",
    "    base_test = pd.read_csv(INPUT + '/' + 'baseline_locations_test.csv')\n",
    "    sample_sub = pd.read_csv(INPUT + '/' + 'sample_submission.csv')\n",
    "    ground_truth = get_ground_truth()\n",
    "    return base_train, base_test, sample_sub, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "macro-january",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_baseline(df, rb):\n",
    "    rb = rb.rename(columns={'latDeg':'latDeg_rb', 'lngDeg':'lngDeg_rb'})\n",
    "    df = df.merge(rb[['millisSinceGpsEpoch', 'phone', 'latDeg_rb', 'lngDeg_rb']], on=['millisSinceGpsEpoch', 'phone'], how='left')\n",
    "\n",
    "    idx = df[~df['latDeg_rb'].isnull()].index\n",
    "    df.loc[idx, 'latDeg'] = df.loc[idx, 'latDeg_rb']\n",
    "    df.loc[idx, 'lngDeg'] = df.loc[idx, 'lngDeg_rb']\n",
    "    \n",
    "    df.drop(columns=['latDeg_rb', 'lngDeg_rb'], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "banned-blind",
   "metadata": {},
   "outputs": [],
   "source": [
    "def err_map(df_, output_dir):\n",
    "    df = df_.copy()\n",
    "    gt = pd.read_csv(INPUT + '/prep/ground_truth_train.csv')\n",
    "    gt = gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n",
    "    df = df.merge(gt[['collectionName', 'phoneName', 'millisSinceGpsEpoch', 'latDeg_gt', 'lngDeg_gt', 'speedMps', 'courseDegree']], on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n",
    "    df['err'] = calc_haversine(df['latDeg'], df['lngDeg'], df['latDeg_gt'], df['lngDeg_gt'])\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for phone in df['phone'].unique():\n",
    "        tmp = df[df['phone']==phone].copy()\n",
    "        fig, axes = plt.subplots(figsize=(30, 30))\n",
    "        sns.scatterplot(x='latDeg', y='lngDeg', hue='err', data=tmp, size='err', s=100, alpha=0.8, lw=0, ax=axes)\n",
    "        axes.invert_xaxis()\n",
    "        fig.suptitle(phone, fontsize=16)\n",
    "        fig.savefig(f'{output_dir}/{phone}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "special-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def err_transition(df_, output_dir):\n",
    "    df = df_.copy()\n",
    "    gt = pd.read_csv(INPUT + '/prep/ground_truth_train.csv')\n",
    "    gt = gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n",
    "    df = df.merge(gt[['collectionName', 'phoneName', 'millisSinceGpsEpoch', 'latDeg_gt', 'lngDeg_gt', 'speedMps', 'courseDegree']], on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n",
    "    df['err'] = calc_haversine(df['latDeg'], df['lngDeg'], df['latDeg_gt'], df['lngDeg_gt'])\n",
    "    df['millis_diff'] = df['millisSinceGpsEpoch'] - df.groupby('phone')['millisSinceGpsEpoch'].shift(1)\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for phone in df['phone'].unique():\n",
    "        tmp = df[df['phone']==phone].copy()\n",
    "        fig, axes = plt.subplots(figsize=(40, 20), nrows=4,sharex=True)\n",
    "        axes[0].plot(tmp['millisSinceGpsEpoch'], tmp['speedMps'], label='speedMps')\n",
    "        axes[0].legend(loc='upper right')\n",
    "        axes[0].grid(color='g', linestyle=':', linewidth=0.3)\n",
    "\n",
    "        axes[1].plot(tmp['millisSinceGpsEpoch'], tmp['courseDegree'], label='courseDegree')\n",
    "        axes[1].legend(loc='upper right')\n",
    "        axes[1].grid(color='g', linestyle=':', linewidth=0.3)\n",
    "\n",
    "        axes[2].plot(tmp['millisSinceGpsEpoch'], tmp['millis_diff'], label='millis_diff')\n",
    "        axes[2].legend(loc='upper right')\n",
    "        axes[2].grid(color='g', linestyle=':', linewidth=0.3)\n",
    "\n",
    "        axes[3].plot(tmp['millisSinceGpsEpoch'], tmp['err'], label='err')\n",
    "        axes[3].legend(loc='upper right')\n",
    "        axes[3].grid(color='g', linestyle=':', linewidth=0.3)\n",
    "\n",
    "        fig.suptitle(phone, fontsize=16)\n",
    "        fig.savefig(f'{output_dir}/{phone}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-latter",
   "metadata": {},
   "source": [
    "# 自前再構成baselineに更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "upper-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, sub, gt = get_data()\n",
    "gt['phone'] = gt['collectionName'] + '_' + gt['phoneName']\n",
    "\n",
    "train = update_baseline(train, pd.read_csv('../output/prep/baseline_g1_v001/result.csv'))\n",
    "train = update_baseline(train, pd.read_csv('../output/prep/baseline_g2_v003/result.csv'))\n",
    "train = update_baseline(train, pd.read_csv('../output/prep/baseline_g3_v003/result.csv'))\n",
    "train = update_baseline(train, pd.read_csv('../output/prep/baseline_g4_v002/result.csv'))\n",
    "\n",
    "train = train[train['collectionName'].isin(target)].copy()\n",
    "train = train.sort_values(['phone', 'millisSinceGpsEpoch']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cordless-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sp0_pred = pd.read_csv('../output/prep/speed0_pred_v001/train_sp0_pred.csv', usecols=['phone', 'millisSinceGpsEpoch', 'isSpeed0'])\n",
    "train = train.merge(train_sp0_pred, on=['phone', 'millisSinceGpsEpoch'], how='left')\n",
    "\n",
    "dp_train = pd.read_csv('../output/prep/rel_pred_v002/train_result.csv')\n",
    "train = train.merge(dp_train[['millisSinceGpsEpoch', 'phone', 'lat_diff', 'lng_diff']], on=['millisSinceGpsEpoch', 'phone'], how='left')\n",
    "train.loc[train['isSpeed0']==1, ['lat_diff', 'lng_diff']] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "compatible-construction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distance_diff(df):\n",
    "    df['latDeg_prev'] = df['latDeg'].shift(1)\n",
    "    df['latDeg_next'] = df['latDeg'].shift(-1)\n",
    "    df['lngDeg_prev'] = df['lngDeg'].shift(1)\n",
    "    df['lngDeg_next'] = df['lngDeg'].shift(-1)\n",
    "    df['phone_prev'] = df['phone'].shift(1)\n",
    "    df['phone_next'] = df['phone'].shift(-1)\n",
    "    \n",
    "    df['dist_prev'] = calc_haversine(df['latDeg'], df['lngDeg'], df['latDeg_prev'], df['lngDeg_prev'])\n",
    "    df['dist_next'] = calc_haversine(df['latDeg'], df['lngDeg'], df['latDeg_next'], df['lngDeg_next'])\n",
    "    \n",
    "    df.loc[df['phone']!=df['phone_prev'], ['latDeg_prev', 'lngDeg_prev', 'dist_prev']] = np.nan\n",
    "    df.loc[df['phone']!=df['phone_next'], ['latDeg_next', 'lngDeg_next', 'dist_next']] = np.nan\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "center-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reject outlier\n",
    "train = add_distance_diff(train)\n",
    "train.loc[((train['dist_prev'] > ro_th) & (train['dist_next'] > ro_th)), ['latDeg', 'lngDeg']] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fourth-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_remove_point(df):\n",
    "    out_df = pd.DataFrame()\n",
    "    phones = df['phone'].unique()\n",
    "    \n",
    "    for phone in phones:\n",
    "        tmp = df[df['phone']==phone].copy()\n",
    "        tmp = tmp.sort_values('millisSinceGpsEpoch')\n",
    "        tmp = tmp.reset_index().set_index('millisSinceGpsEpoch')\n",
    "        tmp[['latDeg', 'lngDeg']] = tmp[['latDeg', 'lngDeg']].interpolate(method='index', limit_area='inside')\n",
    "        tmp = tmp.sort_values('index')\n",
    "        tmp = tmp.reset_index().set_index('index')\n",
    "        out_df = out_df.append(tmp)\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "soviet-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = interpolate_remove_point(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "specialized-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_map(train, f'{OUTPUT}/train/map/before')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "unlimited-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_th_data(df):\n",
    "    def quantile_mean(s):\n",
    "        lth, uth = np.percentile(s, [5, 95]) \n",
    "        return s[(s>lth) & (s<uth)].mean()\n",
    "    def quantile_std(s):\n",
    "        lth, uth = np.percentile(s, [5, 95]) \n",
    "        return s[(s>lth) & (s<uth)].std()\n",
    "    \n",
    "    window = 60\n",
    "    sigma = 2\n",
    "    output_df = pd.DataFrame()\n",
    "    \n",
    "    df = df.sort_values('millisSinceGpsEpoch').reset_index(drop=True)\n",
    "    for idx in df.index:\n",
    "        tmp = df[idx : idx + window].copy()\n",
    "        if not np.isnan(tmp.at[idx, 'latDeg']):        \n",
    "            tmp['lat_base'] = tmp['lat_diff'].shift(1)\n",
    "            tmp['lng_base'] = tmp['lng_diff'].shift(1)\n",
    "            tmp.loc[idx, 'lat_base'] = tmp.loc[idx, 'latDeg']\n",
    "            tmp.loc[idx, 'lng_base'] = tmp.loc[idx, 'lngDeg']\n",
    "            tmp['lat_base'] = tmp['lat_base'].cumsum()\n",
    "            tmp['lng_base'] = tmp['lng_base'].cumsum()\n",
    "            output_df = output_df.append(tmp[['phone', 'millisSinceGpsEpoch', 'lat_base', 'lng_base']])\n",
    "\n",
    "    df = df.sort_values('millisSinceGpsEpoch', ascending=False).reset_index(drop=True)\n",
    "    for idx in df.index:\n",
    "        tmp = df[idx : idx + window].copy()\n",
    "        if not np.isnan(tmp.at[idx, 'latDeg']):        \n",
    "            tmp['lat_base'] = -tmp['lat_diff']\n",
    "            tmp['lng_base'] = -tmp['lng_diff']\n",
    "            tmp.loc[idx, 'lat_base'] = tmp.loc[idx, 'latDeg']\n",
    "            tmp.loc[idx, 'lng_base'] = tmp.loc[idx, 'lngDeg']\n",
    "            tmp['lat_base'] = tmp['lat_base'].cumsum()\n",
    "            tmp['lng_base'] = tmp['lng_base'].cumsum()\n",
    "            output_df = output_df.append(tmp[['phone', 'millisSinceGpsEpoch', 'lat_base', 'lng_base']])\n",
    "    \n",
    "    output_df = output_df.groupby(['phone','millisSinceGpsEpoch']).agg({'lat_base':[quantile_mean, quantile_std], 'lng_base':[quantile_mean, quantile_std]}).reset_index()\n",
    "    output_df.columns = ['phone', 'millisSinceGpsEpoch', 'lat_base_mean', 'lat_base_std', 'lng_base_mean', 'lng_base_std']\n",
    "\n",
    "    output_df['lat_uth'] = output_df['lat_base_mean'] + (output_df['lat_base_std'] * sigma)\n",
    "    output_df['lat_lth'] = output_df['lat_base_mean'] - (output_df['lat_base_std'] * sigma)\n",
    "    output_df['lng_uth'] = output_df['lng_base_mean'] + (output_df['lng_base_std'] * sigma)\n",
    "    output_df['lng_lth'] = output_df['lng_base_mean'] - (output_df['lng_base_std'] * sigma)\n",
    "\n",
    "    return output_df[['millisSinceGpsEpoch', 'lat_uth', 'lat_lth', 'lng_uth' , 'lng_lth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "opposed-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_outlier_by_base_trajectory(df):\n",
    "    output_df = pd.DataFrame()\n",
    "    for phone in df['phone'].unique():\n",
    "        tmp = df[df['phone']==phone].copy()\n",
    "        th_data = make_th_data(tmp)\n",
    "        tmp = tmp.merge(th_data, on=['millisSinceGpsEpoch'], how='left')\n",
    "        reject_idx = tmp[(tmp['latDeg']>tmp['lat_uth']) | (tmp['latDeg']<tmp['lat_lth']) | (tmp['lngDeg']>tmp['lng_uth']) | (tmp['lngDeg']<tmp['lng_lth'])].index\n",
    "        tmp.loc[reject_idx, 'latDeg'] = np.nan\n",
    "        tmp.loc[reject_idx, 'lngDeg'] = np.nan\n",
    "        output_df = output_df.append(tmp)\n",
    "        print(phone, len(reject_idx))\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "separate-trading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-14-US-MTV-1_Pixel4 120\n",
      "2020-05-14-US-MTV-1_Pixel4XLModded 148\n",
      "2020-05-14-US-MTV-2_Pixel4 80\n",
      "2020-05-14-US-MTV-2_Pixel4XLModded 59\n",
      "2020-05-21-US-MTV-1_Pixel4 153\n",
      "2020-05-21-US-MTV-2_Pixel4 104\n",
      "2020-05-21-US-MTV-2_Pixel4XL 133\n",
      "2020-05-29-US-MTV-1_Pixel4 123\n",
      "2020-05-29-US-MTV-1_Pixel4XL 97\n",
      "2020-05-29-US-MTV-1_Pixel4XLModded 120\n",
      "2020-05-29-US-MTV-2_Pixel4 136\n",
      "2020-05-29-US-MTV-2_Pixel4XL 150\n",
      "2020-06-04-US-MTV-1_Pixel4 113\n",
      "2020-06-04-US-MTV-1_Pixel4XL 116\n",
      "2020-06-04-US-MTV-1_Pixel4XLModded 127\n",
      "2020-06-05-US-MTV-1_Pixel4 235\n",
      "2020-06-05-US-MTV-1_Pixel4XL 202\n",
      "2020-06-05-US-MTV-1_Pixel4XLModded 125\n",
      "2020-06-05-US-MTV-2_Pixel4 117\n",
      "2020-06-05-US-MTV-2_Pixel4XL 129\n",
      "2020-06-11-US-MTV-1_Pixel4 138\n",
      "2020-06-11-US-MTV-1_Pixel4XL 105\n",
      "2020-07-08-US-MTV-1_Pixel4 197\n",
      "2020-07-08-US-MTV-1_Pixel4XL 103\n",
      "2020-07-08-US-MTV-1_Pixel4XLModded 117\n",
      "2020-07-17-US-MTV-1_Mi8 15\n",
      "2020-07-17-US-MTV-2_Mi8 0\n",
      "2020-08-03-US-MTV-1_Mi8 43\n",
      "2020-08-03-US-MTV-1_Pixel4 168\n",
      "2020-08-06-US-MTV-2_Mi8 1\n",
      "2020-08-06-US-MTV-2_Pixel4 125\n",
      "2020-08-06-US-MTV-2_Pixel4XL 90\n",
      "2020-09-04-US-SF-1_Mi8 3\n",
      "2020-09-04-US-SF-1_Pixel4 199\n",
      "2020-09-04-US-SF-1_Pixel4XL 101\n",
      "2020-09-04-US-SF-2_Mi8 2\n",
      "2020-09-04-US-SF-2_Pixel4 256\n",
      "2020-09-04-US-SF-2_Pixel4XL 111\n",
      "2021-01-04-US-RWC-1_Pixel4 248\n",
      "2021-01-04-US-RWC-1_Pixel4Modded 279\n",
      "2021-01-04-US-RWC-1_Pixel4XL 302\n",
      "2021-01-04-US-RWC-1_Pixel5 257\n",
      "2021-01-04-US-RWC-2_Pixel4 226\n",
      "2021-01-04-US-RWC-2_Pixel4Modded 311\n",
      "2021-01-04-US-RWC-2_Pixel4XL 226\n",
      "2021-01-04-US-RWC-2_Pixel5 200\n",
      "2021-01-05-US-SVL-1_Mi8 0\n",
      "2021-01-05-US-SVL-1_Pixel4 134\n",
      "2021-01-05-US-SVL-1_Pixel4XL 212\n",
      "2021-01-05-US-SVL-1_Pixel5 198\n",
      "2021-01-05-US-SVL-2_Pixel4 126\n",
      "2021-01-05-US-SVL-2_Pixel4Modded 66\n",
      "2021-01-05-US-SVL-2_Pixel4XL 181\n",
      "2021-04-15-US-MTV-1_Pixel4 176\n",
      "2021-04-15-US-MTV-1_Pixel4Modded 153\n",
      "2021-04-15-US-MTV-1_Pixel5 172\n",
      "2021-04-15-US-MTV-1_SamsungS20Ultra 178\n"
     ]
    }
   ],
   "source": [
    "train = reject_outlier_by_base_trajectory(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "virtual-intersection",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_map(train, f'{OUTPUT}/train/map/after')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
