{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "secret-preparation",
   "metadata": {},
   "source": [
    "# exp017\n",
    "バミューダトライアングル 線形補間検討（他のphoneも使いながら）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "requested-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import pathlib\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import itertools\n",
    "import lightgbm as lgb\n",
    "from optuna.integration import lightgbm as optuna_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-royalty",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "packed-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculates the great circle distance between two points\n",
    "    on the earth. Inputs are array-like and specified in decimal degrees.\n",
    "    \"\"\"\n",
    "    RADIUS = 6_367_000\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + \\\n",
    "        np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    dist = 2 * RADIUS * np.arcsin(a**0.5)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "infectious-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_trafic(df, center, zoom=9):\n",
    "    fig = px.scatter_mapbox(df,\n",
    "                            \n",
    "                            # Here, plotly gets, (x,y) coordinates\n",
    "                            lat=\"latDeg\",\n",
    "                            lon=\"lngDeg\",\n",
    "                            \n",
    "                            #Here, plotly detects color of series\n",
    "                            color=\"phoneName\",\n",
    "                            labels=\"phoneName\",\n",
    "                            \n",
    "                            zoom=zoom,\n",
    "                            center=center,\n",
    "                            height=600,\n",
    "                            width=800)\n",
    "    fig.update_layout(mapbox_style='stamen-terrain')\n",
    "    fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
    "    fig.update_layout(title_text=\"GPS trafic\")\n",
    "    fig.show()\n",
    "    \n",
    "def visualize_collection(df, collection):\n",
    "    target_df = df[df['collectionName']==collection].copy()\n",
    "    lat_center = target_df['latDeg'].mean()\n",
    "    lng_center = target_df['lngDeg'].mean()\n",
    "    center = {\"lat\":lat_center, \"lon\":lng_center}\n",
    "    \n",
    "    visualize_trafic(target_df, center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "intimate-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_truth\n",
    "def get_ground_truth():\n",
    "    p = pathlib.Path(INPUT)\n",
    "    gt_files = list(p.glob('train/*/*/ground_truth.csv'))\n",
    "\n",
    "    gts = []\n",
    "    for gt_file in gt_files:\n",
    "        gts.append(pd.read_csv(gt_file))\n",
    "    ground_truth = pd.concat(gts)\n",
    "\n",
    "    return ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "minimal-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile50(x):\n",
    "    return np.percentile(x, 50)\n",
    "def percentile95(x):\n",
    "    return np.percentile(x, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "solar-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_result:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.gt = get_ground_truth()\n",
    "        self.bl = pd.read_csv(INPUT + '/' + 'baseline_locations_train.csv')\n",
    "        \n",
    "        self.gt = self.gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n",
    "        self.df = self.df.merge(self.gt, on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n",
    "        self.df['phone'] = self.df['collectionName'] + '_' + self.df['phoneName']\n",
    "        self.df['err'] =  calc_haversine(self.df['latDeg_gt'], self.df['lngDeg_gt'], self.df['latDeg'], self.df['lngDeg'])\n",
    "        \n",
    "        self.phone_res = self.calc_err('phone')\n",
    "        self.clc_res = self.calc_err('collectionName')\n",
    "        self.phonename_res = self.calc_err('phoneName')\n",
    "        \n",
    "    def calc_err(self, by):\n",
    "        res = self.df.groupby(by)['err'].agg([percentile50, percentile95])\n",
    "        res['p50_p90_mean'] = (res['percentile50'] + res['percentile95']) / 2\n",
    "        return res\n",
    "    \n",
    "    @property\n",
    "    def score(self):\n",
    "        return self.phone_res['p50_p90_mean'].mean()\n",
    "    @property\n",
    "    def raw_data(self):\n",
    "        return self.df\n",
    "    @property\n",
    "    def err(self):\n",
    "        return self.phone_res\n",
    "    @property\n",
    "    def collection_err(self):\n",
    "        return self.clc_res\n",
    "    @property\n",
    "    def phonename_err(self):\n",
    "        return self.phonename_res\n",
    "    \n",
    "    def viz_map(self, collection, show_gt=True, show_bl=True):\n",
    "        tmp = self.df[self.df['collectionName']==collection][['collectionName', 'phoneName', 'latDeg', 'lngDeg']]\n",
    "        tmp2 = self.df[self.df['collectionName']==collection][['collectionName', 'phoneName', 'latDeg_gt', 'lngDeg_gt']]\n",
    "        tmp2 = tmp2.rename(columns={'latDeg_gt':'latDeg', 'lngDeg_gt':'lngDeg'})\n",
    "        tmp2['phoneName'] = tmp2['phoneName'] + '_GT'\n",
    "        tmp3 = self.bl[self.bl['collectionName']==collection][['collectionName', 'phoneName', 'latDeg', 'lngDeg']]\n",
    "        tmp3['phoneName'] = tmp3['phoneName'] + '_BL'\n",
    "        \n",
    "        if show_gt:\n",
    "            tmp = tmp.append(tmp2)\n",
    "        if show_bl:\n",
    "            tmp = tmp.append(tmp3)\n",
    "        visualize_collection(tmp, collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-earthquake",
   "metadata": {},
   "source": [
    "# data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "precise-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb_path\n",
    "\n",
    "def get_nb_name():\n",
    "    nb_path = ipynb_path.get()\n",
    "    nb_name = nb_path.rsplit('/',1)[1].replace('.ipynb','')\n",
    "    return nb_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "favorite-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory setting\n",
    "nb_name = get_nb_name()\n",
    "INPUT = '../input/google-smartphone-decimeter-challenge'\n",
    "OUTPUT = '../output/' + nb_name\n",
    "os.makedirs(OUTPUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "instant-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_train = pd.read_csv(INPUT + '/' + 'baseline_locations_train.csv')\n",
    "base_test = pd.read_csv(INPUT + '/' + 'baseline_locations_test.csv')\n",
    "sample_sub = pd.read_csv(INPUT + '/' + 'sample_submission.csv')\n",
    "ground_truth = get_ground_truth()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-entertainment",
   "metadata": {},
   "source": [
    "# baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "homeless-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['2021-04-22-US-SJC-1', '2021-04-29-US-SJC-2', '2021-04-28-US-SJC-1', '2021-04-22-US-SJC-2', '2021-04-29-US-SJC-3']\n",
    "train = base_train[base_train['collectionName'].isin(target)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ahead-screw",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2021-04-22-US-SJC-1', '2021-04-28-US-SJC-1',\n",
       "       '2021-04-29-US-SJC-2'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clc = train.collectionName.unique()\n",
    "train_clc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-gabriel",
   "metadata": {},
   "source": [
    "# reject_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cognitive-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distance_diff(df):\n",
    "    df['latDeg_prev'] = df['latDeg'].shift(1)\n",
    "    df['latDeg_next'] = df['latDeg'].shift(-1)\n",
    "    df['lngDeg_prev'] = df['lngDeg'].shift(1)\n",
    "    df['lngDeg_next'] = df['lngDeg'].shift(-1)\n",
    "    df['phone_prev'] = df['phone'].shift(1)\n",
    "    df['phone_next'] = df['phone'].shift(-1)\n",
    "    \n",
    "    df['dist_prev'] = calc_haversine(df['latDeg'], df['lngDeg'], df['latDeg_prev'], df['lngDeg_prev'])\n",
    "    df['dist_next'] = calc_haversine(df['latDeg'], df['lngDeg'], df['latDeg_next'], df['lngDeg_next'])\n",
    "    \n",
    "    df.loc[df['phone']!=df['phone_prev'], ['latDeg_prev', 'lngDeg_prev', 'dist_prev']] = np.nan\n",
    "    df.loc[df['phone']!=df['phone_next'], ['latDeg_next', 'lngDeg_next', 'dist_next']] = np.nan\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "precise-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reject outlier\n",
    "train_ro = train.copy()\n",
    "train_ro = add_distance_diff(train_ro)\n",
    "th = 50\n",
    "train_ro.loc[((train_ro['dist_prev'] > th) & (train_ro['dist_next'] > th)), ['latDeg', 'lngDeg']] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-tunnel",
   "metadata": {},
   "source": [
    "# kalman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "split-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simdkalman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "copyrighted-uruguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1.0\n",
    "state_transition = np.array([[1, 0, T, 0, 0.5 * T ** 2, 0], [0, 1, 0, T, 0, 0.5 * T ** 2], [0, 0, 1, 0, T, 0],\n",
    "                             [0, 0, 0, 1, 0, T], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1]])\n",
    "process_noise = np.diag([1e-5, 1e-5, 5e-6, 5e-6, 1e-6, 1e-6]) + np.ones((6, 6)) * 1e-9\n",
    "observation_model = np.array([[1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0]])\n",
    "observation_noise = np.diag([5e-5, 5e-5]) + np.ones((2, 2)) * 1e-9\n",
    "\n",
    "kf = simdkalman.KalmanFilter(\n",
    "        state_transition = state_transition,\n",
    "        process_noise = process_noise,\n",
    "        observation_model = observation_model,\n",
    "        observation_noise = observation_noise)\n",
    "\n",
    "def apply_kf_smoothing(df, kf_=kf):\n",
    "    unique_paths = df[['collectionName', 'phoneName']].drop_duplicates().to_numpy()\n",
    "    for collection, phone in unique_paths:\n",
    "        cond = np.logical_and(df['collectionName'] == collection, df['phoneName'] == phone)\n",
    "        data = df[cond][['latDeg', 'lngDeg']].to_numpy()\n",
    "        data = data.reshape(1, len(data), 2)\n",
    "        smoothed = kf_.smooth(data)\n",
    "        df.loc[cond, 'latDeg'] = smoothed.states.mean[0, :, 0]\n",
    "        df.loc[cond, 'lngDeg'] = smoothed.states.mean[0, :, 1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "welsh-dispatch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_based_on_grid(target_df, target_gt, th):\n",
    "    for idx in target_df.index:\n",
    "        lat = target_df.at[idx, 'latDeg']\n",
    "        lng = target_df.at[idx, 'lngDeg']\n",
    "        s = target_df.at[idx, 'millisSinceGpsEpoch']\n",
    "        \n",
    "        if np.isnan(lat):\n",
    "            continue\n",
    "        else:\n",
    "            target_gt['latDeg_pred'] = lat\n",
    "            target_gt['lngDeg_pred'] = lng\n",
    "            target_gt['dist'] = calc_haversine(target_gt['latDeg'], target_gt['lngDeg'], target_gt['latDeg_pred'], target_gt['lngDeg_pred'])\n",
    "            closest_dist = target_gt['dist'].min()\n",
    "            if closest_dist > th:\n",
    "                target_df.at[idx, 'latDeg'] = np.nan\n",
    "                target_df.at[idx, 'lngDeg'] = np.nan\n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-destination",
   "metadata": {},
   "source": [
    "# 線形補間の検討"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "exclusive-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_remove_point(df):\n",
    "    out_df = pd.DataFrame()\n",
    "    collections = df['collectionName'].unique()\n",
    "    \n",
    "    for collection in collections:\n",
    "        tmp = df[df['collectionName']==collection].copy()\n",
    "        tmp = tmp.sort_values('millisSinceGpsEpoch')\n",
    "        tmp = tmp.reset_index().set_index('millisSinceGpsEpoch')\n",
    "        tmp[['latDeg', 'lngDeg']] = tmp[['latDeg', 'lngDeg']].interpolate(method='index', limit_area='inside')\n",
    "        tmp = tmp.sort_values('index')\n",
    "        tmp = tmp.reset_index().set_index('index')\n",
    "        out_df = out_df.append(tmp)\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "level-liechtenstein",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 13.026077215880619\n",
      "9 12.906761936231264\n",
      "8 12.49913990655358\n",
      "7 12.134653816567171\n",
      "6 11.72298310768692\n",
      "5 11.503585221891832\n",
      "4 11.329802647115933\n",
      "3 11.186257093044448\n",
      "2 11.521743512957997\n",
      "1 12.745417545551424\n"
     ]
    }
   ],
   "source": [
    "for th in [10,9,8,7,6,5,4,3,2,1]:\n",
    "    train_ro_rg = train_ro.copy()\n",
    "    target_gt = ground_truth[ground_truth['collectionName'].isin(target)].copy()\n",
    "    train_ro_rg = remove_based_on_grid(train_ro_rg, target_gt, th)\n",
    "    train_ro_rg = interpolate_remove_point(train_ro_rg)\n",
    "    train_ro_rg_kf = train_ro_rg.copy()\n",
    "    train_ro_rg_kf = apply_kf_smoothing(train_ro_rg_kf)\n",
    "    result = train_result(train_ro_rg_kf)\n",
    "    score = result.score\n",
    "    print(th, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-riding",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
