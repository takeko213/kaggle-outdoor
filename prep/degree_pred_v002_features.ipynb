{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "natural-morrison",
   "metadata": {},
   "source": [
    "# degree_pred_v002\n",
    "https://www.kaggle.com/t88take/estimating-the-direction-with-a-magnetic-se-e46cec  \n",
    "\n",
    "の計算の誤り修正・スムージングウインドウを1000から500に  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "amber-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipynb_path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', 200)\n",
    "from math import * \n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "constitutional-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nb_name():\n",
    "    nb_path = ipynb_path.get()\n",
    "    nb_name = nb_path.rsplit('/',1)[1].replace('.ipynb','')\n",
    "    return nb_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vocal-jenny",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_trafic(df, center, zoom=9):\n",
    "    fig = px.scatter_mapbox(df,\n",
    "                            \n",
    "                            # Here, plotly gets, (x,y) coordinates\n",
    "                            lat=\"latDeg\",\n",
    "                            lon=\"lngDeg\",\n",
    "                            \n",
    "                            #Here, plotly detects color of series\n",
    "                            color=\"phoneName\",\n",
    "                            labels=\"phoneName\",\n",
    "                            \n",
    "                            zoom=zoom,\n",
    "                            center=center,\n",
    "                            height=1000,\n",
    "                            width=2000)\n",
    "    fig.update_layout(mapbox_style='stamen-terrain')\n",
    "    fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
    "    fig.update_layout(title_text=\"GPS trafic\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interested-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_collection(df, collection):\n",
    "    target_df = df[df['collectionName']==collection].copy()\n",
    "    lat_center = target_df['latDeg'].mean()\n",
    "    lng_center = target_df['lngDeg'].mean()\n",
    "    center = {\"lat\":lat_center, \"lon\":lng_center}\n",
    "    \n",
    "    visualize_trafic(target_df, center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "overhead-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculates the great circle distance between two points\n",
    "    on the earth. Inputs are array-like and specified in decimal degrees.\n",
    "    \"\"\"\n",
    "    RADIUS = 6_367_000\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + \\\n",
    "        np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    dist = 2 * RADIUS * np.arcsin(a**0.5)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "checked-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowpass filter\n",
    "\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "order = 3\n",
    "fs = 50.0\n",
    "cutoff = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "nuclear-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Offset correction\n",
    "# refarence https://github.com/J-ROCKET-BOY/SS-Fitting\n",
    "\n",
    "def SS_fit(data) : \n",
    "\n",
    "    x = data[:,[0]]\n",
    "    y = data[:,[1]]\n",
    "    z = data[:,[2]]\n",
    "\n",
    "    data_len = len(x)\n",
    "    \n",
    "    x2 = np.power(x,2)\n",
    "    y2 = np.power(y,2)\n",
    "    z2 = np.power(z,2)\n",
    "\n",
    "    r1 = -x*(x2+y2+z2)\n",
    "    r2= -y*(x2+y2+z2)\n",
    "    r3 = -z*(x2+y2+z2)\n",
    "    r4 = -(x2+y2+z2)\n",
    "\n",
    "    left = np.array([[np.sum(x2),np.sum(x*y),np.sum(x*z),np.sum(x)],\n",
    "                     [np.sum(x*y),np.sum(y2),np.sum(y*z),np.sum(y)],\n",
    "                     [np.sum(x*z),np.sum(y*z),np.sum(z2),np.sum(z)],\n",
    "                     [np.sum(x), np.sum(y), np.sum(z), data_len]])\n",
    "    \n",
    "    right = np.array([np.sum(r1),\n",
    "                      np.sum(r2),\n",
    "                      np.sum(r3),\n",
    "                      np.sum(r4)])\n",
    "    \n",
    "    si = np.dot(np.linalg.inv(left),right)\n",
    "\n",
    "    x0 = (-1/2)* si[0]\n",
    "    y0 = (-1/2)* si[1]\n",
    "    z0 = (-1/2)* si[2]\n",
    "    \n",
    "    return np.array([x0,y0,z0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "swiss-collar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vincenty's formulae\n",
    "# refarence https://qiita.com/r-fuji/items/99ca549b963cedc106ab\n",
    "\n",
    "def vincenty_inverse(lat1, lon1, lat2, lon2):\n",
    "\n",
    "    # Not advanced\n",
    "    if isclose(lat1, lat2) and isclose(lon1, lon2):\n",
    "        return False\n",
    "    \n",
    "    # WGS84\n",
    "    a = 6378137.0\n",
    "    ƒ = 1 / 298.257223563\n",
    "    b = (1 - ƒ) * a\n",
    "\n",
    "    lat_1 = atan((1 - ƒ) * tan(radians(lat1)))\n",
    "    lat_2 = atan((1 - ƒ) * tan(radians(lat2)))\n",
    "    \n",
    "    lon_diff = radians(lon2) - radians(lon1)\n",
    "    λ = lon_diff\n",
    "\n",
    "    for i in range(1000):\n",
    "        sinλ = sin(λ)\n",
    "        cosλ = cos(λ)\n",
    "        sinσ = sqrt((cos(lat_2) * sinλ) ** 2 + (cos(lat_1) * sin(lat_2) - sin(lat_1) * cos(lat_2) * cosλ) ** 2)\n",
    "        cosσ = sin(lat_1) * sin(lat_2) + cos(lat_1) * cos(lat_2) * cosλ\n",
    "        σ = atan2(sinσ, cosσ)\n",
    "        sinα = cos(lat_1) * cos(lat_2) * sinλ / sinσ\n",
    "        cos2α = 1 - sinα ** 2\n",
    "        cos2σm = cosσ - 2 * sin(lat_1) * sin(lat_2) / cos2α\n",
    "        C = ƒ / 16 * cos2α * (4 + ƒ * (4 - 3 * cos2α))\n",
    "        λʹ = λ\n",
    "        λ = lon_diff + (1 - C) * ƒ * sinα * (σ + C * sinσ * (cos2σm + C * cosσ * (-1 + 2 * cos2σm ** 2)))\n",
    "        \n",
    "        if abs(λ - λʹ) <= 1e-12:\n",
    "            break\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    α = atan2(cos(lat_2) * sinλ, cos(lat_1) * sin(lat_2) - sin(lat_1) * cos(lat_2) * cosλ)\n",
    "\n",
    "    if α < 0:\n",
    "        α = α + pi * 2\n",
    "\n",
    "    return degrees(α)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hidden-collectible",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc3(row):\n",
    "    deg = - degrees(atan2(-1*row['calc2'],row['calc1']))\n",
    "    if deg < 0:\n",
    "        deg += 360\n",
    "    return deg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "amended-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_degree_by_gt(df):\n",
    "    phones = df['phone'].unique()\n",
    "    df['deg'] = np.nan\n",
    "    \n",
    "    for idx in range(len(df)-1):\n",
    "        if df.at[idx, 'phone'] != df.at[idx+1, 'phone']:\n",
    "            continue\n",
    "            \n",
    "        lat = df.at[idx, 'latDeg_gt']\n",
    "        lng = df.at[idx, 'lngDeg_gt']\n",
    "        lat_next = df.at[idx+1, 'latDeg_gt']\n",
    "        lng_next = df.at[idx+1, 'lngDeg_gt']\n",
    "        \n",
    "        res = vincenty_inverse(lat, lng, lat_next, lng_next)\n",
    "        if res:\n",
    "            df.at[idx, 'deg'] = res\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "exact-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_degree_by_imu(df, accel, mag):\n",
    "    df['phone'] = df['collectionName'] + '_' + df['phoneName']\n",
    "    accel['phone'] = accel['collectionName'] + '_' + accel['phoneName']\n",
    "    mag['phone'] = mag['collectionName'] + '_' + mag['phoneName']\n",
    "    \n",
    "    # utc -> gps\n",
    "    accel['millisSinceGpsEpoch'] = accel['utcTimeMillis'] - 315964800000 + 18000\n",
    "    mag['millisSinceGpsEpoch'] = mag['utcTimeMillis'] - 315964800000 + 18000\n",
    "    \n",
    "    # resampling追加\n",
    "    df['secondSinceGpsEpoch'] = df['millisSinceGpsEpoch'] // 1000\n",
    "    accel['secondSinceGpsEpoch'] = accel['millisSinceGpsEpoch'] // 1000\n",
    "    mag['secondSinceGpsEpoch'] = mag['millisSinceGpsEpoch'] // 1000\n",
    "    \n",
    "    # clipping\n",
    "    accel[['UncalAccelXMps2', 'UncalAccelYMps2', 'UncalAccelZMps2']] = accel.groupby('phone')['UncalAccelXMps2', 'UncalAccelYMps2', 'UncalAccelZMps2'].transform(lambda x: x.clip(x.quantile(0.001), x.quantile(0.999)))\n",
    "    mag[['UncalMagXMicroT', 'UncalMagYMicroT', 'UncalMagZMicroT']] = mag.groupby('phone')['UncalMagXMicroT', 'UncalMagYMicroT', 'UncalMagZMicroT'].transform(lambda x: x.clip(x.quantile(0.001), x.quantile(0.999)))\n",
    "    \n",
    "    #     acce filtering and smooting\n",
    "    accel[\"global_x\"] = accel[\"UncalAccelZMps2\"]\n",
    "    accel[\"global_y\"] = accel[\"UncalAccelXMps2\"]\n",
    "    accel[\"global_z\"] = accel[\"UncalAccelYMps2\"]\n",
    "    accel[\"x_f\"] = butter_lowpass_filter(accel[\"global_x\"], cutoff, fs, order)\n",
    "    accel[\"y_f\"] = butter_lowpass_filter(accel[\"global_y\"], cutoff, fs, order)\n",
    "    accel[\"z_f\"] = butter_lowpass_filter(accel[\"global_z\"], cutoff, fs, order)\n",
    "    \n",
    "    mag[\"global_mx\"] = mag[\"UncalMagZMicroT\"]\n",
    "    mag[\"global_my\"] = mag[\"UncalMagXMicroT\"]\n",
    "    mag[\"global_mz\"] = mag[\"UncalMagYMicroT\"]\n",
    "\n",
    "    \n",
    "    output_df = pd.DataFrame()\n",
    "    for phone in mag['phone'].unique():\n",
    "        df_tmp = df[df['phone']==phone]\n",
    "        accel_tmp = accel[accel['phone']==phone].copy()\n",
    "        mag_tmp = mag[mag['phone']==phone].copy()\n",
    "    \n",
    "        smooth_range = 500\n",
    "        accel_tmp[\"x_f\"] = accel_tmp.groupby('phone')[\"x_f\"].rolling(smooth_range, center=True, min_periods=1).mean().values\n",
    "        accel_tmp[\"y_f\"] = accel_tmp.groupby('phone')[\"y_f\"].rolling(smooth_range, center=True, min_periods=1).mean().values\n",
    "        accel_tmp[\"z_f\"] = accel_tmp.groupby('phone')[\"z_f\"].rolling(smooth_range, center=True, min_periods=1).mean().values\n",
    "\n",
    "        mag_tmp[\"global_mx\"] = mag_tmp.groupby('phone')[\"global_mx\"].rolling(smooth_range,  min_periods=1).mean().values\n",
    "        mag_tmp[\"global_my\"] = mag_tmp.groupby('phone')[\"global_my\"].rolling(smooth_range,  min_periods=1).mean().values\n",
    "        mag_tmp[\"global_mz\"] = mag_tmp.groupby('phone')[\"global_mz\"].rolling(smooth_range,  min_periods=1).mean().values\n",
    "\n",
    "        offset = SS_fit(np.array(mag_tmp[[\"global_mx\",\"global_my\",\"global_mz\"]]))\n",
    "        mag_tmp[\"global_mx\"] = (mag_tmp[\"global_mx\"] - offset[0])*-1\n",
    "        mag_tmp[\"global_my\"] = mag_tmp[\"global_my\"] - offset[1]\n",
    "        mag_tmp[\"global_mz\"] = mag_tmp[\"global_mz\"] - offset[2]\n",
    "        \n",
    "        accel_tmp = accel_tmp.groupby(['phone', 'secondSinceGpsEpoch'])['x_f', 'y_f', 'z_f'].mean().reset_index()\n",
    "        accel_tmp.columns = ['phone', 'secondSinceGpsEpoch', 'x_f', 'y_f', 'z_f']\n",
    "    \n",
    "        mag_tmp = mag_tmp.groupby(['phone', 'secondSinceGpsEpoch'])['global_mx', 'global_my', 'global_mz'].mean().reset_index()\n",
    "        mag_tmp.columns = ['phone', 'secondSinceGpsEpoch', 'global_mx', 'global_my', 'global_mz']    \n",
    "\n",
    "        df_tmp = df_tmp.merge(accel_tmp, on=['phone', 'secondSinceGpsEpoch'], how='left')\n",
    "        df_tmp = df_tmp.merge(mag_tmp, on=['phone', 'secondSinceGpsEpoch'], how='left')\n",
    "        \n",
    "        start_mean_range = 10\n",
    "        x_start_mean = df_tmp[:start_mean_range][\"x_f\"].mean()\n",
    "        y_start_mean = df_tmp[:start_mean_range][\"y_f\"].mean()\n",
    "        z_start_mean = df_tmp[:start_mean_range][\"z_f\"].mean() \n",
    "\n",
    "        #     roll and picth, device tilt\n",
    "        r = atan(y_start_mean/z_start_mean)\n",
    "        p = atan(x_start_mean/(y_start_mean**2 + z_start_mean**2)**0.5)\n",
    "\n",
    "    #     calculation　degrees\n",
    "\n",
    "        df_tmp[\"calc1\"] = df_tmp[\"global_mx\"]*cos(p) + df_tmp[\"global_my\"]*sin(r)*sin(p) + df_tmp[\"global_mz\"]*sin(p)*cos(r)\n",
    "        df_tmp[\"calc2\"] = df_tmp[\"global_mz\"]*sin(r) - df_tmp[\"global_my\"]*cos(r)\n",
    "        df_tmp[\"calc_deg\"] = df_tmp.apply(calc3, axis=1)\n",
    "        output_df = output_df.append(df_tmp)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "municipal-hurricane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory setting\n",
    "nb_name = get_nb_name()\n",
    "INPUT = '../input/google-smartphone-decimeter-challenge'\n",
    "OUTPUT = '../output/prep/' + nb_name\n",
    "os.makedirs(OUTPUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-quarter",
   "metadata": {},
   "source": [
    "# データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "disciplinary-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_train = pd.read_csv(INPUT + '/prep/gnss/train/UncalAccel.csv')\n",
    "mag_train = pd.read_csv(INPUT + '/prep/gnss/train/UncalMag.csv')\n",
    "accel_test = pd.read_csv(INPUT + '/prep/gnss/test/UncalAccel.csv')\n",
    "mag_test = pd.read_csv(INPUT + '/prep/gnss/test/UncalMag.csv')\n",
    "train = pd.read_csv(INPUT + '/' + 'baseline_locations_train.csv')\n",
    "test = pd.read_csv(INPUT + '/' + 'baseline_locations_test.csv')\n",
    "ground_truth = pd.read_csv(INPUT + '/prep/ground_truth_train.csv')\n",
    "\n",
    "ground_truth = ground_truth.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n",
    "gt = ground_truth[['collectionName', 'phoneName', 'millisSinceGpsEpoch', 'latDeg_gt', 'lngDeg_gt', 'speedMps', 'courseDegree']].copy()\n",
    "train = train.merge(gt, on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-material",
   "metadata": {},
   "source": [
    "# IMUからdegを算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "finite-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = calc_degree_by_imu(train, accel_train, mag_train)\n",
    "test = calc_degree_by_imu(test, accel_test, mag_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-firewall",
   "metadata": {},
   "source": [
    "# 座標移動からdegを算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "binding-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "train = calc_degree_by_gt(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "demanding-bride",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(OUTPUT + '/train_degree_pred.csv', index=False)\n",
    "test.to_csv(OUTPUT + '/test_degree_pred.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
