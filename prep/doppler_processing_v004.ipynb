{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "impressive-imaging",
   "metadata": {},
   "source": [
    "# doppler_processing_v004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "loaded-contrast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import library\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import pathlib\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import itertools\n",
    "import lightgbm as lgb\n",
    "from optuna.integration import lightgbm as optuna_lgb\n",
    "import simdkalman\n",
    "import optuna\n",
    "import pyproj\n",
    "from pyproj import Proj, transform\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, confusion_matrix, accuracy_score, mean_squared_error\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acceptable-baker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb_path\n",
    "\n",
    "def get_nb_name():\n",
    "    nb_path = ipynb_path.get()\n",
    "    nb_name = nb_path.rsplit('/',1)[1].replace('.ipynb','')\n",
    "    return nb_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "inappropriate-suite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory setting\n",
    "nb_name = get_nb_name()\n",
    "INPUT = '../input/google-smartphone-decimeter-challenge'\n",
    "OUTPUT = '../output/prep/' + nb_name\n",
    "os.makedirs(OUTPUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-accounting",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "joint-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_score(df, gt):\n",
    "    gt = gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n",
    "    df = df.merge(gt, on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n",
    "    # calc_distance_error\n",
    "    df['err'] = calc_haversine(df['latDeg_gt'], df['lngDeg_gt'], df['latDeg'], df['lngDeg'])\n",
    "    # calc_evaluate_score\n",
    "    df['phone'] = df['collectionName'] + '_' + df['phoneName']\n",
    "    res = df.groupby('phone')['err'].agg([percentile50, percentile95])\n",
    "    res['p50_p90_mean'] = (res['percentile50'] + res['percentile95']) / 2 \n",
    "    score = res['p50_p90_mean'].mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "requested-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculates the great circle distance between two points\n",
    "    on the earth. Inputs are array-like and specified in decimal degrees.\n",
    "    \"\"\"\n",
    "    RADIUS = 6_367_000\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + \\\n",
    "        np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    dist = 2 * RADIUS * np.arcsin(a**0.5)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-canvas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_trafic(df, center, zoom=9):\n",
    "    fig = px.scatter_mapbox(df,\n",
    "                            \n",
    "                            # Here, plotly gets, (x,y) coordinates\n",
    "                            lat=\"latDeg\",\n",
    "                            lon=\"lngDeg\",\n",
    "                            \n",
    "                            #Here, plotly detects color of series\n",
    "                            color=\"phoneName\",\n",
    "                            labels=\"phoneName\",\n",
    "                            \n",
    "                            zoom=zoom,\n",
    "                            center=center,\n",
    "                            height=600,\n",
    "                            width=800)\n",
    "    fig.update_layout(mapbox_style='stamen-terrain')\n",
    "    fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
    "    fig.update_layout(title_text=\"GPS trafic\")\n",
    "    fig.show()\n",
    "    \n",
    "def visualize_collection(df, collection):\n",
    "    target_df = df[df['collectionName']==collection].copy()\n",
    "    lat_center = target_df['latDeg'].mean()\n",
    "    lng_center = target_df['lngDeg'].mean()\n",
    "    center = {\"lat\":lat_center, \"lon\":lng_center}\n",
    "    \n",
    "    visualize_trafic(target_df, center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "constant-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_truth\n",
    "def get_ground_truth():\n",
    "    p = pathlib.Path(INPUT)\n",
    "    gt_files = list(p.glob('train/*/*/ground_truth.csv'))\n",
    "\n",
    "    gts = []\n",
    "    for gt_file in gt_files:\n",
    "        gts.append(pd.read_csv(gt_file))\n",
    "    ground_truth = pd.concat(gts)\n",
    "\n",
    "    return ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fatty-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile50(x):\n",
    "    return np.percentile(x, 50)\n",
    "def percentile95(x):\n",
    "    return np.percentile(x, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "rising-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_result:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.gt = get_ground_truth()\n",
    "        self.bl = pd.read_csv(INPUT + '/' + 'baseline_locations_train.csv')\n",
    "        \n",
    "        self.gt = self.gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n",
    "        self.df = self.df.merge(self.gt, on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n",
    "        self.df['phone'] = self.df['collectionName'] + '_' + self.df['phoneName']\n",
    "        self.df['err'] =  calc_haversine(self.df['latDeg_gt'], self.df['lngDeg_gt'], self.df['latDeg'], self.df['lngDeg'])\n",
    "        \n",
    "        self.phone_res = self.calc_err('phone')\n",
    "        self.clc_res = self.calc_err('collectionName')\n",
    "        self.phonename_res = self.calc_err('phoneName')\n",
    "        \n",
    "    def calc_err(self, by):\n",
    "        res = self.df.groupby(by)['err'].agg([percentile50, percentile95])\n",
    "        res['p50_p90_mean'] = (res['percentile50'] + res['percentile95']) / 2\n",
    "        return res\n",
    "    \n",
    "    @property\n",
    "    def score(self):\n",
    "        return self.phone_res['p50_p90_mean'].mean()\n",
    "    @property\n",
    "    def raw_data(self):\n",
    "        return self.df\n",
    "    @property\n",
    "    def err(self):\n",
    "        return self.phone_res\n",
    "    @property\n",
    "    def collection_err(self):\n",
    "        return self.clc_res\n",
    "    @property\n",
    "    def phonename_err(self):\n",
    "        return self.phonename_res\n",
    "    \n",
    "    def viz_map(self, collection, show_gt=True, show_bl=True):\n",
    "        tmp = self.df[self.df['collectionName']==collection][['collectionName', 'phoneName', 'latDeg', 'lngDeg']]\n",
    "        tmp2 = self.df[self.df['collectionName']==collection][['collectionName', 'phoneName', 'latDeg_gt', 'lngDeg_gt']]\n",
    "        tmp2 = tmp2.rename(columns={'latDeg_gt':'latDeg', 'lngDeg_gt':'lngDeg'})\n",
    "        tmp2['phoneName'] = tmp2['phoneName'] + '_GT'\n",
    "        tmp3 = self.bl[self.bl['collectionName']==collection][['collectionName', 'phoneName', 'latDeg', 'lngDeg']]\n",
    "        tmp3['phoneName'] = tmp3['phoneName'] + '_BL'\n",
    "        \n",
    "        if show_gt:\n",
    "            tmp = tmp.append(tmp2)\n",
    "        if show_bl:\n",
    "            tmp = tmp.append(tmp3)\n",
    "        visualize_collection(tmp, collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "regulation-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    base_train = pd.read_csv(INPUT + '/' + 'baseline_locations_train.csv')\n",
    "    base_test = pd.read_csv(INPUT + '/' + 'baseline_locations_test.csv')\n",
    "    sample_sub = pd.read_csv(INPUT + '/' + 'sample_submission.csv')\n",
    "    ground_truth = get_ground_truth()\n",
    "    return base_train, base_test, sample_sub, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alternative-language",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz(df_, outdir):\n",
    "    outdir = OUTPUT + '/' + outdir\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    df = df_.copy()\n",
    "    df['d'] = np.sqrt(df['xVehVel']**2 + df['yVehVel']**2 + df['zVehVel']**2)\n",
    "    \n",
    "    for phone in df['phone'].unique():\n",
    "        gt_tmp = gt[gt['phone']==phone].copy()\n",
    "        tmp = df[df['phone']==phone].copy()\n",
    "\n",
    "        fig, axes = plt.subplots(figsize=(40, 15), nrows=3, sharex=True)\n",
    "        axes[0].plot(gt_tmp['millisSinceGpsEpoch'], gt_tmp['speedMps'], label='speed')\n",
    "        axes[0].plot(tmp['millisSinceGpsEpoch'], tmp['d'], label='d')\n",
    "        axes[0].legend(loc='upper right')\n",
    "        axes[0].grid(color='g', linestyle=':', linewidth=0.3)\n",
    "\n",
    "        axes[1].plot(gt_tmp['millisSinceGpsEpoch'], gt_tmp['courseDegree'], label='deg')\n",
    "        axes[1].legend(loc='upper right')\n",
    "        axes[1].grid(color='g', linestyle=':', linewidth=0.3)\n",
    "\n",
    "        axes[2].plot(tmp['millisSinceGpsEpoch'], tmp['xVehVel'], label='xVel')\n",
    "        axes[2].plot(tmp['millisSinceGpsEpoch'], tmp['yVehVel'], label='yVel')\n",
    "        axes[2].plot(tmp['millisSinceGpsEpoch'], tmp['zVehVel'], label='zVel')\n",
    "        axes[2].legend(loc='upper right')\n",
    "        axes[2].grid(color='g', linestyle=':', linewidth=0.3)\n",
    "        fig.suptitle(phone, fontsize=16)\n",
    "        fig.savefig(f'{outdir}/{phone}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "wooden-backing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_rolling(df_, outdir):\n",
    "    outdir = OUTPUT + '/' + outdir\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    df = df_.copy()\n",
    "    df['d'] = np.sqrt(df['xVehVel']**2 + df['yVehVel']**2 + df['zVehVel']**2)\n",
    "    \n",
    "    for phone in df['phone'].unique():\n",
    "        gt_tmp = gt[gt['phone']==phone].copy()\n",
    "        tmp = df[df['phone']==phone].copy()\n",
    "\n",
    "        fig, axes = plt.subplots(figsize=(40, 15), nrows=3, sharex=True)\n",
    "        axes[0].plot(gt_tmp['millisSinceGpsEpoch'], gt_tmp['speedMps'], label='speed')\n",
    "        axes[0].plot(tmp['millisSinceGpsEpoch'], tmp['d'], label='d')\n",
    "        axes[0].plot(tmp['millisSinceGpsEpoch'], tmp['roll_d'], label='d')\n",
    "        axes[0].legend(loc='upper right')\n",
    "        axes[0].grid(color='g', linestyle=':', linewidth=0.3)\n",
    "\n",
    "        axes[1].plot(gt_tmp['millisSinceGpsEpoch'], gt_tmp['courseDegree'], label='deg')\n",
    "        axes[1].legend(loc='upper right')\n",
    "        axes[1].grid(color='g', linestyle=':', linewidth=0.3)\n",
    "\n",
    "        axes[2].plot(tmp['millisSinceGpsEpoch'], tmp['xVehVel'], label='xVel')\n",
    "        axes[2].plot(tmp['millisSinceGpsEpoch'], tmp['yVehVel'], label='yVel')\n",
    "        axes[2].plot(tmp['millisSinceGpsEpoch'], tmp['zVehVel'], label='zVel')\n",
    "        axes[2].legend(loc='upper right')\n",
    "        axes[2].grid(color='g', linestyle=':', linewidth=0.3)\n",
    "        fig.suptitle(phone, fontsize=16)\n",
    "        fig.savefig(f'{outdir}/{phone}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "possible-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_status(df_, ignore_mi8=True):\n",
    "    df = df_.copy()\n",
    "    if ignore_mi8:\n",
    "        df = df[df['phoneName']!='Mi8'].copy()\n",
    "    \n",
    "    df['d'] = np.sqrt(df['xVehVel']**2 + df['yVehVel']**2 + df['zVehVel']**2)\n",
    "    na_cnt = df['d'].isnull().sum()\n",
    "    \n",
    "    df = df.merge(gt, on=['phone', 'millisSinceGpsEpoch'], how='left')\n",
    "    df = df.dropna(subset=['d'])\n",
    "    score = np.sqrt(mean_squared_error(df['speedMps'], df['d']))\n",
    "    \n",
    "    print(f'RMSE : {score}  | nullの数 : {na_cnt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-drink",
   "metadata": {},
   "source": [
    "# データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cutting-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, sub, gt = get_data()\n",
    "gt['phone'] = gt['collectionName'] + '_' + gt['phoneName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "looking-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "dop_train = pd.read_csv('../output/prep/doppler_v004/result_train.csv')\n",
    "dop_test = pd.read_csv('../output/prep/doppler_v004/result_test.csv')\n",
    "\n",
    "dop_train = dop_train.sort_values(['phone', 'millisSinceGpsEpoch'])\n",
    "dop_test = dop_test.sort_values(['phone', 'millisSinceGpsEpoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "successful-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz(dop_train, 'train/00_raw')\n",
    "viz(dop_test, 'test/00_raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-killer",
   "metadata": {},
   "source": [
    "# train, testの時間に合わせる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "worthy-trading",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_seconds(df, dop_df):\n",
    "    df = df.merge(dop_df[['phone', 'millisSinceGpsEpoch', 'xVehVel', 'yVehVel', 'zVehVel']], on=['phone', 'millisSinceGpsEpoch'], how='outer')\n",
    "    df = df.sort_values(['phone', 'millisSinceGpsEpoch'])\n",
    "    \n",
    "    out = pd.DataFrame()\n",
    "    for phone in df['phone'].unique():\n",
    "        tmp = df[df['phone']==phone].copy()\n",
    "        tmp = tmp.set_index('millisSinceGpsEpoch')\n",
    "        tmp[['xVehVel', 'yVehVel', 'zVehVel']] = tmp[['xVehVel', 'yVehVel', 'zVehVel']].interpolate(method='index', limit_area='inside')\n",
    "        tmp = tmp.reset_index()\n",
    "        out = out.append(tmp)\n",
    "    \n",
    "    out = out.dropna(subset=['collectionName'])\n",
    "    out = out.reset_index(drop=True)\n",
    "    return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "responsible-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = adjust_seconds(train, dop_train)\n",
    "test = adjust_seconds(test, dop_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "accompanied-albania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.41813347049858096  | nullの数 : 229\n"
     ]
    }
   ],
   "source": [
    "viz(train, 'train/01_adjust_seconds')\n",
    "viz(test, 'test/01_adjust_seconds')\n",
    "check_status(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-device",
   "metadata": {},
   "source": [
    "# speed変化量が大きすぎるデータを除外"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "secure-guide",
   "metadata": {},
   "outputs": [],
   "source": [
    "th=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "peripheral-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['d'] = np.sqrt(train['xVehVel']**2 + train['yVehVel']**2 + train['zVehVel']**2)\n",
    "test['d'] = np.sqrt(test['xVehVel']**2 + test['yVehVel']**2 + test['zVehVel']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "christian-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['d_diff_prev'] = abs(train['d'] - train.groupby('phone')['d'].shift(1))\n",
    "test['d_diff_prev'] = abs(test['d'] - test.groupby('phone')['d'].shift(1))\n",
    "train['d_diff_next'] = abs(train['d'] - train.groupby('phone')['d'].shift(-1))\n",
    "test['d_diff_next'] = abs(test['d'] - test.groupby('phone')['d'].shift(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "developmental-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[(train['d_diff_prev']>th)&(train['d_diff_next']>th), ['xVehVel', 'yVehVel', 'zVehVel', 'd']] = np.nan \n",
    "test.loc[(test['d_diff_prev']>th)&(test['d_diff_next']>th), ['xVehVel', 'yVehVel', 'zVehVel', 'd']] = np.nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ranging-thumbnail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.32169149585772394  | nullの数 : 290\n"
     ]
    }
   ],
   "source": [
    "viz(train, 'train/02_change_diff_reject')\n",
    "viz(test, 'test/02_change_diff_reject')\n",
    "check_status(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-version",
   "metadata": {},
   "source": [
    "# speedが大きすぎるデータを除外"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "southern-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['d']>50, ['xVehVel', 'yVehVel', 'zVehVel', 'd']] = np.nan \n",
    "test.loc[test['d']>50, ['xVehVel', 'yVehVel', 'zVehVel', 'd']] = np.nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "blessed-disease",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.32169149585772394  | nullの数 : 290\n"
     ]
    }
   ],
   "source": [
    "viz(train, 'train/03_hi_speed_reject')\n",
    "viz(test, 'test/03_hi_speed_reject')\n",
    "check_status(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-progressive",
   "metadata": {},
   "source": [
    "# 移動平均確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sustainable-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_test(df_, window, min_periods, center):\n",
    "    df = df_.copy()\n",
    "    df['roll_d'] = df.groupby('phone')['d'].rolling(window, min_periods=min_periods, center=center).mean().values\n",
    "    df = df.merge(gt, on=['phone', 'millisSinceGpsEpoch'], how='left')\n",
    "    na_cnt = df['roll_d'].isnull().sum()\n",
    "    df = df.dropna(subset=['roll_d'])\n",
    "    score = np.sqrt(mean_squared_error(df['speedMps'], df['roll_d']))\n",
    "    print(f'RMSE : {score}  | nullの数 : {na_cnt}')\n",
    "    \n",
    "    viz_rolling(df, 'train/04_rolling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "enormous-municipality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.45051989494688127  | nullの数 : 429\n"
     ]
    }
   ],
   "source": [
    "rolling_test(train, window=5, min_periods=3, center=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-rhythm",
   "metadata": {},
   "source": [
    "# 移動平均実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "tutorial-image",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "train = train.sort_values(['phone', 'millisSinceGpsEpoch'])\n",
    "test = test.sort_values(['phone', 'millisSinceGpsEpoch'])\n",
    "\n",
    "train[['xVehVel_roll', 'yVehVel_roll', 'zVehVel_roll']] = train.groupby('phone')['xVehVel', 'yVehVel', 'zVehVel'].rolling(5, min_periods=3, center=True).mean().values\n",
    "test[['xVehVel_roll', 'yVehVel_roll', 'zVehVel_roll']] = test.groupby('phone')['xVehVel', 'yVehVel', 'zVehVel'].rolling(5, min_periods=3, center=True).mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "alternate-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['roll_d'] = np.sqrt(train['xVehVel_roll']**2 + train['yVehVel_roll']**2 + train['zVehVel_roll']**2)\n",
    "test['roll_d'] = np.sqrt(test['xVehVel_roll']**2 + test['yVehVel_roll']**2 + test['zVehVel_roll']**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-model",
   "metadata": {},
   "source": [
    "# 相対座標算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "human-freeware",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WGS84_to_ECEF(lat, lon, alt):\n",
    "    # convert to radians\n",
    "    rad_lat = lat * (np.pi / 180.0)\n",
    "    rad_lon = lon * (np.pi / 180.0)\n",
    "    a    = 6378137.0\n",
    "    # f is the flattening factor\n",
    "    finv = 298.257223563\n",
    "    f = 1 / finv   \n",
    "    # e is the eccentricity\n",
    "    e2 = 1 - (1 - f) * (1 - f)    \n",
    "    # N is the radius of curvature in the prime vertical\n",
    "    N = a / np.sqrt(1 - e2 * np.sin(rad_lat) * np.sin(rad_lat))\n",
    "    x = (N + alt) * np.cos(rad_lat) * np.cos(rad_lon)\n",
    "    y = (N + alt) * np.cos(rad_lat) * np.sin(rad_lon)\n",
    "    z = (N * (1 - e2) + alt)        * np.sin(rad_lat)\n",
    "    return x, y, z\n",
    "\n",
    "transformer = pyproj.Transformer.from_crs(\n",
    "    {\"proj\":'geocent', \"ellps\":'WGS84', \"datum\":'WGS84'},\n",
    "    {\"proj\":'latlong', \"ellps\":'WGS84', \"datum\":'WGS84'},)\n",
    "\n",
    "def ECEF_to_WGS84(x,y,z):\n",
    "    lon, lat, alt = transformer.transform(x,y,z,radians=False)\n",
    "    return lon, lat, alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "occupational-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['h'] = 0\n",
    "test['h'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "agricultural-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rel(df):\n",
    "    df['x'], df['y'], df['z'] = zip(*df.apply(lambda x: WGS84_to_ECEF(x.latDeg, x.lngDeg, x.h), axis=1))\n",
    "    df['x_add'] = df['x'] + df['xVehVel']\n",
    "    df['y_add'] = df['y'] + df['yVehVel']\n",
    "    df['z_add'] = df['z'] + df['zVehVel']\n",
    "    df['lng_add'], df['lat_add'], df['h_add'] = zip(*df.apply(lambda x: ECEF_to_WGS84(x.x_add, x.y_add, x.z_add), axis=1))\n",
    "    df['lat_rel'] = df['lat_add'] - df['latDeg']\n",
    "    df['lng_rel'] = df['lng_add'] - df['lngDeg']\n",
    "    \n",
    "    df['x_add_roll'] = df['x'] + df['xVehVel_roll']\n",
    "    df['y_add_roll'] = df['y'] + df['yVehVel_roll']\n",
    "    df['z_add_roll'] = df['z'] + df['zVehVel_roll']\n",
    "    df['lng_add_roll'], df['lat_add_roll'], df['h_add_roll'] = zip(*df.apply(lambda x: ECEF_to_WGS84(x.x_add, x.y_add, x.z_add), axis=1))\n",
    "    df['lat_rel_roll'] = df['lat_add_roll'] - df['latDeg']\n",
    "    df['lng_rel_roll'] = df['lng_add_roll'] - df['lngDeg']   \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "responsible-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = calc_rel(train)\n",
    "test = calc_rel(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "under-metropolitan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['millisSinceGpsEpoch', 'collectionName', 'phoneName', 'latDeg',\n",
       "       'lngDeg', 'heightAboveWgs84EllipsoidM', 'phone', 'xVehVel', 'yVehVel',\n",
       "       'zVehVel', 'd', 'd_diff_prev', 'd_diff_next', 'xVehVel_roll',\n",
       "       'yVehVel_roll', 'zVehVel_roll', 'roll_d', 'h', 'x', 'y', 'z', 'x_add',\n",
       "       'y_add', 'z_add', 'lng_add', 'lat_add', 'h_add', 'lat_rel', 'lng_rel',\n",
       "       'x_add_roll', 'y_add_roll', 'z_add_roll', 'lng_add_roll',\n",
       "       'lat_add_roll', 'h_add_roll', 'lat_rel_roll', 'lng_rel_roll'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "vietnamese-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['millisSinceGpsEpoch', 'phone', 'xVehVel', 'yVehVel', 'zVehVel', 'd', \n",
    "        'xVehVel_roll', 'yVehVel_roll', 'zVehVel_roll', \n",
    "        'lat_rel', 'lng_rel', 'lat_rel_roll', 'lng_rel_roll', 'roll_d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "unexpected-plasma",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[cols].to_csv(OUTPUT+'/train_result.csv', index=False)\n",
    "test[cols].to_csv(OUTPUT+'/test_result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
