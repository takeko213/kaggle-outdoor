{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fluid-commons",
   "metadata": {},
   "source": [
    "# rel_pred_v003\n",
    "相対座標予測 + oofにnullがないように + v002をメタ特徴量に"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "grave-amendment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import library\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import pathlib\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import itertools\n",
    "import lightgbm as lgb\n",
    "from optuna.integration import lightgbm as optuna_lgb\n",
    "import simdkalman\n",
    "import optuna\n",
    "import pyproj\n",
    "from pyproj import Proj, transform\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, confusion_matrix, accuracy_score\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "handled-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb_path\n",
    "\n",
    "def get_nb_name():\n",
    "    nb_path = ipynb_path.get()\n",
    "    nb_name = nb_path.rsplit('/',1)[1].replace('.ipynb','')\n",
    "    return nb_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "german-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory setting\n",
    "nb_name = get_nb_name()\n",
    "INPUT = '../input/google-smartphone-decimeter-challenge'\n",
    "OUTPUT = '../output/prep/' + nb_name\n",
    "os.makedirs(OUTPUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "preliminary-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_labeling = pd.read_csv('../output/prep/area_labeling/result.csv')\n",
    "\n",
    "g1 = list(area_labeling[area_labeling['g']==1]['collectionName'])\n",
    "g2 = list(area_labeling[area_labeling['g']==2]['collectionName'])\n",
    "g3 = list(area_labeling[area_labeling['g']==3]['collectionName'])\n",
    "g4 = list(area_labeling[area_labeling['g']==4]['collectionName'])\n",
    "g5 = list(area_labeling[area_labeling['g']==5]['collectionName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-thing",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "proud-benjamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_score(df, gt):\n",
    "    gt = gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n",
    "    df = df.merge(gt, on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n",
    "    # calc_distance_error\n",
    "    df['err'] = calc_haversine(df['latDeg_gt'], df['lngDeg_gt'], df['latDeg'], df['lngDeg'])\n",
    "    # calc_evaluate_score\n",
    "    df['phone'] = df['collectionName'] + '_' + df['phoneName']\n",
    "    res = df.groupby('phone')['err'].agg([percentile50, percentile95])\n",
    "    res['p50_p90_mean'] = (res['percentile50'] + res['percentile95']) / 2 \n",
    "    score = res['p50_p90_mean'].mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "direct-jordan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculates the great circle distance between two points\n",
    "    on the earth. Inputs are array-like and specified in decimal degrees.\n",
    "    \"\"\"\n",
    "    RADIUS = 6_367_000\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + \\\n",
    "        np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    dist = 2 * RADIUS * np.arcsin(a**0.5)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "smart-surrey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_trafic(df, center, zoom=9):\n",
    "    fig = px.scatter_mapbox(df,\n",
    "                            \n",
    "                            # Here, plotly gets, (x,y) coordinates\n",
    "                            lat=\"latDeg\",\n",
    "                            lon=\"lngDeg\",\n",
    "                            \n",
    "                            #Here, plotly detects color of series\n",
    "                            color=\"phoneName\",\n",
    "                            labels=\"phoneName\",\n",
    "                            \n",
    "                            zoom=zoom,\n",
    "                            center=center,\n",
    "                            height=600,\n",
    "                            width=800)\n",
    "    fig.update_layout(mapbox_style='stamen-terrain')\n",
    "    fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
    "    fig.update_layout(title_text=\"GPS trafic\")\n",
    "    fig.show()\n",
    "    \n",
    "def visualize_collection(df, collection):\n",
    "    target_df = df[df['collectionName']==collection].copy()\n",
    "    lat_center = target_df['latDeg'].mean()\n",
    "    lng_center = target_df['lngDeg'].mean()\n",
    "    center = {\"lat\":lat_center, \"lon\":lng_center}\n",
    "    \n",
    "    visualize_trafic(target_df, center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "gothic-condition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_truth\n",
    "def get_ground_truth():\n",
    "    p = pathlib.Path(INPUT)\n",
    "    gt_files = list(p.glob('train/*/*/ground_truth.csv'))\n",
    "\n",
    "    gts = []\n",
    "    for gt_file in gt_files:\n",
    "        gts.append(pd.read_csv(gt_file))\n",
    "    ground_truth = pd.concat(gts)\n",
    "\n",
    "    return ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "injured-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile50(x):\n",
    "    return np.percentile(x, 50)\n",
    "def percentile95(x):\n",
    "    return np.percentile(x, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ignored-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_result:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.gt = get_ground_truth()\n",
    "        self.bl = pd.read_csv(INPUT + '/' + 'baseline_locations_train.csv')\n",
    "        \n",
    "        self.gt = self.gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n",
    "        self.df = self.df.merge(self.gt, on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n",
    "        self.df['phone'] = self.df['collectionName'] + '_' + self.df['phoneName']\n",
    "        self.df['err'] =  calc_haversine(self.df['latDeg_gt'], self.df['lngDeg_gt'], self.df['latDeg'], self.df['lngDeg'])\n",
    "        \n",
    "        self.phone_res = self.calc_err('phone')\n",
    "        self.clc_res = self.calc_err('collectionName')\n",
    "        self.phonename_res = self.calc_err('phoneName')\n",
    "        \n",
    "    def calc_err(self, by):\n",
    "        res = self.df.groupby(by)['err'].agg([percentile50, percentile95])\n",
    "        res['p50_p90_mean'] = (res['percentile50'] + res['percentile95']) / 2\n",
    "        return res\n",
    "    \n",
    "    @property\n",
    "    def score(self):\n",
    "        return self.phone_res['p50_p90_mean'].mean()\n",
    "    @property\n",
    "    def raw_data(self):\n",
    "        return self.df\n",
    "    @property\n",
    "    def err(self):\n",
    "        return self.phone_res\n",
    "    @property\n",
    "    def collection_err(self):\n",
    "        return self.clc_res\n",
    "    @property\n",
    "    def phonename_err(self):\n",
    "        return self.phonename_res\n",
    "    \n",
    "    def viz_map(self, collection, show_gt=True, show_bl=True):\n",
    "        tmp = self.df[self.df['collectionName']==collection][['collectionName', 'phoneName', 'latDeg', 'lngDeg']]\n",
    "        tmp2 = self.df[self.df['collectionName']==collection][['collectionName', 'phoneName', 'latDeg_gt', 'lngDeg_gt']]\n",
    "        tmp2 = tmp2.rename(columns={'latDeg_gt':'latDeg', 'lngDeg_gt':'lngDeg'})\n",
    "        tmp2['phoneName'] = tmp2['phoneName'] + '_GT'\n",
    "        tmp3 = self.bl[self.bl['collectionName']==collection][['collectionName', 'phoneName', 'latDeg', 'lngDeg']]\n",
    "        tmp3['phoneName'] = tmp3['phoneName'] + '_BL'\n",
    "        \n",
    "        if show_gt:\n",
    "            tmp = tmp.append(tmp2)\n",
    "        if show_bl:\n",
    "            tmp = tmp.append(tmp3)\n",
    "        visualize_collection(tmp, collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "structural-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    base_train = pd.read_csv(INPUT + '/' + 'baseline_locations_train.csv')\n",
    "    base_test = pd.read_csv(INPUT + '/' + 'baseline_locations_test.csv')\n",
    "    sample_sub = pd.read_csv(INPUT + '/' + 'sample_submission.csv')\n",
    "    ground_truth = get_ground_truth()\n",
    "    return base_train, base_test, sample_sub, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "original-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    for c,i in itertools.product(['millisSinceGpsEpoch'], [1,2,3,4,5,-1,-2,-3,-4,-5]):\n",
    "        col = c+ '_s' + str(i)\n",
    "        df[col] = df[c].shift(i)\n",
    "        df[col+'_diff'] = df[c] - df[col]\n",
    "        df.loc[df['phone']!=df['phone'].shift(i), [col, col+'_diff']] = np.nan\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "frequent-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sensor_features(df, accel, gyro, mag, ori):\n",
    "    # phoneを追加\n",
    "    df['phone'] = df['collectionName'] + '_' + df['phoneName']\n",
    "    accel['phone'] = accel['collectionName'] + '_' + accel['phoneName']\n",
    "    gyro['phone'] = gyro['collectionName'] + '_' + gyro['phoneName']\n",
    "    mag['phone'] = mag['collectionName'] + '_' + mag['phoneName']\n",
    "    ori['phone'] = ori['collectionName'] + '_' + ori['phoneName']\n",
    "    \n",
    "     # 一定の値しか入っていないphoneを除外しておく\n",
    "    ori = ori[~ori['phone'].isin(['2021-04-29-US-MTV-1_SamsungS20Ultra', '2021-04-28-US-MTV-1_SamsungS20Ultra', '2021-04-28-US-SJC-1_SamsungS20Ultra', '2021-04-29-US-SJC-2_SamsungS20Ultra',\n",
    "                                 '2021-04-28-US-MTV-2_SamsungS20Ultra', '2021-04-29-US-SJC-3_SamsungS20Ultra', '2021-04-29-US-MTV-2_SamsungS20Ultra'])]\n",
    "    \n",
    "    \n",
    "    # phonenameをラベルエンコーディング\n",
    "    phoneName_map = {'Pixel4':1, 'Pixel4XLModded':2, 'Pixel4XL':3, 'Mi8':4, 'Pixel4Modded':5, 'Pixel5':6, 'SamsungS20Ultra':7}\n",
    "    df['phoneName_le'] = df['phoneName'].map(phoneName_map)\n",
    "    \n",
    "    # utc -> gps\n",
    "    accel['millisSinceGpsEpoch'] = accel['utcTimeMillis'] - 315964800000 + 18000\n",
    "    gyro['millisSinceGpsEpoch'] = gyro['utcTimeMillis'] - 315964800000 + 18000\n",
    "    mag['millisSinceGpsEpoch'] = mag['utcTimeMillis'] - 315964800000 + 18000\n",
    "    ori['millisSinceGpsEpoch'] = ori['utcTimeMillis'] - 315964800000 + 18000\n",
    "    \n",
    "    # resampling追加\n",
    "    df['secondSinceGpsEpoch'] = df['millisSinceGpsEpoch'] // 1000\n",
    "    accel['secondSinceGpsEpoch'] = accel['millisSinceGpsEpoch'] // 1000\n",
    "    gyro['secondSinceGpsEpoch'] = gyro['millisSinceGpsEpoch'] // 1000\n",
    "    mag['secondSinceGpsEpoch'] = mag['millisSinceGpsEpoch'] // 1000\n",
    "    ori['secondSinceGpsEpoch'] = ori['millisSinceGpsEpoch'] // 1000\n",
    "    \n",
    "    # clipping\n",
    "    accel[['UncalAccelXMps2', 'UncalAccelYMps2', 'UncalAccelZMps2']] = accel.groupby('phone')['UncalAccelXMps2', 'UncalAccelYMps2', 'UncalAccelZMps2'].transform(lambda x: x.clip(x.quantile(0.001), x.quantile(0.999)))\n",
    "    gyro[['UncalGyroXRadPerSec', 'UncalGyroYRadPerSec', 'UncalGyroZRadPerSec']] = gyro.groupby('phone')['UncalGyroXRadPerSec', 'UncalGyroYRadPerSec', 'UncalGyroZRadPerSec'].transform(lambda x: x.clip(x.quantile(0.001), x.quantile(0.999)))\n",
    "    mag[['UncalMagXMicroT', 'UncalMagYMicroT', 'UncalMagZMicroT']] = mag.groupby('phone')['UncalMagXMicroT', 'UncalMagYMicroT', 'UncalMagZMicroT'].transform(lambda x: x.clip(x.quantile(0.001), x.quantile(0.999)))\n",
    "    \n",
    "    accel = accel.groupby(['phone', 'secondSinceGpsEpoch'])['UncalAccelXMps2', 'UncalAccelYMps2', 'UncalAccelZMps2'].agg(['mean', 'std']).reset_index()\n",
    "    accel.columns = ['phone', 'secondSinceGpsEpoch', 'UncalAccelXMps2_mean', 'UncalAccelXMps2_std', 'UncalAccelYMps2_mean', 'UncalAccelYMps2_std', 'UncalAccelZMps2_mean', 'UncalAccelZMps2_std']\n",
    "    gyro = gyro.groupby(['phone', 'secondSinceGpsEpoch'])['UncalGyroXRadPerSec', 'UncalGyroYRadPerSec', 'UncalGyroZRadPerSec'].agg(['mean', 'std']).reset_index()\n",
    "    gyro.columns = ['phone', 'secondSinceGpsEpoch', 'UncalGyroXRadPerSec_mean', 'UncalGyroXRadPerSec_std', 'UncalGyroYRadPerSec_mean', 'UncalGyroYRadPerSec_std', 'UncalGyroZRadPerSec_mean', 'UncalGyroZRadPerSec_std' ]\n",
    "    mag = mag.groupby(['phone', 'secondSinceGpsEpoch'])['UncalMagXMicroT', 'UncalMagYMicroT', 'UncalMagZMicroT'].agg(['mean', 'std']).reset_index()\n",
    "    mag.columns = ['phone', 'secondSinceGpsEpoch', 'UncalMagXMicroT_mean', 'UncalMagXMicroT_std', 'UncalMagYMicroT_mean', 'UncalMagYMicroT_std', 'UncalMagZMicroT_mean', 'UncalMagZMicroT_std']\n",
    "    ori = ori.groupby(['phone', 'secondSinceGpsEpoch'])['yawDeg', 'rollDeg', 'pitchDeg'].agg(['mean', 'std']).reset_index()\n",
    "    ori.columns = ['phone', 'secondSinceGpsEpoch', 'yawDeg_mean', 'yawDeg_std', 'rollDeg_mean', 'rollDeg_std', 'pitchDeg_mean', 'pitchDeg_std']\n",
    "    \n",
    "    \n",
    "    # shift特徴量\n",
    "    for c, i in itertools.product(['UncalAccelXMps2_mean', 'UncalAccelXMps2_std', 'UncalAccelYMps2_mean', 'UncalAccelYMps2_std', 'UncalAccelZMps2_mean', 'UncalAccelZMps2_std'], [1,2,3,4,5-1,-2,-3,-4,-5]):\n",
    "        col = c+ '_s' + str(i)\n",
    "        accel[col] = accel[c].shift(i)\n",
    "        accel[col+'_diff'] = accel[c] - accel[col]\n",
    "        accel.loc[accel['phone']!=accel['phone'].shift(i), [col, col+'_diff']] = np.nan\n",
    "    for c, i in itertools.product(['UncalGyroXRadPerSec_mean', 'UncalGyroXRadPerSec_std', 'UncalGyroYRadPerSec_mean', 'UncalGyroYRadPerSec_std', 'UncalGyroZRadPerSec_mean', 'UncalGyroZRadPerSec_std'], [1,2,3,4,5-1,-2,-3,-4,-5]):\n",
    "        col = c+ '_s' + str(i)\n",
    "        gyro[col] = gyro[c].shift(i)\n",
    "        gyro[col+'_diff'] = gyro[c] - gyro[col]\n",
    "        gyro.loc[gyro['phone']!=gyro['phone'].shift(i), [col, col+'_diff']] = np.nan\n",
    "    for c, i in itertools.product(['UncalMagXMicroT_mean', 'UncalMagXMicroT_std', 'UncalMagYMicroT_mean', 'UncalMagYMicroT_std', 'UncalMagZMicroT_mean', 'UncalMagZMicroT_std'], [1,2,3,4,5-1,-2,-3,-4,-5]):\n",
    "        col = c+ '_s' + str(i)\n",
    "        mag[col] = mag[c].shift(i)\n",
    "        mag[col+'_diff'] = mag[c] - mag[col]\n",
    "        mag.loc[mag['phone']!=mag['phone'].shift(i), [col, col+'_diff']] = np.nan\n",
    "    for c, i in itertools.product(['yawDeg_mean', 'yawDeg_std', 'rollDeg_mean', 'rollDeg_std', 'pitchDeg_mean', 'pitchDeg_std'], [1,2,3,-1,-2,-3]):\n",
    "        col = c+ '_s' + str(i)\n",
    "        ori[col] = ori[c].shift(i)\n",
    "        ori[col+'_diff'] = ori[c] - ori[col]\n",
    "        ori.loc[ori['phone']!=ori['phone'].shift(i), [col, col+'_diff']] = np.nan        \n",
    "    \n",
    "    df = df.merge(accel, on=['phone', 'secondSinceGpsEpoch'], how='left')\n",
    "    df = df.merge(gyro, on=['phone', 'secondSinceGpsEpoch'], how='left')\n",
    "    df = df.merge(mag, on=['phone', 'secondSinceGpsEpoch'], how='left')\n",
    "    df = df.merge(ori, on=['phone', 'secondSinceGpsEpoch'], how='left')\n",
    "    \n",
    "    df.drop(['secondSinceGpsEpoch'], axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beginning-address",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:32: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:33: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:34: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:36: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:38: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:40: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:42: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:32: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:33: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:34: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:36: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:38: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:40: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:42: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n"
     ]
    }
   ],
   "source": [
    "train, test, sub, gt = get_data()\n",
    "accel_train = pd.read_csv(INPUT + '/prep/gnss/train/UncalAccel.csv')\n",
    "gyro_train = pd.read_csv(INPUT + '/prep/gnss/train/UncalGyro.csv')\n",
    "mag_train = pd.read_csv(INPUT + '/prep/gnss/train/UncalMag.csv')\n",
    "ori_train = pd.read_csv(INPUT + '/prep/gnss/train/OrientationDeg.csv')\n",
    "accel_test = pd.read_csv(INPUT + '/prep/gnss/test/UncalAccel.csv')\n",
    "gyro_test = pd.read_csv(INPUT + '/prep/gnss/test/UncalGyro.csv')\n",
    "mag_test = pd.read_csv(INPUT + '/prep/gnss/test/UncalMag.csv')\n",
    "ori_test = pd.read_csv(INPUT + '/prep/gnss/test/OrientationDeg.csv')\n",
    "\n",
    "train = train.merge(gt[['collectionName', 'phoneName', 'millisSinceGpsEpoch', 'speedMps']], on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n",
    "train = add_features(train)\n",
    "test = add_features(test)\n",
    "train = add_sensor_features(train, accel_train, gyro_train, mag_train, ori_train)\n",
    "test = add_sensor_features(test, accel_test, gyro_test, mag_test, ori_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-machine",
   "metadata": {},
   "source": [
    "# doppler追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "developing-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dop_features(df):\n",
    "    for c,i in itertools.product(['d', 'roll_d', 'lat_rel', 'lng_rel', 'lat_rel_roll', 'lng_rel_roll'], [1,2,3,4,5,-1,-2,-3,-4,-5]):\n",
    "        col = c+ '_s' + str(i)\n",
    "        df[col] = df[c].shift(i)\n",
    "        df[col+'_diff'] = df[c] - df[col]\n",
    "        df.loc[df['phone']!=df['phone'].shift(i), [col, col+'_diff']] = np.nan\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "beautiful-knitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_train = pd.read_csv('../output/prep/doppler_processing_v004/train_result.csv')\n",
    "dp_test = pd.read_csv('../output/prep/doppler_processing_v004/test_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "capable-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(dp_train, on=['phone', 'millisSinceGpsEpoch'], how='left')\n",
    "test = test.merge(dp_test, on=['phone', 'millisSinceGpsEpoch'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "phantom-hello",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_dop_features(train)\n",
    "test = add_dop_features(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-election",
   "metadata": {},
   "source": [
    "# degree追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "technical-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_train = pd.read_csv(f'../output/prep/degree_pred_v004/train_degree_pred.csv')\n",
    "deg_test = pd.read_csv(f'../output/prep/degree_pred_v004/test_degree_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "expired-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(deg_train[['phone', 'millisSinceGpsEpoch', 'calc_deg']], on=['phone', 'millisSinceGpsEpoch'], how='left')\n",
    "test = test.merge(deg_test[['phone', 'millisSinceGpsEpoch', 'calc_deg']], on=['phone', 'millisSinceGpsEpoch'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "periodic-cattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_deg_features(df):\n",
    "    \n",
    "    for c,i in itertools.product(['calc_deg'], [1,2,3,4,5,-1,-2,-3,-4,-5]):\n",
    "        col = c+ '_s' + str(i)\n",
    "        df[col] = df[c].shift(i)\n",
    "        df[col+'_diff'] = df[c] - df[col]\n",
    "        df.loc[df['phone']!=df['phone'].shift(i), [col, col+'_diff']] = np.nan\n",
    "    \n",
    "    for c in ['calc_deg']:\n",
    "        df[c+'_s1_diff_sum'] = df[c+'_s1_diff'].fillna(0) + df[c+'_s-1_diff'].fillna(0)\n",
    "        df[c+'_s2_diff_sum'] = df[c+'_s1_diff_sum'] + df[c+'_s2_diff'].fillna(0) + df[c+'_s-2_diff'].fillna(0)\n",
    "        df[c+'_s3_diff_sum'] = df[c+'_s2_diff_sum'] + df[c+'_s3_diff'].fillna(0) + df[c+'_s-3_diff'].fillna(0)\n",
    "        df[c+'_s4_diff_sum'] = df[c+'_s3_diff_sum'] + df[c+'_s4_diff'].fillna(0) + df[c+'_s-4_diff'].fillna(0)\n",
    "        df[c+'_s5_diff_sum'] = df[c+'_s4_diff_sum'] + df[c+'_s5_diff'].fillna(0) + df[c+'_s-5_diff'].fillna(0)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "armed-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_deg_features(train)\n",
    "test = add_deg_features(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-sunrise",
   "metadata": {},
   "source": [
    "# meta特徴量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "formed-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = pd.read_csv(f'../output/prep/rel_pred_v002/train_result.csv')\n",
    "pred_test = pd.read_csv(f'../output/prep/rel_pred_v002/test_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cardiac-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = pred_train.rename(columns={'lat_diff':'lat_diff_meta', 'lng_diff':'lng_diff_meta'})\n",
    "pred_test = pred_test.rename(columns={'lat_diff':'lat_diff_meta', 'lng_diff':'lng_diff_meta'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "comparative-refund",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(pred_train, on=['phone', 'millisSinceGpsEpoch'], how='left')\n",
    "test = test.merge(pred_test, on=['phone', 'millisSinceGpsEpoch'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "qualified-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sort_values(['phone', 'millisSinceGpsEpoch'])\n",
    "test = test.sort_values(['phone', 'millisSinceGpsEpoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dominican-cheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_meta_features(df):\n",
    "    for c,i in itertools.product(['lat_diff_meta', 'lng_diff_meta'], [1,2,3,4,5,-1,-2,-3,-4,-5]):\n",
    "        col = c+ '_s' + str(i)\n",
    "        df[col] = df[c].shift(i)\n",
    "        df[col+'_diff'] = df[c] - df[col]\n",
    "        df.loc[df['phone']!=df['phone'].shift(i), [col, col+'_diff']] = np.nan\n",
    "        \n",
    "        df['lat_diff_meta_roll_mean'] = df.groupby('phone')['lat_diff_meta'].rolling(10, min_periods=1, center=True).mean().values\n",
    "        df['lng_diff_meta_roll_mean'] = df.groupby('phone')['lng_diff_meta'].rolling(10, min_periods=1, center=True).mean().values\n",
    "        df['lat_diff_meta_roll_std'] = df.groupby('phone')['lat_diff_meta'].rolling(10, min_periods=1, center=True).std().values\n",
    "        df['lng_diff_meta_roll_std'] = df.groupby('phone')['lng_diff_meta'].rolling(10, min_periods=1, center=True).std().values\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "protective-handy",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_meta_features(train)\n",
    "test = add_meta_features(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-bracelet",
   "metadata": {},
   "source": [
    "# ラベル生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "union-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt['phone'] = gt['collectionName'] + '_' + gt['phoneName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "opposed-aside",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt['lat_diff'] = gt.groupby('phone')['latDeg'].shift(-1) - gt['latDeg']\n",
    "gt['lng_diff'] = gt.groupby('phone')['lngDeg'].shift(-1) - gt['lngDeg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "contained-consultation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(gt[['phone', 'millisSinceGpsEpoch', 'lat_diff', 'lng_diff']], on=['phone', 'millisSinceGpsEpoch'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-department",
   "metadata": {},
   "source": [
    "# Mi8除去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "classified-white",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['phoneName']!='Mi8'].copy()\n",
    "test = test[test['phoneName']!='Mi8'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "married-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "southeast-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_org = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "tired-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna(subset=['lat_diff'])\n",
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "normal-diabetes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collectionName</th>\n",
       "      <th>phoneName</th>\n",
       "      <th>millisSinceGpsEpoch</th>\n",
       "      <th>latDeg</th>\n",
       "      <th>lngDeg</th>\n",
       "      <th>heightAboveWgs84EllipsoidM</th>\n",
       "      <th>phone</th>\n",
       "      <th>speedMps</th>\n",
       "      <th>millisSinceGpsEpoch_s1</th>\n",
       "      <th>millisSinceGpsEpoch_s1_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>lat_diff_meta</th>\n",
       "      <th>lng_diff_meta</th>\n",
       "      <th>lat_diff_meta_s1</th>\n",
       "      <th>lat_diff_meta_s1_diff</th>\n",
       "      <th>lat_diff_meta_roll_mean</th>\n",
       "      <th>lng_diff_meta_roll_mean</th>\n",
       "      <th>lat_diff_meta_roll_std</th>\n",
       "      <th>lng_diff_meta_roll_std</th>\n",
       "      <th>lat_diff</th>\n",
       "      <th>lng_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-14-US-MTV-1</td>\n",
       "      <td>Pixel4</td>\n",
       "      <td>1273529463442</td>\n",
       "      <td>37.423575</td>\n",
       "      <td>-122.094091</td>\n",
       "      <td>-34.06</td>\n",
       "      <td>2020-05-14-US-MTV-1_Pixel4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.565132e-08</td>\n",
       "      <td>-2.033064e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.135882e-08</td>\n",
       "      <td>-6.237127e-07</td>\n",
       "      <td>1.470919e-07</td>\n",
       "      <td>7.892964e-07</td>\n",
       "      <td>2.999982e-10</td>\n",
       "      <td>-1.700002e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-14-US-MTV-1</td>\n",
       "      <td>Pixel4</td>\n",
       "      <td>1273529464442</td>\n",
       "      <td>37.423578</td>\n",
       "      <td>-122.094101</td>\n",
       "      <td>-33.29</td>\n",
       "      <td>2020-05-14-US-MTV-1_Pixel4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.273529e+12</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.906106e-07</td>\n",
       "      <td>-3.131273e-07</td>\n",
       "      <td>-4.565132e-08</td>\n",
       "      <td>-2.449593e-07</td>\n",
       "      <td>-4.153880e-08</td>\n",
       "      <td>-5.571706e-07</td>\n",
       "      <td>1.315638e-07</td>\n",
       "      <td>7.245399e-07</td>\n",
       "      <td>1.040000e-08</td>\n",
       "      <td>3.400004e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-14-US-MTV-1</td>\n",
       "      <td>Pixel4</td>\n",
       "      <td>1273529465442</td>\n",
       "      <td>37.423573</td>\n",
       "      <td>-122.094111</td>\n",
       "      <td>-30.99</td>\n",
       "      <td>2020-05-14-US-MTV-1_Pixel4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.273529e+12</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.437528e-08</td>\n",
       "      <td>-3.216168e-07</td>\n",
       "      <td>-2.906106e-07</td>\n",
       "      <td>3.449859e-07</td>\n",
       "      <td>-3.391710e-08</td>\n",
       "      <td>-5.037839e-07</td>\n",
       "      <td>1.217819e-07</td>\n",
       "      <td>6.763255e-07</td>\n",
       "      <td>1.140000e-08</td>\n",
       "      <td>1.600000e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-14-US-MTV-1</td>\n",
       "      <td>Pixel4</td>\n",
       "      <td>1273529466442</td>\n",
       "      <td>37.423583</td>\n",
       "      <td>-122.094121</td>\n",
       "      <td>-32.83</td>\n",
       "      <td>2020-05-14-US-MTV-1_Pixel4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.273529e+12</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.484404e-08</td>\n",
       "      <td>-2.429534e-07</td>\n",
       "      <td>5.437528e-08</td>\n",
       "      <td>2.046876e-08</td>\n",
       "      <td>-2.140680e-08</td>\n",
       "      <td>-4.675765e-07</td>\n",
       "      <td>1.181702e-07</td>\n",
       "      <td>6.344752e-07</td>\n",
       "      <td>9.899992e-09</td>\n",
       "      <td>-1.600000e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-14-US-MTV-1</td>\n",
       "      <td>Pixel4</td>\n",
       "      <td>1273529467442</td>\n",
       "      <td>37.423579</td>\n",
       "      <td>-122.094114</td>\n",
       "      <td>-34.49</td>\n",
       "      <td>2020-05-14-US-MTV-1_Pixel4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.273529e+12</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.484493e-10</td>\n",
       "      <td>-2.078019e-07</td>\n",
       "      <td>7.484404e-08</td>\n",
       "      <td>-7.459560e-08</td>\n",
       "      <td>-1.637033e-08</td>\n",
       "      <td>-4.395326e-07</td>\n",
       "      <td>1.115660e-07</td>\n",
       "      <td>5.994306e-07</td>\n",
       "      <td>1.350000e-08</td>\n",
       "      <td>-3.400004e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117168</th>\n",
       "      <td>2021-04-29-US-SJC-2</td>\n",
       "      <td>SamsungS20Ultra</td>\n",
       "      <td>1303760315000</td>\n",
       "      <td>37.334460</td>\n",
       "      <td>-121.899600</td>\n",
       "      <td>-8.09</td>\n",
       "      <td>2021-04-29-US-SJC-2_SamsungS20Ultra</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.303760e+12</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.458291e-07</td>\n",
       "      <td>1.912361e-07</td>\n",
       "      <td>-3.582190e-08</td>\n",
       "      <td>-1.100072e-07</td>\n",
       "      <td>-2.411826e-07</td>\n",
       "      <td>9.309389e-08</td>\n",
       "      <td>5.376970e-07</td>\n",
       "      <td>2.341611e-06</td>\n",
       "      <td>5.000004e-09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117169</th>\n",
       "      <td>2021-04-29-US-SJC-2</td>\n",
       "      <td>SamsungS20Ultra</td>\n",
       "      <td>1303760316000</td>\n",
       "      <td>37.334472</td>\n",
       "      <td>-121.899583</td>\n",
       "      <td>-7.59</td>\n",
       "      <td>2021-04-29-US-SJC-2_SamsungS20Ultra</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.303760e+12</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.223730e-07</td>\n",
       "      <td>1.094452e-06</td>\n",
       "      <td>-1.458291e-07</td>\n",
       "      <td>-2.765439e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.700002e-09</td>\n",
       "      <td>-1.600000e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117170</th>\n",
       "      <td>2021-04-29-US-SJC-2</td>\n",
       "      <td>SamsungS20Ultra</td>\n",
       "      <td>1303760317000</td>\n",
       "      <td>37.334491</td>\n",
       "      <td>-121.899597</td>\n",
       "      <td>-8.35</td>\n",
       "      <td>2021-04-29-US-SJC-2_SamsungS20Ultra</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.303760e+12</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.474816e-07</td>\n",
       "      <td>7.823073e-09</td>\n",
       "      <td>-4.223730e-07</td>\n",
       "      <td>8.698546e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.330000e-08</td>\n",
       "      <td>3.300002e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117171</th>\n",
       "      <td>2021-04-29-US-SJC-2</td>\n",
       "      <td>SamsungS20Ultra</td>\n",
       "      <td>1303760318000</td>\n",
       "      <td>37.334495</td>\n",
       "      <td>-121.899583</td>\n",
       "      <td>-8.73</td>\n",
       "      <td>2021-04-29-US-SJC-2_SamsungS20Ultra</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.303760e+12</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.238877e-06</td>\n",
       "      <td>2.591218e-06</td>\n",
       "      <td>4.474816e-07</td>\n",
       "      <td>-1.686359e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.170000e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117172</th>\n",
       "      <td>2021-04-29-US-SJC-2</td>\n",
       "      <td>SamsungS20Ultra</td>\n",
       "      <td>1303760319000</td>\n",
       "      <td>37.334485</td>\n",
       "      <td>-121.899570</td>\n",
       "      <td>-7.64</td>\n",
       "      <td>2021-04-29-US-SJC-2_SamsungS20Ultra</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.303760e+12</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.114873e-06</td>\n",
       "      <td>-6.268051e-06</td>\n",
       "      <td>-1.238877e-06</td>\n",
       "      <td>1.240042e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117173 rows × 581 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             collectionName        phoneName  millisSinceGpsEpoch     latDeg  \\\n",
       "0       2020-05-14-US-MTV-1           Pixel4        1273529463442  37.423575   \n",
       "1       2020-05-14-US-MTV-1           Pixel4        1273529464442  37.423578   \n",
       "2       2020-05-14-US-MTV-1           Pixel4        1273529465442  37.423573   \n",
       "3       2020-05-14-US-MTV-1           Pixel4        1273529466442  37.423583   \n",
       "4       2020-05-14-US-MTV-1           Pixel4        1273529467442  37.423579   \n",
       "...                     ...              ...                  ...        ...   \n",
       "117168  2021-04-29-US-SJC-2  SamsungS20Ultra        1303760315000  37.334460   \n",
       "117169  2021-04-29-US-SJC-2  SamsungS20Ultra        1303760316000  37.334472   \n",
       "117170  2021-04-29-US-SJC-2  SamsungS20Ultra        1303760317000  37.334491   \n",
       "117171  2021-04-29-US-SJC-2  SamsungS20Ultra        1303760318000  37.334495   \n",
       "117172  2021-04-29-US-SJC-2  SamsungS20Ultra        1303760319000  37.334485   \n",
       "\n",
       "            lngDeg  heightAboveWgs84EllipsoidM  \\\n",
       "0      -122.094091                      -34.06   \n",
       "1      -122.094101                      -33.29   \n",
       "2      -122.094111                      -30.99   \n",
       "3      -122.094121                      -32.83   \n",
       "4      -122.094114                      -34.49   \n",
       "...            ...                         ...   \n",
       "117168 -121.899600                       -8.09   \n",
       "117169 -121.899583                       -7.59   \n",
       "117170 -121.899597                       -8.35   \n",
       "117171 -121.899583                       -8.73   \n",
       "117172 -121.899570                       -7.64   \n",
       "\n",
       "                                      phone  speedMps  millisSinceGpsEpoch_s1  \\\n",
       "0                2020-05-14-US-MTV-1_Pixel4       0.0                     NaN   \n",
       "1                2020-05-14-US-MTV-1_Pixel4       0.0            1.273529e+12   \n",
       "2                2020-05-14-US-MTV-1_Pixel4       0.0            1.273529e+12   \n",
       "3                2020-05-14-US-MTV-1_Pixel4       0.0            1.273529e+12   \n",
       "4                2020-05-14-US-MTV-1_Pixel4       0.0            1.273529e+12   \n",
       "...                                     ...       ...                     ...   \n",
       "117168  2021-04-29-US-SJC-2_SamsungS20Ultra       0.0            1.303760e+12   \n",
       "117169  2021-04-29-US-SJC-2_SamsungS20Ultra       0.0            1.303760e+12   \n",
       "117170  2021-04-29-US-SJC-2_SamsungS20Ultra       0.0            1.303760e+12   \n",
       "117171  2021-04-29-US-SJC-2_SamsungS20Ultra       0.0            1.303760e+12   \n",
       "117172  2021-04-29-US-SJC-2_SamsungS20Ultra       0.0            1.303760e+12   \n",
       "\n",
       "        millisSinceGpsEpoch_s1_diff  ...  lat_diff_meta  lng_diff_meta  \\\n",
       "0                               NaN  ...  -4.565132e-08  -2.033064e-06   \n",
       "1                            1000.0  ...  -2.906106e-07  -3.131273e-07   \n",
       "2                            1000.0  ...   5.437528e-08  -3.216168e-07   \n",
       "3                            1000.0  ...   7.484404e-08  -2.429534e-07   \n",
       "4                            1000.0  ...   2.484493e-10  -2.078019e-07   \n",
       "...                             ...  ...            ...            ...   \n",
       "117168                       1000.0  ...  -1.458291e-07   1.912361e-07   \n",
       "117169                       1000.0  ...  -4.223730e-07   1.094452e-06   \n",
       "117170                       1000.0  ...   4.474816e-07   7.823073e-09   \n",
       "117171                       1000.0  ...  -1.238877e-06   2.591218e-06   \n",
       "117172                       1000.0  ...  -1.114873e-06  -6.268051e-06   \n",
       "\n",
       "        lat_diff_meta_s1  lat_diff_meta_s1_diff  lat_diff_meta_roll_mean  \\\n",
       "0                    NaN                    NaN            -4.135882e-08   \n",
       "1          -4.565132e-08          -2.449593e-07            -4.153880e-08   \n",
       "2          -2.906106e-07           3.449859e-07            -3.391710e-08   \n",
       "3           5.437528e-08           2.046876e-08            -2.140680e-08   \n",
       "4           7.484404e-08          -7.459560e-08            -1.637033e-08   \n",
       "...                  ...                    ...                      ...   \n",
       "117168     -3.582190e-08          -1.100072e-07            -2.411826e-07   \n",
       "117169     -1.458291e-07          -2.765439e-07                      NaN   \n",
       "117170     -4.223730e-07           8.698546e-07                      NaN   \n",
       "117171      4.474816e-07          -1.686359e-06                      NaN   \n",
       "117172     -1.238877e-06           1.240042e-07                      NaN   \n",
       "\n",
       "        lng_diff_meta_roll_mean  lat_diff_meta_roll_std  \\\n",
       "0                 -6.237127e-07            1.470919e-07   \n",
       "1                 -5.571706e-07            1.315638e-07   \n",
       "2                 -5.037839e-07            1.217819e-07   \n",
       "3                 -4.675765e-07            1.181702e-07   \n",
       "4                 -4.395326e-07            1.115660e-07   \n",
       "...                         ...                     ...   \n",
       "117168             9.309389e-08            5.376970e-07   \n",
       "117169                      NaN                     NaN   \n",
       "117170                      NaN                     NaN   \n",
       "117171                      NaN                     NaN   \n",
       "117172                      NaN                     NaN   \n",
       "\n",
       "        lng_diff_meta_roll_std      lat_diff      lng_diff  \n",
       "0                 7.892964e-07  2.999982e-10 -1.700002e-09  \n",
       "1                 7.245399e-07  1.040000e-08  3.400004e-09  \n",
       "2                 6.763255e-07  1.140000e-08  1.600000e-09  \n",
       "3                 6.344752e-07  9.899992e-09 -1.600000e-09  \n",
       "4                 5.994306e-07  1.350000e-08 -3.400004e-09  \n",
       "...                        ...           ...           ...  \n",
       "117168            2.341611e-06  5.000004e-09  0.000000e+00  \n",
       "117169                     NaN  1.700002e-09 -1.600000e-09  \n",
       "117170                     NaN -4.330000e-08  3.300002e-09  \n",
       "117171                     NaN -3.170000e-08  0.000000e+00  \n",
       "117172                     NaN           NaN           NaN  \n",
       "\n",
       "[117173 rows x 581 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-princess",
   "metadata": {},
   "source": [
    "# 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "knowing-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "target1 = 'lat_diff'\n",
    "target2 = 'lng_diff'\n",
    "not_use_cols = ['collectionName', 'phoneName', 'millisSinceGpsEpoch', 'latDeg', 'lngDeg', 'heightAboveWgs84EllipsoidM',\n",
    "                'phone', 'speedMps', target1, target2]\n",
    "\n",
    "features = [c for c in train.columns if c not in not_use_cols]\n",
    "\n",
    "opt_params = {'objective': 'regression', \n",
    "              'metric': 'rmse', \n",
    "              'learning_rate': 0.1, \n",
    "              'seed': 42, \n",
    "              'feature_pre_filter': False, \n",
    "              'lambda_l1': 0.0, \n",
    "              'lambda_l2': 0.0, \n",
    "              'num_leaves': 31, \n",
    "              'feature_fraction': 0.852, \n",
    "              'bagging_fraction': 1.0, \n",
    "              'bagging_freq': 0, \n",
    "              'min_child_samples': 10, \n",
    "              'num_iterations': 20000, \n",
    "              'early_stopping_round': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "universal-detection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat_diff\n",
      "valid :  2020-05-14-US-MTV-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.450207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145195\n",
      "[LightGBM] [Info] Number of data points in the train set: 113624, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000006\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.39166e-06\tvalid_1's rmse: 1.89274e-06\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's rmse: 5.52241e-06\tvalid_1's rmse: 1.65645e-06\n",
      "valid :  2020-05-14-US-MTV-2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.475264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145187\n",
      "[LightGBM] [Info] Number of data points in the train set: 114763, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000013\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.30756e-06\tvalid_1's rmse: 1.41308e-05\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's rmse: 6.98078e-06\tvalid_1's rmse: 6.48755e-06\n",
      "valid :  2020-05-21-US-MTV-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.520028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145201\n",
      "[LightGBM] [Info] Number of data points in the train set: 115078, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000008\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.26527e-06\tvalid_1's rmse: 7.42438e-06\n",
      "[200]\ttraining's rmse: 1.9307e-06\tvalid_1's rmse: 6.58867e-06\n",
      "[300]\ttraining's rmse: 1.52954e-06\tvalid_1's rmse: 6.67413e-06\n",
      "Early stopping, best iteration is:\n",
      "[206]\ttraining's rmse: 1.89354e-06\tvalid_1's rmse: 6.53324e-06\n",
      "valid :  2020-05-21-US-MTV-2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.530057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145195\n",
      "[LightGBM] [Info] Number of data points in the train set: 113351, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000013\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.28551e-06\tvalid_1's rmse: 2.06285e-06\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's rmse: 6.17242e-06\tvalid_1's rmse: 1.77642e-06\n",
      "valid :  2020-05-29-US-MTV-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.533164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145199\n",
      "[LightGBM] [Info] Number of data points in the train set: 111360, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000007\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.32435e-06\tvalid_1's rmse: 2.21525e-06\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's rmse: 5.56491e-06\tvalid_1's rmse: 2.12875e-06\n",
      "valid :  2020-05-29-US-MTV-2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.529514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145196\n",
      "[LightGBM] [Info] Number of data points in the train set: 113101, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000011\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.29562e-06\tvalid_1's rmse: 4.78201e-06\n",
      "[200]\ttraining's rmse: 1.94223e-06\tvalid_1's rmse: 4.77008e-06\n",
      "Early stopping, best iteration is:\n",
      "[125]\ttraining's rmse: 2.75481e-06\tvalid_1's rmse: 4.74423e-06\n",
      "valid :  2020-06-04-US-MTV-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.469463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145203\n",
      "[LightGBM] [Info] Number of data points in the train set: 111921, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000004\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.33625e-06\tvalid_1's rmse: 4.11788e-06\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's rmse: 5.29215e-06\tvalid_1's rmse: 3.46632e-06\n",
      "valid :  2020-06-05-US-MTV-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.465849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145199\n",
      "[LightGBM] [Info] Number of data points in the train set: 111954, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000008\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.3395e-06\tvalid_1's rmse: 3.47908e-06\n",
      "[200]\ttraining's rmse: 1.9595e-06\tvalid_1's rmse: 3.24231e-06\n",
      "[300]\ttraining's rmse: 1.5496e-06\tvalid_1's rmse: 3.15345e-06\n",
      "[400]\ttraining's rmse: 1.36893e-06\tvalid_1's rmse: 3.09736e-06\n",
      "[500]\ttraining's rmse: 1.25131e-06\tvalid_1's rmse: 3.07786e-06\n",
      "[600]\ttraining's rmse: 1.16086e-06\tvalid_1's rmse: 3.07141e-06\n",
      "Early stopping, best iteration is:\n",
      "[536]\ttraining's rmse: 1.21575e-06\tvalid_1's rmse: 3.06674e-06\n",
      "valid :  2020-06-05-US-MTV-2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.475858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145199\n",
      "[LightGBM] [Info] Number of data points in the train set: 113549, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000014\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.29105e-06\tvalid_1's rmse: 2.25521e-06\n",
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's rmse: 4.07263e-06\tvalid_1's rmse: 2.11401e-06\n",
      "valid :  2020-06-11-US-MTV-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.574413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145198\n",
      "[LightGBM] [Info] Number of data points in the train set: 113346, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000008\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.32332e-06\tvalid_1's rmse: 4.66263e-06\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's rmse: 5.4778e-06\tvalid_1's rmse: 3.77342e-06\n",
      "valid :  2020-07-08-US-MTV-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.462244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145203\n",
      "[LightGBM] [Info] Number of data points in the train set: 111763, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000005\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.29699e-06\tvalid_1's rmse: 3.0475e-06\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's rmse: 4.9899e-06\tvalid_1's rmse: 2.70024e-06\n",
      "valid :  2020-08-03-US-MTV-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.562209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145199\n",
      "[LightGBM] [Info] Number of data points in the train set: 115100, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000008\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.32906e-06\tvalid_1's rmse: 2.05344e-06\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's rmse: 6.22723e-06\tvalid_1's rmse: 1.60663e-06\n",
      "valid :  2020-08-06-US-MTV-2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.546425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145195\n",
      "[LightGBM] [Info] Number of data points in the train set: 113571, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000011\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.27769e-06\tvalid_1's rmse: 1.36137e-05\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's rmse: 7.90184e-06\tvalid_1's rmse: 1.12856e-05\n",
      "valid :  2020-09-04-US-SF-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.547950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145202\n",
      "[LightGBM] [Info] Number of data points in the train set: 113628, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000006\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.37142e-06\tvalid_1's rmse: 6.98354e-06\n",
      "[200]\ttraining's rmse: 1.95203e-06\tvalid_1's rmse: 5.67785e-06\n",
      "[300]\ttraining's rmse: 1.5373e-06\tvalid_1's rmse: 5.39167e-06\n",
      "[400]\ttraining's rmse: 1.3556e-06\tvalid_1's rmse: 5.29423e-06\n",
      "Early stopping, best iteration is:\n",
      "[378]\ttraining's rmse: 1.38934e-06\tvalid_1's rmse: 5.2775e-06\n",
      "valid :  2020-09-04-US-SF-2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.547598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145203\n",
      "[LightGBM] [Info] Number of data points in the train set: 113502, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000013\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.00678e-06\tvalid_1's rmse: 5.58364e-05\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's rmse: 2.24763e-06\tvalid_1's rmse: 5.56332e-05\n",
      "valid :  2021-01-04-US-RWC-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.534025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145104\n",
      "[LightGBM] [Info] Number of data points in the train set: 108819, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000010\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.26941e-06\tvalid_1's rmse: 3.94376e-06\n",
      "[200]\ttraining's rmse: 1.93324e-06\tvalid_1's rmse: 3.72752e-06\n",
      "[300]\ttraining's rmse: 1.52635e-06\tvalid_1's rmse: 3.69674e-06\n",
      "[400]\ttraining's rmse: 1.34683e-06\tvalid_1's rmse: 3.66649e-06\n",
      "[500]\ttraining's rmse: 1.23572e-06\tvalid_1's rmse: 3.66569e-06\n",
      "[600]\ttraining's rmse: 1.15186e-06\tvalid_1's rmse: 3.65882e-06\n",
      "[700]\ttraining's rmse: 1.07378e-06\tvalid_1's rmse: 3.65049e-06\n",
      "[800]\ttraining's rmse: 1.01116e-06\tvalid_1's rmse: 3.64613e-06\n",
      "[900]\ttraining's rmse: 9.56041e-07\tvalid_1's rmse: 3.64381e-06\n",
      "[1000]\ttraining's rmse: 9.07703e-07\tvalid_1's rmse: 3.64109e-06\n",
      "Early stopping, best iteration is:\n",
      "[974]\ttraining's rmse: 9.19018e-07\tvalid_1's rmse: 3.63912e-06\n",
      "valid :  2021-01-04-US-RWC-2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.473428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145090\n",
      "[LightGBM] [Info] Number of data points in the train set: 109536, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000010\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.23539e-06\tvalid_1's rmse: 5.18802e-06\n",
      "[200]\ttraining's rmse: 1.93125e-06\tvalid_1's rmse: 4.8654e-06\n",
      "[300]\ttraining's rmse: 1.51151e-06\tvalid_1's rmse: 4.8481e-06\n",
      "[400]\ttraining's rmse: 1.33402e-06\tvalid_1's rmse: 4.83877e-06\n",
      "[500]\ttraining's rmse: 1.21383e-06\tvalid_1's rmse: 4.80693e-06\n",
      "[600]\ttraining's rmse: 1.12421e-06\tvalid_1's rmse: 4.80181e-06\n",
      "Early stopping, best iteration is:\n",
      "[580]\ttraining's rmse: 1.13949e-06\tvalid_1's rmse: 4.79489e-06\n",
      "valid :  2021-01-05-US-SVL-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.550518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145171\n",
      "[LightGBM] [Info] Number of data points in the train set: 112816, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000010\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.34519e-06\tvalid_1's rmse: 8.71386e-06\n",
      "[200]\ttraining's rmse: 1.95335e-06\tvalid_1's rmse: 7.84878e-06\n",
      "[300]\ttraining's rmse: 1.52524e-06\tvalid_1's rmse: 7.6505e-06\n",
      "[400]\ttraining's rmse: 1.34647e-06\tvalid_1's rmse: 7.55433e-06\n",
      "[500]\ttraining's rmse: 1.23136e-06\tvalid_1's rmse: 7.52425e-06\n",
      "[600]\ttraining's rmse: 1.14604e-06\tvalid_1's rmse: 7.48266e-06\n",
      "[700]\ttraining's rmse: 1.07317e-06\tvalid_1's rmse: 7.46179e-06\n",
      "[800]\ttraining's rmse: 1.00955e-06\tvalid_1's rmse: 7.44639e-06\n",
      "[900]\ttraining's rmse: 9.53485e-07\tvalid_1's rmse: 7.43085e-06\n",
      "[1000]\ttraining's rmse: 9.07586e-07\tvalid_1's rmse: 7.42286e-06\n",
      "[1100]\ttraining's rmse: 8.63794e-07\tvalid_1's rmse: 7.41341e-06\n",
      "[1200]\ttraining's rmse: 8.23347e-07\tvalid_1's rmse: 7.40281e-06\n",
      "[1300]\ttraining's rmse: 7.86296e-07\tvalid_1's rmse: 7.39611e-06\n",
      "[1400]\ttraining's rmse: 7.52226e-07\tvalid_1's rmse: 7.38919e-06\n",
      "[1500]\ttraining's rmse: 7.22405e-07\tvalid_1's rmse: 7.38373e-06\n",
      "[1600]\ttraining's rmse: 6.93467e-07\tvalid_1's rmse: 7.37493e-06\n",
      "[1700]\ttraining's rmse: 6.67952e-07\tvalid_1's rmse: 7.37465e-06\n",
      "[1800]\ttraining's rmse: 6.4257e-07\tvalid_1's rmse: 7.37255e-06\n",
      "[1900]\ttraining's rmse: 6.18484e-07\tvalid_1's rmse: 7.37252e-06\n",
      "Early stopping, best iteration is:\n",
      "[1827]\ttraining's rmse: 6.35633e-07\tvalid_1's rmse: 7.37152e-06\n",
      "valid :  2021-01-05-US-SVL-2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.540369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145195\n",
      "[LightGBM] [Info] Number of data points in the train set: 113463, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000009\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.3043e-06\tvalid_1's rmse: 5.31586e-06\n",
      "Early stopping, best iteration is:\n",
      "[81]\ttraining's rmse: 3.99005e-06\tvalid_1's rmse: 5.21709e-06\n",
      "valid :  2021-03-10-US-SVL-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.688459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145204\n",
      "[LightGBM] [Info] Number of data points in the train set: 114064, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000009\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.31524e-06\tvalid_1's rmse: 4.46507e-06\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's rmse: 8.29456e-06\tvalid_1's rmse: 4.05232e-06\n",
      "valid :  2021-04-15-US-MTV-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.152680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145199\n",
      "[LightGBM] [Info] Number of data points in the train set: 110207, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000010\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.32919e-06\tvalid_1's rmse: 1.92672e-06\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's rmse: 4.18811e-06\tvalid_1's rmse: 1.87412e-06\n",
      "valid :  2021-04-22-US-SJC-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.032482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145203\n",
      "[LightGBM] [Info] Number of data points in the train set: 111394, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000010\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.25547e-06\tvalid_1's rmse: 5.12205e-06\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's rmse: 6.78963e-06\tvalid_1's rmse: 4.69904e-06\n",
      "valid :  2021-04-26-US-SVL-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.589149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145195\n",
      "[LightGBM] [Info] Number of data points in the train set: 116075, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000009\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.25885e-06\tvalid_1's rmse: 9.78167e-07\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's rmse: 5.75367e-06\tvalid_1's rmse: 9.32039e-07\n",
      "valid :  2021-04-28-US-MTV-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.900655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145199\n",
      "[LightGBM] [Info] Number of data points in the train set: 111146, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000010\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.40021e-06\tvalid_1's rmse: 1.46084e-06\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's rmse: 6.30644e-06\tvalid_1's rmse: 1.41784e-06\n",
      "valid :  2021-04-28-US-SJC-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.653354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145206\n",
      "[LightGBM] [Info] Number of data points in the train set: 113013, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000010\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.21042e-06\tvalid_1's rmse: 8.7183e-06\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's rmse: 6.50027e-06\tvalid_1's rmse: 6.90377e-06\n",
      "valid :  2021-04-29-US-MTV-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.858283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145178\n",
      "[LightGBM] [Info] Number of data points in the train set: 112254, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000010\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.35902e-06\tvalid_1's rmse: 4.64745e-06\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's rmse: 6.94924e-06\tvalid_1's rmse: 2.94735e-06\n",
      "valid :  2021-04-29-US-SJC-2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.662185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145199\n",
      "[LightGBM] [Info] Number of data points in the train set: 112410, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score 0.000010\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.26129e-06\tvalid_1's rmse: 3.78851e-06\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's rmse: 3.78041e-06\tvalid_1's rmse: 3.59606e-06\n",
      "lng_diff\n",
      "valid :  2020-05-14-US-MTV-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.471712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145195\n",
      "[LightGBM] [Info] Number of data points in the train set: 113624, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000018\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.43809e-06\tvalid_1's rmse: 3.71965e-06\n",
      "[200]\ttraining's rmse: 2.37447e-06\tvalid_1's rmse: 3.68642e-06\n",
      "[300]\ttraining's rmse: 1.99215e-06\tvalid_1's rmse: 3.67079e-06\n",
      "[400]\ttraining's rmse: 1.79515e-06\tvalid_1's rmse: 3.6498e-06\n",
      "[500]\ttraining's rmse: 1.6511e-06\tvalid_1's rmse: 3.66432e-06\n",
      "Early stopping, best iteration is:\n",
      "[413]\ttraining's rmse: 1.77475e-06\tvalid_1's rmse: 3.64849e-06\n",
      "valid :  2020-05-14-US-MTV-2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.530435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145187\n",
      "[LightGBM] [Info] Number of data points in the train set: 114763, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000026\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.4513e-06\tvalid_1's rmse: 6.48792e-06\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's rmse: 4.92679e-06\tvalid_1's rmse: 4.95205e-06\n",
      "valid :  2020-05-21-US-MTV-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.548519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145201\n",
      "[LightGBM] [Info] Number of data points in the train set: 115078, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000020\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.41426e-06\tvalid_1's rmse: 6.30349e-06\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's rmse: 5.12152e-06\tvalid_1's rmse: 3.04635e-06\n",
      "valid :  2020-05-21-US-MTV-2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.532645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145195\n",
      "[LightGBM] [Info] Number of data points in the train set: 113351, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000029\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.46137e-06\tvalid_1's rmse: 2.5222e-06\n",
      "[200]\ttraining's rmse: 2.37012e-06\tvalid_1's rmse: 2.51213e-06\n",
      "[300]\ttraining's rmse: 1.97504e-06\tvalid_1's rmse: 2.48959e-06\n",
      "[400]\ttraining's rmse: 1.78159e-06\tvalid_1's rmse: 2.447e-06\n",
      "[500]\ttraining's rmse: 1.64054e-06\tvalid_1's rmse: 2.42512e-06\n",
      "[600]\ttraining's rmse: 1.53725e-06\tvalid_1's rmse: 2.39492e-06\n",
      "[700]\ttraining's rmse: 1.44653e-06\tvalid_1's rmse: 2.38976e-06\n",
      "[800]\ttraining's rmse: 1.36502e-06\tvalid_1's rmse: 2.37731e-06\n",
      "[900]\ttraining's rmse: 1.29554e-06\tvalid_1's rmse: 2.37244e-06\n",
      "[1000]\ttraining's rmse: 1.22606e-06\tvalid_1's rmse: 2.35503e-06\n",
      "Early stopping, best iteration is:\n",
      "[943]\ttraining's rmse: 1.26436e-06\tvalid_1's rmse: 2.35251e-06\n",
      "valid :  2020-05-29-US-MTV-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.486848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145199\n",
      "[LightGBM] [Info] Number of data points in the train set: 111360, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000016\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.51364e-06\tvalid_1's rmse: 2.09524e-06\n",
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's rmse: 4.02262e-06\tvalid_1's rmse: 2.07985e-06\n",
      "valid :  2020-05-29-US-MTV-2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.484758 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145196\n",
      "[LightGBM] [Info] Number of data points in the train set: 113101, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.42098e-06\tvalid_1's rmse: 1.26703e-05\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's rmse: 4.21423e-06\tvalid_1's rmse: 1.22274e-05\n",
      "valid :  2020-06-04-US-MTV-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.529954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145203\n",
      "[LightGBM] [Info] Number of data points in the train set: 111921, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000014\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.48289e-06\tvalid_1's rmse: 2.74901e-06\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's rmse: 5.15067e-06\tvalid_1's rmse: 2.31998e-06\n",
      "valid :  2020-06-05-US-MTV-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.521436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145199\n",
      "[LightGBM] [Info] Number of data points in the train set: 111954, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000017\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.45437e-06\tvalid_1's rmse: 4.81068e-06\n",
      "[200]\ttraining's rmse: 2.38324e-06\tvalid_1's rmse: 4.45849e-06\n",
      "[300]\ttraining's rmse: 1.99874e-06\tvalid_1's rmse: 4.42331e-06\n",
      "[400]\ttraining's rmse: 1.79891e-06\tvalid_1's rmse: 4.3641e-06\n",
      "[500]\ttraining's rmse: 1.66209e-06\tvalid_1's rmse: 4.32939e-06\n",
      "[600]\ttraining's rmse: 1.54947e-06\tvalid_1's rmse: 4.33252e-06\n",
      "Early stopping, best iteration is:\n",
      "[543]\ttraining's rmse: 1.61053e-06\tvalid_1's rmse: 4.31977e-06\n",
      "valid :  2020-06-05-US-MTV-2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.462668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145199\n",
      "[LightGBM] [Info] Number of data points in the train set: 113549, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.40088e-06\tvalid_1's rmse: 3.70774e-06\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's rmse: 4.80907e-06\tvalid_1's rmse: 3.39607e-06\n",
      "valid :  2020-06-11-US-MTV-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.481606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145198\n",
      "[LightGBM] [Info] Number of data points in the train set: 113346, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000018\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.4762e-06\tvalid_1's rmse: 2.64426e-06\n",
      "[200]\ttraining's rmse: 2.38731e-06\tvalid_1's rmse: 2.50894e-06\n",
      "[300]\ttraining's rmse: 1.99871e-06\tvalid_1's rmse: 2.43833e-06\n",
      "[400]\ttraining's rmse: 1.78858e-06\tvalid_1's rmse: 2.38702e-06\n",
      "[500]\ttraining's rmse: 1.65841e-06\tvalid_1's rmse: 2.3681e-06\n",
      "[600]\ttraining's rmse: 1.55265e-06\tvalid_1's rmse: 2.3509e-06\n",
      "[700]\ttraining's rmse: 1.45463e-06\tvalid_1's rmse: 2.32869e-06\n",
      "[800]\ttraining's rmse: 1.37681e-06\tvalid_1's rmse: 2.31489e-06\n",
      "[900]\ttraining's rmse: 1.29998e-06\tvalid_1's rmse: 2.2825e-06\n",
      "[1000]\ttraining's rmse: 1.23955e-06\tvalid_1's rmse: 2.27674e-06\n",
      "[1100]\ttraining's rmse: 1.18142e-06\tvalid_1's rmse: 2.27477e-06\n",
      "[1200]\ttraining's rmse: 1.12846e-06\tvalid_1's rmse: 2.25871e-06\n",
      "[1300]\ttraining's rmse: 1.08238e-06\tvalid_1's rmse: 2.2504e-06\n",
      "[1400]\ttraining's rmse: 1.03648e-06\tvalid_1's rmse: 2.231e-06\n",
      "[1500]\ttraining's rmse: 9.92508e-07\tvalid_1's rmse: 2.22951e-06\n",
      "[1600]\ttraining's rmse: 9.56977e-07\tvalid_1's rmse: 2.22419e-06\n",
      "[1700]\ttraining's rmse: 9.21094e-07\tvalid_1's rmse: 2.22164e-06\n",
      "[1800]\ttraining's rmse: 8.87391e-07\tvalid_1's rmse: 2.21753e-06\n",
      "[1900]\ttraining's rmse: 8.55682e-07\tvalid_1's rmse: 2.21556e-06\n",
      "[2000]\ttraining's rmse: 8.25351e-07\tvalid_1's rmse: 2.21279e-06\n",
      "[2100]\ttraining's rmse: 7.97605e-07\tvalid_1's rmse: 2.21296e-06\n",
      "Early stopping, best iteration is:\n",
      "[2008]\ttraining's rmse: 8.22955e-07\tvalid_1's rmse: 2.21257e-06\n",
      "valid :  2020-07-08-US-MTV-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.464339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145203\n",
      "[LightGBM] [Info] Number of data points in the train set: 111763, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000015\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.48238e-06\tvalid_1's rmse: 5.84111e-06\n",
      "[200]\ttraining's rmse: 2.37734e-06\tvalid_1's rmse: 5.79923e-06\n",
      "Early stopping, best iteration is:\n",
      "[127]\ttraining's rmse: 3.06214e-06\tvalid_1's rmse: 5.73074e-06\n",
      "valid :  2020-08-03-US-MTV-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.571616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145199\n",
      "[LightGBM] [Info] Number of data points in the train set: 115100, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000020\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.45717e-06\tvalid_1's rmse: 3.73499e-06\n",
      "[200]\ttraining's rmse: 2.3734e-06\tvalid_1's rmse: 3.48634e-06\n",
      "[300]\ttraining's rmse: 1.982e-06\tvalid_1's rmse: 3.339e-06\n",
      "[400]\ttraining's rmse: 1.78106e-06\tvalid_1's rmse: 3.32495e-06\n",
      "Early stopping, best iteration is:\n",
      "[335]\ttraining's rmse: 1.90668e-06\tvalid_1's rmse: 3.3185e-06\n",
      "valid :  2020-08-06-US-MTV-2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.496866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145195\n",
      "[LightGBM] [Info] Number of data points in the train set: 113571, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.42829e-06\tvalid_1's rmse: 1.36002e-05\n",
      "[200]\ttraining's rmse: 2.36814e-06\tvalid_1's rmse: 1.29498e-05\n",
      "[300]\ttraining's rmse: 1.99055e-06\tvalid_1's rmse: 1.27187e-05\n",
      "[400]\ttraining's rmse: 1.78207e-06\tvalid_1's rmse: 1.26637e-05\n",
      "[500]\ttraining's rmse: 1.63468e-06\tvalid_1's rmse: 1.26237e-05\n",
      "Early stopping, best iteration is:\n",
      "[429]\ttraining's rmse: 1.7376e-06\tvalid_1's rmse: 1.2582e-05\n",
      "valid :  2020-09-04-US-SF-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.486680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145202\n",
      "[LightGBM] [Info] Number of data points in the train set: 113628, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000017\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.42655e-06\tvalid_1's rmse: 1.08133e-05\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's rmse: 5.0535e-06\tvalid_1's rmse: 9.17844e-06\n",
      "valid :  2020-09-04-US-SF-2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.484611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145203\n",
      "[LightGBM] [Info] Number of data points in the train set: 113502, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.5534e-06\tvalid_1's rmse: 3.84646e-05\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's rmse: 2.67421e-06\tvalid_1's rmse: 3.84494e-05\n",
      "valid :  2021-01-04-US-RWC-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.477988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145104\n",
      "[LightGBM] [Info] Number of data points in the train set: 108819, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000024\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.47226e-06\tvalid_1's rmse: 3.42918e-06\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's rmse: 4.37965e-06\tvalid_1's rmse: 3.36435e-06\n",
      "valid :  2021-01-04-US-RWC-2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.531231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145090\n",
      "[LightGBM] [Info] Number of data points in the train set: 109536, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000024\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.42076e-06\tvalid_1's rmse: 6.72717e-06\n",
      "[200]\ttraining's rmse: 2.29994e-06\tvalid_1's rmse: 6.63775e-06\n",
      "[300]\ttraining's rmse: 1.907e-06\tvalid_1's rmse: 6.58227e-06\n",
      "[400]\ttraining's rmse: 1.70758e-06\tvalid_1's rmse: 6.53831e-06\n",
      "Early stopping, best iteration is:\n",
      "[390]\ttraining's rmse: 1.72318e-06\tvalid_1's rmse: 6.52963e-06\n",
      "valid :  2021-01-05-US-SVL-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.472980 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145171\n",
      "[LightGBM] [Info] Number of data points in the train set: 112816, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000023\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.46491e-06\tvalid_1's rmse: 2.78383e-06\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's rmse: 5.07991e-06\tvalid_1's rmse: 2.3501e-06\n",
      "valid :  2021-01-05-US-SVL-2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.478516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145195\n",
      "[LightGBM] [Info] Number of data points in the train set: 113463, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000023\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.42521e-06\tvalid_1's rmse: 2.92869e-06\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's rmse: 3.77403e-06\tvalid_1's rmse: 2.90438e-06\n",
      "valid :  2021-03-10-US-SVL-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.848377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145204\n",
      "[LightGBM] [Info] Number of data points in the train set: 114064, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000023\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.39088e-06\tvalid_1's rmse: 3.34384e-06\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's rmse: 4.74324e-06\tvalid_1's rmse: 3.27716e-06\n",
      "valid :  2021-04-15-US-MTV-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.384896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145199\n",
      "[LightGBM] [Info] Number of data points in the train set: 110207, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000024\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.49095e-06\tvalid_1's rmse: 2.38698e-06\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's rmse: 5.0028e-06\tvalid_1's rmse: 2.29138e-06\n",
      "valid :  2021-04-22-US-SJC-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.129835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145203\n",
      "[LightGBM] [Info] Number of data points in the train set: 111394, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000023\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.3127e-06\tvalid_1's rmse: 6.15983e-06\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's rmse: 5.25398e-06\tvalid_1's rmse: 5.96399e-06\n",
      "valid :  2021-04-26-US-SVL-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.614002 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145195\n",
      "[LightGBM] [Info] Number of data points in the train set: 116075, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000023\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.46667e-06\tvalid_1's rmse: 4.98492e-06\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's rmse: 5.29202e-06\tvalid_1's rmse: 4.46443e-06\n",
      "valid :  2021-04-28-US-MTV-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.910154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145199\n",
      "[LightGBM] [Info] Number of data points in the train set: 111146, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000024\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.47236e-06\tvalid_1's rmse: 2.1807e-06\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's rmse: 5.18431e-06\tvalid_1's rmse: 1.89545e-06\n",
      "valid :  2021-04-28-US-SJC-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.593452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145206\n",
      "[LightGBM] [Info] Number of data points in the train set: 113013, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000023\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.33038e-06\tvalid_1's rmse: 9.9423e-06\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's rmse: 6.01281e-06\tvalid_1's rmse: 8.51861e-06\n",
      "valid :  2021-04-29-US-MTV-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.810490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 145178\n",
      "[LightGBM] [Info] Number of data points in the train set: 112254, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000023\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.40876e-06\tvalid_1's rmse: 5.61604e-06\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's rmse: 4.50947e-06\tvalid_1's rmse: 4.20971e-06\n",
      "valid :  2021-04-29-US-SJC-2\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.531836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 145199\n",
      "[LightGBM] [Info] Number of data points in the train set: 112410, number of used features: 571\n",
      "[LightGBM] [Info] Start training from score -0.000023\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.35976e-06\tvalid_1's rmse: 6.13623e-06\n",
      "[200]\ttraining's rmse: 2.27847e-06\tvalid_1's rmse: 6.07485e-06\n",
      "Early stopping, best iteration is:\n",
      "[194]\ttraining's rmse: 2.31609e-06\tvalid_1's rmse: 6.07058e-06\n"
     ]
    }
   ],
   "source": [
    "collections = train['collectionName'].unique()\n",
    "imp = pd.DataFrame()\n",
    "n = len(collections)\n",
    "oof = oof_org[['phone', 'millisSinceGpsEpoch']].copy()\n",
    "\n",
    "for target in [target1, target2]:\n",
    "    print(target)\n",
    "    test_preds = np.zeros(len(test))\n",
    "    oof1 = pd.DataFrame()\n",
    "    \n",
    "    for collection in collections:\n",
    "        print('valid : ', collection)\n",
    "        tr_idx = train[train['collectionName']!=collection].index\n",
    "        vl_idx = train[train['collectionName']==collection].index\n",
    "        oof_idx = oof_org[oof_org['collectionName']==collection].index\n",
    "        tr_x, tr_y = train[features].iloc[tr_idx], train[target].iloc[tr_idx]\n",
    "        vl_x, vl_y = train[features].iloc[vl_idx], train[target].iloc[vl_idx]\n",
    "        oof_x, oof_y = oof_org[features].iloc[oof_idx], oof_org[target].iloc[oof_idx]\n",
    "        tr_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "        vl_data = lgb.Dataset(vl_x, label=vl_y)\n",
    "\n",
    "        model = lgb.train(opt_params, tr_data, valid_sets=[tr_data, vl_data],\n",
    "                          num_boost_round=20000, early_stopping_rounds=100, verbose_eval=100)\n",
    "        oof_pred = model.predict(oof_x, num_iteration=model.best_iteration)\n",
    "\n",
    "        oof_tmp = oof_org.iloc[oof_idx].copy()\n",
    "        oof_tmp[target] = oof_pred\n",
    "        oof1 = oof1.append(oof_tmp)\n",
    "\n",
    "        imp_tmp = pd.DataFrame()\n",
    "        imp_tmp['feature'] = model.feature_name()\n",
    "        imp_tmp['importance'] = model.feature_importance()\n",
    "        imp_tmp['valid_collection'] = collection\n",
    "        imp_tmp['target'] = target\n",
    "        imp = imp.append(imp_tmp)\n",
    "\n",
    "        pred = model.predict(test[features], num_iteration=model.best_iteration)\n",
    "        test_preds += pred / n\n",
    "    \n",
    "    test[target] = test_preds\n",
    "    oof = oof.merge(oof1[['phone', 'millisSinceGpsEpoch', target]], on=['phone', 'millisSinceGpsEpoch'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-coordinator",
   "metadata": {},
   "source": [
    "# 結果出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "endangered-zealand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone</th>\n",
       "      <th>millisSinceGpsEpoch</th>\n",
       "      <th>lat_diff</th>\n",
       "      <th>lng_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-14-US-MTV-1_Pixel4</td>\n",
       "      <td>1273529463442</td>\n",
       "      <td>7.642816e-08</td>\n",
       "      <td>-4.508143e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-14-US-MTV-1_Pixel4</td>\n",
       "      <td>1273529464442</td>\n",
       "      <td>4.313090e-09</td>\n",
       "      <td>-1.037187e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-14-US-MTV-1_Pixel4</td>\n",
       "      <td>1273529465442</td>\n",
       "      <td>4.313090e-09</td>\n",
       "      <td>-1.768307e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-14-US-MTV-1_Pixel4</td>\n",
       "      <td>1273529466442</td>\n",
       "      <td>4.313090e-09</td>\n",
       "      <td>-2.428237e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-14-US-MTV-1_Pixel4</td>\n",
       "      <td>1273529467442</td>\n",
       "      <td>4.313090e-09</td>\n",
       "      <td>-2.142450e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117168</th>\n",
       "      <td>2021-04-29-US-SJC-2_SamsungS20Ultra</td>\n",
       "      <td>1303760315000</td>\n",
       "      <td>4.668694e-08</td>\n",
       "      <td>2.375342e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117169</th>\n",
       "      <td>2021-04-29-US-SJC-2_SamsungS20Ultra</td>\n",
       "      <td>1303760316000</td>\n",
       "      <td>-1.438678e-07</td>\n",
       "      <td>2.905691e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117170</th>\n",
       "      <td>2021-04-29-US-SJC-2_SamsungS20Ultra</td>\n",
       "      <td>1303760317000</td>\n",
       "      <td>-6.436183e-07</td>\n",
       "      <td>1.000176e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117171</th>\n",
       "      <td>2021-04-29-US-SJC-2_SamsungS20Ultra</td>\n",
       "      <td>1303760318000</td>\n",
       "      <td>3.939988e-06</td>\n",
       "      <td>6.026322e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117172</th>\n",
       "      <td>2021-04-29-US-SJC-2_SamsungS20Ultra</td>\n",
       "      <td>1303760319000</td>\n",
       "      <td>5.453207e-06</td>\n",
       "      <td>4.317503e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117173 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      phone  millisSinceGpsEpoch  \\\n",
       "0                2020-05-14-US-MTV-1_Pixel4        1273529463442   \n",
       "1                2020-05-14-US-MTV-1_Pixel4        1273529464442   \n",
       "2                2020-05-14-US-MTV-1_Pixel4        1273529465442   \n",
       "3                2020-05-14-US-MTV-1_Pixel4        1273529466442   \n",
       "4                2020-05-14-US-MTV-1_Pixel4        1273529467442   \n",
       "...                                     ...                  ...   \n",
       "117168  2021-04-29-US-SJC-2_SamsungS20Ultra        1303760315000   \n",
       "117169  2021-04-29-US-SJC-2_SamsungS20Ultra        1303760316000   \n",
       "117170  2021-04-29-US-SJC-2_SamsungS20Ultra        1303760317000   \n",
       "117171  2021-04-29-US-SJC-2_SamsungS20Ultra        1303760318000   \n",
       "117172  2021-04-29-US-SJC-2_SamsungS20Ultra        1303760319000   \n",
       "\n",
       "            lat_diff      lng_diff  \n",
       "0       7.642816e-08 -4.508143e-07  \n",
       "1       4.313090e-09 -1.037187e-06  \n",
       "2       4.313090e-09 -1.768307e-07  \n",
       "3       4.313090e-09 -2.428237e-07  \n",
       "4       4.313090e-09 -2.142450e-07  \n",
       "...              ...           ...  \n",
       "117168  4.668694e-08  2.375342e-06  \n",
       "117169 -1.438678e-07  2.905691e-06  \n",
       "117170 -6.436183e-07  1.000176e-06  \n",
       "117171  3.939988e-06  6.026322e-06  \n",
       "117172  5.453207e-06  4.317503e-06  \n",
       "\n",
       "[117173 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "straight-collection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collectionName</th>\n",
       "      <th>phoneName</th>\n",
       "      <th>millisSinceGpsEpoch</th>\n",
       "      <th>latDeg</th>\n",
       "      <th>lngDeg</th>\n",
       "      <th>heightAboveWgs84EllipsoidM</th>\n",
       "      <th>phone</th>\n",
       "      <th>millisSinceGpsEpoch_s1</th>\n",
       "      <th>millisSinceGpsEpoch_s1_diff</th>\n",
       "      <th>millisSinceGpsEpoch_s2</th>\n",
       "      <th>...</th>\n",
       "      <th>lat_diff_meta</th>\n",
       "      <th>lng_diff_meta</th>\n",
       "      <th>lat_diff_meta_s1</th>\n",
       "      <th>lat_diff_meta_s1_diff</th>\n",
       "      <th>lat_diff_meta_roll_mean</th>\n",
       "      <th>lng_diff_meta_roll_mean</th>\n",
       "      <th>lat_diff_meta_roll_std</th>\n",
       "      <th>lng_diff_meta_roll_std</th>\n",
       "      <th>lat_diff</th>\n",
       "      <th>lng_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-15-US-MTV-1</td>\n",
       "      <td>Pixel4</td>\n",
       "      <td>1273608785432</td>\n",
       "      <td>37.416628</td>\n",
       "      <td>-122.082053</td>\n",
       "      <td>-30.69</td>\n",
       "      <td>2020-05-15-US-MTV-1_Pixel4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.184321e-07</td>\n",
       "      <td>-1.081375e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.188121e-09</td>\n",
       "      <td>-2.218806e-07</td>\n",
       "      <td>7.029347e-08</td>\n",
       "      <td>4.831168e-07</td>\n",
       "      <td>4.848696e-08</td>\n",
       "      <td>-6.162366e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-15-US-MTV-1</td>\n",
       "      <td>Pixel4</td>\n",
       "      <td>1273608786432</td>\n",
       "      <td>37.416646</td>\n",
       "      <td>-122.082040</td>\n",
       "      <td>-31.76</td>\n",
       "      <td>2020-05-15-US-MTV-1_Pixel4</td>\n",
       "      <td>1.273609e+12</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.010947e-08</td>\n",
       "      <td>-8.364074e-08</td>\n",
       "      <td>-1.184321e-07</td>\n",
       "      <td>1.083227e-07</td>\n",
       "      <td>6.146181e-09</td>\n",
       "      <td>-1.819964e-07</td>\n",
       "      <td>6.538876e-08</td>\n",
       "      <td>4.430192e-07</td>\n",
       "      <td>5.259774e-08</td>\n",
       "      <td>-1.501509e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-15-US-MTV-1</td>\n",
       "      <td>Pixel4</td>\n",
       "      <td>1273608787432</td>\n",
       "      <td>37.416653</td>\n",
       "      <td>-122.082039</td>\n",
       "      <td>-31.65</td>\n",
       "      <td>2020-05-15-US-MTV-1_Pixel4</td>\n",
       "      <td>1.273609e+12</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.273609e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>2.443408e-08</td>\n",
       "      <td>-2.115849e-08</td>\n",
       "      <td>-1.010947e-08</td>\n",
       "      <td>3.454355e-08</td>\n",
       "      <td>1.078255e-08</td>\n",
       "      <td>-1.596549e-07</td>\n",
       "      <td>6.093887e-08</td>\n",
       "      <td>4.087162e-07</td>\n",
       "      <td>6.786127e-08</td>\n",
       "      <td>-4.746413e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-15-US-MTV-1</td>\n",
       "      <td>Pixel4</td>\n",
       "      <td>1273608788432</td>\n",
       "      <td>37.416607</td>\n",
       "      <td>-122.082063</td>\n",
       "      <td>-31.52</td>\n",
       "      <td>2020-05-15-US-MTV-1_Pixel4</td>\n",
       "      <td>1.273609e+12</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.273609e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>3.840679e-08</td>\n",
       "      <td>3.808520e-08</td>\n",
       "      <td>2.443408e-08</td>\n",
       "      <td>1.397271e-08</td>\n",
       "      <td>1.416572e-08</td>\n",
       "      <td>-1.428887e-07</td>\n",
       "      <td>5.722417e-08</td>\n",
       "      <td>3.813577e-07</td>\n",
       "      <td>6.604939e-08</td>\n",
       "      <td>9.181628e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-15-US-MTV-1</td>\n",
       "      <td>Pixel4</td>\n",
       "      <td>1273608789432</td>\n",
       "      <td>37.416609</td>\n",
       "      <td>-122.082073</td>\n",
       "      <td>-28.95</td>\n",
       "      <td>2020-05-15-US-MTV-1_Pixel4</td>\n",
       "      <td>1.273609e+12</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.273609e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>5.976011e-08</td>\n",
       "      <td>3.868589e-08</td>\n",
       "      <td>3.840679e-08</td>\n",
       "      <td>2.135332e-08</td>\n",
       "      <td>1.782573e-08</td>\n",
       "      <td>-1.282815e-07</td>\n",
       "      <td>5.464285e-08</td>\n",
       "      <td>3.594090e-07</td>\n",
       "      <td>5.591566e-08</td>\n",
       "      <td>4.774714e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85674</th>\n",
       "      <td>2021-04-29-US-SJC-3</td>\n",
       "      <td>SamsungS20Ultra</td>\n",
       "      <td>1303763185000</td>\n",
       "      <td>37.334539</td>\n",
       "      <td>-121.899383</td>\n",
       "      <td>-8.39</td>\n",
       "      <td>2021-04-29-US-SJC-3_SamsungS20Ultra</td>\n",
       "      <td>1.303763e+12</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.303763e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>4.109606e-08</td>\n",
       "      <td>-4.836975e-08</td>\n",
       "      <td>4.967414e-08</td>\n",
       "      <td>-8.578072e-09</td>\n",
       "      <td>-1.106133e-07</td>\n",
       "      <td>-6.915032e-07</td>\n",
       "      <td>4.334301e-07</td>\n",
       "      <td>2.292981e-06</td>\n",
       "      <td>6.337661e-08</td>\n",
       "      <td>-6.726324e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85675</th>\n",
       "      <td>2021-04-29-US-SJC-3</td>\n",
       "      <td>SamsungS20Ultra</td>\n",
       "      <td>1303763186000</td>\n",
       "      <td>37.334545</td>\n",
       "      <td>-121.899380</td>\n",
       "      <td>-7.36</td>\n",
       "      <td>2021-04-29-US-SJC-3_SamsungS20Ultra</td>\n",
       "      <td>1.303763e+12</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.303763e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>9.169505e-08</td>\n",
       "      <td>4.871519e-08</td>\n",
       "      <td>4.109606e-08</td>\n",
       "      <td>5.059899e-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.941823e-08</td>\n",
       "      <td>9.305772e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85676</th>\n",
       "      <td>2021-04-29-US-SJC-3</td>\n",
       "      <td>SamsungS20Ultra</td>\n",
       "      <td>1303763187000</td>\n",
       "      <td>37.334551</td>\n",
       "      <td>-121.899371</td>\n",
       "      <td>-4.08</td>\n",
       "      <td>2021-04-29-US-SJC-3_SamsungS20Ultra</td>\n",
       "      <td>1.303763e+12</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.303763e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>2.638764e-07</td>\n",
       "      <td>3.348728e-07</td>\n",
       "      <td>9.169505e-08</td>\n",
       "      <td>1.721814e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.246651e-08</td>\n",
       "      <td>1.588271e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85677</th>\n",
       "      <td>2021-04-29-US-SJC-3</td>\n",
       "      <td>SamsungS20Ultra</td>\n",
       "      <td>1303763188000</td>\n",
       "      <td>37.334540</td>\n",
       "      <td>-121.899371</td>\n",
       "      <td>-5.70</td>\n",
       "      <td>2021-04-29-US-SJC-3_SamsungS20Ultra</td>\n",
       "      <td>1.303763e+12</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.303763e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.514531e-07</td>\n",
       "      <td>-1.749042e-07</td>\n",
       "      <td>2.638764e-07</td>\n",
       "      <td>-8.153295e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.445455e-07</td>\n",
       "      <td>-7.649551e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85678</th>\n",
       "      <td>2021-04-29-US-SJC-3</td>\n",
       "      <td>SamsungS20Ultra</td>\n",
       "      <td>1303763189000</td>\n",
       "      <td>37.334562</td>\n",
       "      <td>-121.899354</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>2021-04-29-US-SJC-3_SamsungS20Ultra</td>\n",
       "      <td>1.303763e+12</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.303763e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.190453e-06</td>\n",
       "      <td>-7.207612e-06</td>\n",
       "      <td>-5.514531e-07</td>\n",
       "      <td>-6.390001e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.083382e-06</td>\n",
       "      <td>-6.035953e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85679 rows × 580 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            collectionName        phoneName  millisSinceGpsEpoch     latDeg  \\\n",
       "0      2020-05-15-US-MTV-1           Pixel4        1273608785432  37.416628   \n",
       "1      2020-05-15-US-MTV-1           Pixel4        1273608786432  37.416646   \n",
       "2      2020-05-15-US-MTV-1           Pixel4        1273608787432  37.416653   \n",
       "3      2020-05-15-US-MTV-1           Pixel4        1273608788432  37.416607   \n",
       "4      2020-05-15-US-MTV-1           Pixel4        1273608789432  37.416609   \n",
       "...                    ...              ...                  ...        ...   \n",
       "85674  2021-04-29-US-SJC-3  SamsungS20Ultra        1303763185000  37.334539   \n",
       "85675  2021-04-29-US-SJC-3  SamsungS20Ultra        1303763186000  37.334545   \n",
       "85676  2021-04-29-US-SJC-3  SamsungS20Ultra        1303763187000  37.334551   \n",
       "85677  2021-04-29-US-SJC-3  SamsungS20Ultra        1303763188000  37.334540   \n",
       "85678  2021-04-29-US-SJC-3  SamsungS20Ultra        1303763189000  37.334562   \n",
       "\n",
       "           lngDeg  heightAboveWgs84EllipsoidM  \\\n",
       "0     -122.082053                      -30.69   \n",
       "1     -122.082040                      -31.76   \n",
       "2     -122.082039                      -31.65   \n",
       "3     -122.082063                      -31.52   \n",
       "4     -122.082073                      -28.95   \n",
       "...           ...                         ...   \n",
       "85674 -121.899383                       -8.39   \n",
       "85675 -121.899380                       -7.36   \n",
       "85676 -121.899371                       -4.08   \n",
       "85677 -121.899371                       -5.70   \n",
       "85678 -121.899354                       -0.90   \n",
       "\n",
       "                                     phone  millisSinceGpsEpoch_s1  \\\n",
       "0               2020-05-15-US-MTV-1_Pixel4                     NaN   \n",
       "1               2020-05-15-US-MTV-1_Pixel4            1.273609e+12   \n",
       "2               2020-05-15-US-MTV-1_Pixel4            1.273609e+12   \n",
       "3               2020-05-15-US-MTV-1_Pixel4            1.273609e+12   \n",
       "4               2020-05-15-US-MTV-1_Pixel4            1.273609e+12   \n",
       "...                                    ...                     ...   \n",
       "85674  2021-04-29-US-SJC-3_SamsungS20Ultra            1.303763e+12   \n",
       "85675  2021-04-29-US-SJC-3_SamsungS20Ultra            1.303763e+12   \n",
       "85676  2021-04-29-US-SJC-3_SamsungS20Ultra            1.303763e+12   \n",
       "85677  2021-04-29-US-SJC-3_SamsungS20Ultra            1.303763e+12   \n",
       "85678  2021-04-29-US-SJC-3_SamsungS20Ultra            1.303763e+12   \n",
       "\n",
       "       millisSinceGpsEpoch_s1_diff  millisSinceGpsEpoch_s2  ...  \\\n",
       "0                              NaN                     NaN  ...   \n",
       "1                           1000.0                     NaN  ...   \n",
       "2                           1000.0            1.273609e+12  ...   \n",
       "3                           1000.0            1.273609e+12  ...   \n",
       "4                           1000.0            1.273609e+12  ...   \n",
       "...                            ...                     ...  ...   \n",
       "85674                       1000.0            1.303763e+12  ...   \n",
       "85675                       1000.0            1.303763e+12  ...   \n",
       "85676                       1000.0            1.303763e+12  ...   \n",
       "85677                       1000.0            1.303763e+12  ...   \n",
       "85678                       1000.0            1.303763e+12  ...   \n",
       "\n",
       "       lat_diff_meta  lng_diff_meta  lat_diff_meta_s1  lat_diff_meta_s1_diff  \\\n",
       "0      -1.184321e-07  -1.081375e-06               NaN                    NaN   \n",
       "1      -1.010947e-08  -8.364074e-08     -1.184321e-07           1.083227e-07   \n",
       "2       2.443408e-08  -2.115849e-08     -1.010947e-08           3.454355e-08   \n",
       "3       3.840679e-08   3.808520e-08      2.443408e-08           1.397271e-08   \n",
       "4       5.976011e-08   3.868589e-08      3.840679e-08           2.135332e-08   \n",
       "...              ...            ...               ...                    ...   \n",
       "85674   4.109606e-08  -4.836975e-08      4.967414e-08          -8.578072e-09   \n",
       "85675   9.169505e-08   4.871519e-08      4.109606e-08           5.059899e-08   \n",
       "85676   2.638764e-07   3.348728e-07      9.169505e-08           1.721814e-07   \n",
       "85677  -5.514531e-07  -1.749042e-07      2.638764e-07          -8.153295e-07   \n",
       "85678  -1.190453e-06  -7.207612e-06     -5.514531e-07          -6.390001e-07   \n",
       "\n",
       "       lat_diff_meta_roll_mean  lng_diff_meta_roll_mean  \\\n",
       "0                -1.188121e-09            -2.218806e-07   \n",
       "1                 6.146181e-09            -1.819964e-07   \n",
       "2                 1.078255e-08            -1.596549e-07   \n",
       "3                 1.416572e-08            -1.428887e-07   \n",
       "4                 1.782573e-08            -1.282815e-07   \n",
       "...                        ...                      ...   \n",
       "85674            -1.106133e-07            -6.915032e-07   \n",
       "85675                      NaN                      NaN   \n",
       "85676                      NaN                      NaN   \n",
       "85677                      NaN                      NaN   \n",
       "85678                      NaN                      NaN   \n",
       "\n",
       "       lat_diff_meta_roll_std  lng_diff_meta_roll_std      lat_diff  \\\n",
       "0                7.029347e-08            4.831168e-07  4.848696e-08   \n",
       "1                6.538876e-08            4.430192e-07  5.259774e-08   \n",
       "2                6.093887e-08            4.087162e-07  6.786127e-08   \n",
       "3                5.722417e-08            3.813577e-07  6.604939e-08   \n",
       "4                5.464285e-08            3.594090e-07  5.591566e-08   \n",
       "...                       ...                     ...           ...   \n",
       "85674            4.334301e-07            2.292981e-06  6.337661e-08   \n",
       "85675                     NaN                     NaN -5.941823e-08   \n",
       "85676                     NaN                     NaN  1.246651e-08   \n",
       "85677                     NaN                     NaN -4.445455e-07   \n",
       "85678                     NaN                     NaN -1.083382e-06   \n",
       "\n",
       "           lng_diff  \n",
       "0     -6.162366e-07  \n",
       "1     -1.501509e-07  \n",
       "2     -4.746413e-09  \n",
       "3      9.181628e-08  \n",
       "4      4.774714e-08  \n",
       "...             ...  \n",
       "85674 -6.726324e-08  \n",
       "85675  9.305772e-07  \n",
       "85676  1.588271e-06  \n",
       "85677 -7.649551e-08  \n",
       "85678 -6.035953e-06  \n",
       "\n",
       "[85679 rows x 580 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "friendly-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['phone', 'millisSinceGpsEpoch', 'lat_diff', 'lng_diff']\n",
    "oof[cols].to_csv(OUTPUT+'/train_result.csv', index=False)\n",
    "test[cols].to_csv(OUTPUT+'/test_result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
