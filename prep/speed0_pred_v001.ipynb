{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unauthorized-transport",
   "metadata": {},
   "source": [
    "# speed0_pred_v001\n",
    "exp035のstop予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fancy-empire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import library\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import pathlib\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import itertools\n",
    "import lightgbm as lgb\n",
    "from optuna.integration import lightgbm as optuna_lgb\n",
    "import simdkalman\n",
    "import optuna\n",
    "import pyproj\n",
    "from pyproj import Proj, transform\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, confusion_matrix, accuracy_score\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fiscal-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb_path\n",
    "\n",
    "def get_nb_name():\n",
    "    nb_path = ipynb_path.get()\n",
    "    nb_name = nb_path.rsplit('/',1)[1].replace('.ipynb','')\n",
    "    return nb_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "according-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory setting\n",
    "nb_name = get_nb_name()\n",
    "INPUT = '../input/google-smartphone-decimeter-challenge'\n",
    "OUTPUT = '../output/prep/' + nb_name\n",
    "os.makedirs(OUTPUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-street",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "legitimate-parish",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_score(df, gt):\n",
    "    gt = gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n",
    "    df = df.merge(gt, on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n",
    "    # calc_distance_error\n",
    "    df['err'] = calc_haversine(df['latDeg_gt'], df['lngDeg_gt'], df['latDeg'], df['lngDeg'])\n",
    "    # calc_evaluate_score\n",
    "    df['phone'] = df['collectionName'] + '_' + df['phoneName']\n",
    "    res = df.groupby('phone')['err'].agg([percentile50, percentile95])\n",
    "    res['p50_p90_mean'] = (res['percentile50'] + res['percentile95']) / 2 \n",
    "    score = res['p50_p90_mean'].mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "impressed-hypothetical",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculates the great circle distance between two points\n",
    "    on the earth. Inputs are array-like and specified in decimal degrees.\n",
    "    \"\"\"\n",
    "    RADIUS = 6_367_000\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + \\\n",
    "        np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    dist = 2 * RADIUS * np.arcsin(a**0.5)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "formed-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_trafic(df, center, zoom=9):\n",
    "    fig = px.scatter_mapbox(df,\n",
    "                            \n",
    "                            # Here, plotly gets, (x,y) coordinates\n",
    "                            lat=\"latDeg\",\n",
    "                            lon=\"lngDeg\",\n",
    "                            \n",
    "                            #Here, plotly detects color of series\n",
    "                            color=\"phoneName\",\n",
    "                            labels=\"phoneName\",\n",
    "                            \n",
    "                            zoom=zoom,\n",
    "                            center=center,\n",
    "                            height=600,\n",
    "                            width=800)\n",
    "    fig.update_layout(mapbox_style='stamen-terrain')\n",
    "    fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
    "    fig.update_layout(title_text=\"GPS trafic\")\n",
    "    fig.show()\n",
    "    \n",
    "def visualize_collection(df, collection):\n",
    "    target_df = df[df['collectionName']==collection].copy()\n",
    "    lat_center = target_df['latDeg'].mean()\n",
    "    lng_center = target_df['lngDeg'].mean()\n",
    "    center = {\"lat\":lat_center, \"lon\":lng_center}\n",
    "    \n",
    "    visualize_trafic(target_df, center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "special-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_truth\n",
    "def get_ground_truth():\n",
    "    p = pathlib.Path(INPUT)\n",
    "    gt_files = list(p.glob('train/*/*/ground_truth.csv'))\n",
    "\n",
    "    gts = []\n",
    "    for gt_file in gt_files:\n",
    "        gts.append(pd.read_csv(gt_file))\n",
    "    ground_truth = pd.concat(gts)\n",
    "\n",
    "    return ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "secure-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile50(x):\n",
    "    return np.percentile(x, 50)\n",
    "def percentile95(x):\n",
    "    return np.percentile(x, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "compact-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_result:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.gt = get_ground_truth()\n",
    "        self.bl = pd.read_csv(INPUT + '/' + 'baseline_locations_train.csv')\n",
    "        \n",
    "        self.gt = self.gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n",
    "        self.df = self.df.merge(self.gt, on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n",
    "        self.df['phone'] = self.df['collectionName'] + '_' + self.df['phoneName']\n",
    "        self.df['err'] =  calc_haversine(self.df['latDeg_gt'], self.df['lngDeg_gt'], self.df['latDeg'], self.df['lngDeg'])\n",
    "        \n",
    "        self.phone_res = self.calc_err('phone')\n",
    "        self.clc_res = self.calc_err('collectionName')\n",
    "        self.phonename_res = self.calc_err('phoneName')\n",
    "        \n",
    "    def calc_err(self, by):\n",
    "        res = self.df.groupby(by)['err'].agg([percentile50, percentile95])\n",
    "        res['p50_p90_mean'] = (res['percentile50'] + res['percentile95']) / 2\n",
    "        return res\n",
    "    \n",
    "    @property\n",
    "    def score(self):\n",
    "        return self.phone_res['p50_p90_mean'].mean()\n",
    "    @property\n",
    "    def raw_data(self):\n",
    "        return self.df\n",
    "    @property\n",
    "    def err(self):\n",
    "        return self.phone_res\n",
    "    @property\n",
    "    def collection_err(self):\n",
    "        return self.clc_res\n",
    "    @property\n",
    "    def phonename_err(self):\n",
    "        return self.phonename_res\n",
    "    \n",
    "    def viz_map(self, collection, show_gt=True, show_bl=True):\n",
    "        tmp = self.df[self.df['collectionName']==collection][['collectionName', 'phoneName', 'latDeg', 'lngDeg']]\n",
    "        tmp2 = self.df[self.df['collectionName']==collection][['collectionName', 'phoneName', 'latDeg_gt', 'lngDeg_gt']]\n",
    "        tmp2 = tmp2.rename(columns={'latDeg_gt':'latDeg', 'lngDeg_gt':'lngDeg'})\n",
    "        tmp2['phoneName'] = tmp2['phoneName'] + '_GT'\n",
    "        tmp3 = self.bl[self.bl['collectionName']==collection][['collectionName', 'phoneName', 'latDeg', 'lngDeg']]\n",
    "        tmp3['phoneName'] = tmp3['phoneName'] + '_BL'\n",
    "        \n",
    "        if show_gt:\n",
    "            tmp = tmp.append(tmp2)\n",
    "        if show_bl:\n",
    "            tmp = tmp.append(tmp3)\n",
    "        visualize_collection(tmp, collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "banned-participant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    base_train = pd.read_csv(INPUT + '/' + 'baseline_locations_train.csv')\n",
    "    base_test = pd.read_csv(INPUT + '/' + 'baseline_locations_test.csv')\n",
    "    sample_sub = pd.read_csv(INPUT + '/' + 'sample_submission.csv')\n",
    "    ground_truth = get_ground_truth()\n",
    "    return base_train, base_test, sample_sub, ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-height",
   "metadata": {},
   "source": [
    "# speed0の分類モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "seasonal-divide",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    for c,i in itertools.product(['latDeg', 'lngDeg', 'heightAboveWgs84EllipsoidM'], [1,2,3,4,5,-1,-2,-3,-4,-5]):\n",
    "        col = c+ '_s' + str(i)\n",
    "        df[col] = df[c].shift(i)\n",
    "        df[col+'_diff'] = df[c] - df[col]\n",
    "        df.loc[df['phone']!=df['phone'].shift(i), [col, col+'_diff']] = np.nan\n",
    "    \n",
    "    for c in ['latDeg', 'lngDeg', 'heightAboveWgs84EllipsoidM']:\n",
    "        df[c+'_s1_diff_sum'] = df[c+'_s1_diff'].fillna(0) + df[c+'_s-1_diff'].fillna(0)\n",
    "        df[c+'_s2_diff_sum'] = df[c+'_s1_diff_sum'] + df[c+'_s2_diff'].fillna(0) + df[c+'_s-2_diff'].fillna(0)\n",
    "        df[c+'_s3_diff_sum'] = df[c+'_s2_diff_sum'] + df[c+'_s3_diff'].fillna(0) + df[c+'_s-3_diff'].fillna(0)\n",
    "        df[c+'_s4_diff_sum'] = df[c+'_s3_diff_sum'] + df[c+'_s4_diff'].fillna(0) + df[c+'_s-4_diff'].fillna(0)\n",
    "        df[c+'_s5_diff_sum'] = df[c+'_s4_diff_sum'] + df[c+'_s5_diff'].fillna(0) + df[c+'_s-5_diff'].fillna(0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "raising-mentor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sensor_features(df, accel, gyro, mag):\n",
    "    # phoneを追加\n",
    "    df['phone'] = df['collectionName'] + '_' + df['phoneName']\n",
    "    accel['phone'] = accel['collectionName'] + '_' + accel['phoneName']\n",
    "    gyro['phone'] = gyro['collectionName'] + '_' + gyro['phoneName']\n",
    "    mag['phone'] = mag['collectionName'] + '_' + mag['phoneName']\n",
    "    \n",
    "    # phonenameをラベルエンコーディング\n",
    "    phoneName_map = {'Pixel4':1, 'Pixel4XLModded':2, 'Pixel4XL':3, 'Mi8':4, 'Pixel4Modded':5, 'Pixel5':6, 'SamsungS20Ultra':7}\n",
    "    df['phoneName_le'] = df['phoneName'].map(phoneName_map)\n",
    "    \n",
    "    # utc -> gps\n",
    "    accel['millisSinceGpsEpoch'] = accel['utcTimeMillis'] - 315964800000 + 18000\n",
    "    gyro['millisSinceGpsEpoch'] = gyro['utcTimeMillis'] - 315964800000 + 18000\n",
    "    mag['millisSinceGpsEpoch'] = mag['utcTimeMillis'] - 315964800000 + 18000\n",
    "    \n",
    "    # resampling追加\n",
    "    df['secondSinceGpsEpoch'] = df['millisSinceGpsEpoch'] // 1000\n",
    "    accel['secondSinceGpsEpoch'] = accel['millisSinceGpsEpoch'] // 1000\n",
    "    gyro['secondSinceGpsEpoch'] = gyro['millisSinceGpsEpoch'] // 1000\n",
    "    mag['secondSinceGpsEpoch'] = mag['millisSinceGpsEpoch'] // 1000\n",
    "    \n",
    "    # clipping\n",
    "    accel[['UncalAccelXMps2', 'UncalAccelYMps2', 'UncalAccelZMps2']] = accel.groupby('phone')['UncalAccelXMps2', 'UncalAccelYMps2', 'UncalAccelZMps2'].transform(lambda x: x.clip(x.quantile(0.001), x.quantile(0.999)))\n",
    "    gyro[['UncalGyroXRadPerSec', 'UncalGyroYRadPerSec', 'UncalGyroZRadPerSec']] = gyro.groupby('phone')['UncalGyroXRadPerSec', 'UncalGyroYRadPerSec', 'UncalGyroZRadPerSec'].transform(lambda x: x.clip(x.quantile(0.001), x.quantile(0.999)))\n",
    "    mag[['UncalMagXMicroT', 'UncalMagYMicroT', 'UncalMagZMicroT']] = mag.groupby('phone')['UncalMagXMicroT', 'UncalMagYMicroT', 'UncalMagZMicroT'].transform(lambda x: x.clip(x.quantile(0.001), x.quantile(0.999)))\n",
    "    \n",
    "    accel = accel.groupby(['phone', 'secondSinceGpsEpoch'])['UncalAccelXMps2', 'UncalAccelYMps2', 'UncalAccelZMps2'].agg(['mean', 'std']).reset_index()\n",
    "    accel.columns = ['phone', 'secondSinceGpsEpoch', 'UncalAccelXMps2_mean', 'UncalAccelXMps2_std', 'UncalAccelYMps2_mean', 'UncalAccelYMps2_std', 'UncalAccelZMps2_mean', 'UncalAccelZMps2_std']\n",
    "    gyro = gyro.groupby(['phone', 'secondSinceGpsEpoch'])['UncalGyroXRadPerSec', 'UncalGyroYRadPerSec', 'UncalGyroZRadPerSec'].agg(['mean', 'std']).reset_index()\n",
    "    gyro.columns = ['phone', 'secondSinceGpsEpoch', 'UncalGyroXRadPerSec_mean', 'UncalGyroXRadPerSec_std', 'UncalGyroYRadPerSec_mean', 'UncalGyroYRadPerSec_std', 'UncalGyroZRadPerSec_mean', 'UncalGyroZRadPerSec_std' ]\n",
    "    mag = mag.groupby(['phone', 'secondSinceGpsEpoch'])['UncalMagXMicroT', 'UncalMagYMicroT', 'UncalMagZMicroT'].agg(['mean', 'std']).reset_index()\n",
    "    mag.columns = ['phone', 'secondSinceGpsEpoch', 'UncalMagXMicroT_mean', 'UncalMagXMicroT_std', 'UncalMagYMicroT_mean', 'UncalMagYMicroT_std', 'UncalMagZMicroT_mean', 'UncalMagZMicroT_std']\n",
    "    \n",
    "    # shift特徴量\n",
    "    for c, i in itertools.product(['UncalAccelXMps2_mean', 'UncalAccelXMps2_std', 'UncalAccelYMps2_mean', 'UncalAccelYMps2_std', 'UncalAccelZMps2_mean', 'UncalAccelZMps2_std'], [1,2,3,4,5-1,-2,-3,-4,-5]):\n",
    "        col = c+ '_s' + str(i)\n",
    "        accel[col] = accel[c].shift(i)\n",
    "        accel[col+'_diff'] = accel[c] - accel[col]\n",
    "        accel.loc[accel['phone']!=accel['phone'].shift(i), [col, col+'_diff']] = np.nan\n",
    "    for c, i in itertools.product(['UncalGyroXRadPerSec_mean', 'UncalGyroXRadPerSec_std', 'UncalGyroYRadPerSec_mean', 'UncalGyroYRadPerSec_std', 'UncalGyroZRadPerSec_mean', 'UncalGyroZRadPerSec_std'], [1,2,3,4,5-1,-2,-3,-4,-5]):\n",
    "        col = c+ '_s' + str(i)\n",
    "        gyro[col] = gyro[c].shift(i)\n",
    "        gyro[col+'_diff'] = gyro[c] - gyro[col]\n",
    "        gyro.loc[gyro['phone']!=gyro['phone'].shift(i), [col, col+'_diff']] = np.nan\n",
    "    for c, i in itertools.product(['UncalMagXMicroT_mean', 'UncalMagXMicroT_std', 'UncalMagYMicroT_mean', 'UncalMagYMicroT_std', 'UncalMagZMicroT_mean', 'UncalMagZMicroT_std'], [1,2,3,4,5-1,-2,-3,-4,-5]):\n",
    "        col = c+ '_s' + str(i)\n",
    "        mag[col] = mag[c].shift(i)\n",
    "        mag[col+'_diff'] = mag[c] - mag[col]\n",
    "        mag.loc[mag['phone']!=mag['phone'].shift(i), [col, col+'_diff']] = np.nan\n",
    "        \n",
    "    \n",
    "    df = df.merge(accel, on=['phone', 'secondSinceGpsEpoch'], how='left')\n",
    "    df = df.merge(gyro, on=['phone', 'secondSinceGpsEpoch'], how='left')\n",
    "    df = df.merge(mag, on=['phone', 'secondSinceGpsEpoch'], how='left')\n",
    "    \n",
    "    df.drop(['secondSinceGpsEpoch'], axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-separation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:24: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:25: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:26: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:28: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:30: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n"
     ]
    }
   ],
   "source": [
    "train, test, sub, gt = get_data()\n",
    "accel_train = pd.read_csv(INPUT + '/prep/gnss/train/UncalAccel.csv')\n",
    "gyro_train = pd.read_csv(INPUT + '/prep/gnss/train/UncalGyro.csv')\n",
    "mag_train = pd.read_csv(INPUT + '/prep/gnss/train/UncalMag.csv')\n",
    "accel_test = pd.read_csv(INPUT + '/prep/gnss/test/UncalAccel.csv')\n",
    "gyro_test = pd.read_csv(INPUT + '/prep/gnss/test/UncalGyro.csv')\n",
    "mag_test = pd.read_csv(INPUT + '/prep/gnss/test/UncalMag.csv')\n",
    "\n",
    "train = train.merge(gt[['collectionName', 'phoneName', 'millisSinceGpsEpoch', 'speedMps']], on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n",
    "train.loc[train['speedMps']==0.0, 'isSpeed0'] = 1\n",
    "train['isSpeed0'] = train['isSpeed0'].fillna(0)\n",
    "train = add_features(train)\n",
    "test = add_features(test)\n",
    "\n",
    "train = add_sensor_features(train, accel_train, gyro_train, mag_train)\n",
    "test = add_sensor_features(test, accel_test, gyro_test, mag_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-geneva",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'isSpeed0'\n",
    "not_use_cols = ['speedMps', 'collectionName', 'phoneName', 'phone', 'millisSinceGpsEpoch', 'latDeg', 'lngDeg', 'heightAboveWgs84EllipsoidM',\n",
    "                'latDeg_s1', 'latDeg_s2', 'latDeg_s3', 'latDeg_s-1', 'latDeg_s-2',\n",
    "                'latDeg_s-3', 'lngDeg_s1', 'lngDeg_s2', 'lngDeg_s3', 'lngDeg_s-1',\n",
    "                'lngDeg_s-2', 'lngDeg_s-3', 'heightAboveWgs84EllipsoidM_s1',\n",
    "                'heightAboveWgs84EllipsoidM_s2', 'heightAboveWgs84EllipsoidM_s3',\n",
    "                'heightAboveWgs84EllipsoidM_s-1', 'heightAboveWgs84EllipsoidM_s-2',\n",
    "                'heightAboveWgs84EllipsoidM_s-3', target]\n",
    "features = [c for c in train.columns if c not in not_use_cols]\n",
    "\n",
    "opt_params = {'objective': 'binary', \n",
    "              'learning_rate': 0.1, \n",
    "              'seed': 42, \n",
    "              'feature_pre_filter': False, \n",
    "              'lambda_l1': 5.430530747001109e-05, \n",
    "              'lambda_l2': 3.4066721259729875, \n",
    "              'num_leaves': 136, \n",
    "              'feature_fraction': 0.8999999999999999, \n",
    "              'bagging_fraction': 1.0, \n",
    "              'bagging_freq': 0, \n",
    "              'min_child_samples': 20, \n",
    "              'num_iterations': 20000, \n",
    "              'early_stopping_round': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = train['collectionName'].unique()\n",
    "\n",
    "oof = pd.DataFrame()\n",
    "imp = pd.DataFrame()\n",
    "test_preds = np.zeros(len(test))\n",
    "n = len(collections)\n",
    "\n",
    "for collection in collections:\n",
    "    print('valid : ', collection)\n",
    "    tr_idx = train[train['collectionName']!=collection].index\n",
    "    vl_idx = train[train['collectionName']==collection].index\n",
    "    tr_x, tr_y = train[features].iloc[tr_idx], train[target].iloc[tr_idx]\n",
    "    vl_x, vl_y = train[features].iloc[vl_idx], train[target].iloc[vl_idx]\n",
    "    tr_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "    vl_data = lgb.Dataset(vl_x, label=vl_y)\n",
    "    \n",
    "    model = lgb.train(opt_params, tr_data, valid_sets=[tr_data, vl_data],\n",
    "                      num_boost_round=20000, early_stopping_rounds=100, verbose_eval=100)\n",
    "    vl_pred = model.predict(vl_x, num_iteration=model.best_iteration)\n",
    "    \n",
    "    oof_tmp = train.iloc[vl_idx].copy()\n",
    "    oof_tmp['pred'] = vl_pred\n",
    "    oof = oof.append(oof_tmp)\n",
    "    \n",
    "    imp_tmp = pd.DataFrame()\n",
    "    imp_tmp['feature'] = model.feature_name()\n",
    "    imp_tmp['importance'] = model.feature_importance()\n",
    "    imp_tmp['valid_collection'] = collection\n",
    "    imp = imp.append(imp_tmp)\n",
    "    \n",
    "    pred = model.predict(test[features], num_iteration=model.best_iteration)\n",
    "    test_preds += pred / n\n",
    "test['pred'] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean = imp.groupby('feature').mean().reset_index()\n",
    "plt.figure(figsize=(10, 50))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=imp_mean.sort_values(by=\"importance\", ascending=False))\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(oof['isSpeed0'], oof['pred'])\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %.2f)'%auc)\n",
    "plt.legend()\n",
    "plt.xlabel('FPR: False positive rate')\n",
    "plt.ylabel('TPR: True positive rate')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(oof['isSpeed0'], oof['pred'])\n",
    "\n",
    "auc = metrics.auc(recall, precision)\n",
    "print(auc)\n",
    "\n",
    "plt.plot(recall, precision, label='PR curve (area = %.2f)'%auc)\n",
    "plt.legend()\n",
    "plt.title('PR curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "print('PR_AUC : ', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-springer",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof.loc[oof['pred']>0.5, 'pred2'] = 1\n",
    "oof['pred2'] = oof['pred2'].fillna(0)\n",
    "confusion_matrix(oof['isSpeed0'], oof['pred2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-activity",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof['pred'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sp0_pred = oof[['collectionName', 'phoneName', 'millisSinceGpsEpoch', 'pred']].copy()\n",
    "test_sp0_pred = test[['collectionName', 'phoneName', 'millisSinceGpsEpoch', 'pred']].copy()\n",
    "\n",
    "train_sp0_pred['phone'] = train_sp0_pred['collectionName'] + '_' + train_sp0_pred['phoneName']\n",
    "test_sp0_pred['phone'] = test_sp0_pred['collectionName'] + '_' + test_sp0_pred['phoneName']\n",
    "\n",
    "train_sp0_pred['isSpeed0'] = 0\n",
    "test_sp0_pred['isSpeed0'] = 0\n",
    "train_sp0_pred.loc[train_sp0_pred['pred']>0.5, 'isSpeed0'] = 1\n",
    "test_sp0_pred.loc[test_sp0_pred['pred']>0.5, 'isSpeed0'] = 1\n",
    "\n",
    "print('acc : ', accuracy_score(oof['isSpeed0'], train_sp0_pred['isSpeed0']))\n",
    "\n",
    "train_sp0_pred.loc[(train_sp0_pred['phone']==train_sp0_pred['phone'].shift(1)) & (train_sp0_pred['phone']==train_sp0_pred['phone'].shift(-1)) &\n",
    "                   (train_sp0_pred['isSpeed0']==0) & (train_sp0_pred['isSpeed0'].shift(1)==1) & (train_sp0_pred['isSpeed0'].shift(-1)==1), 'isSpeed0'] = 1\n",
    "\n",
    "test_sp0_pred.loc[(test_sp0_pred['phone']==test_sp0_pred['phone'].shift(1)) & (test_sp0_pred['phone']==test_sp0_pred['phone'].shift(-1)) &\n",
    "                   (test_sp0_pred['isSpeed0']==0) & (test_sp0_pred['isSpeed0'].shift(1)==1) & (test_sp0_pred['isSpeed0'].shift(-1)==1), 'isSpeed0'] = 1\n",
    "\n",
    "print('acc(オセロ後) : ', accuracy_score(oof['isSpeed0'], train_sp0_pred['isSpeed0']))\n",
    "\n",
    "train_sp0_pred.to_csv(OUTPUT + '/train_sp0_pred.csv', index=False)\n",
    "test_sp0_pred.to_csv(OUTPUT + '/test_sp0_pred.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
